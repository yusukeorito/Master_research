{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusukeorito/Master_research/blob/main/exp011/notebooks/Exp011_Train_model_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "k4jttm-bBRQw",
        "outputId": "7abed0a4-ac5b-4cf9-bbb4-aae9d4fba6c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n問題設定：分類問題\\n学習データサイズ M：訓練6000、テスト10000\\nレイヤー数L : 10 or 20\\nネットワークの幅N:100\\nノイズパラメータλ:1.5\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "問題設定：分類問題\n",
        "学習データサイズ M：訓練6000、テスト10000\n",
        "レイヤー数L : 10 or 20\n",
        "ネットワークの幅N:100\n",
        "ノイズパラメータλ:1.5\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJH8A7QCbdT",
        "outputId": "c849ffaf-9536-4d1e-bb73-ed7ebfe3bc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_tPowEVCb-b",
        "outputId": "48e30201-1732-4802-f6e9-440828262498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master_research/exp011\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Master_research/exp011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GW8siZNYCkfh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,Activation\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class CFG:\n",
        "    task = 'classification'\n",
        "    seed1 = 820\n",
        "    seed2=314\n",
        "    seed3=1228\n",
        "    seed4=1229\n",
        "    data_seed = 42\n",
        "    save_dir = '../Model/'\n",
        "    output_dir = '../Output/'\n",
        "    L=10\n",
        "    M=60000\n",
        "    N=100\n",
        "    #A=1.5#ノイズの強さ\n",
        "    C=50#結合を持つweightの個数\n",
        "    ini_type = 'B'\n",
        "    train='train'\n",
        "    mean = 0.5  # 平均\n",
        "    std_dev = 0.1  # 標準偏差\n",
        "    layer_name_list =['batch_normalization1', 'batch_normalization2', 'batch_normalization3',\n",
        "                   'batch_normalization4', 'batch_normalization5', 'batch_normalization6', 'batch_normalization7', 'batch_normalization8',\n",
        "                   'batch_normalization9','batch_normalization10',]\n",
        "\n",
        "def set_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    # optional\n",
        "    # for numpy.random\n",
        "    np.random.seed(seed)\n",
        "    # for built-in random\n",
        "    random.seed(seed)\n",
        "    # for hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "def preprocess_data(X_train_, y_train_):\n",
        "    # Rasterize and normalize samples\n",
        "\n",
        "    X_train_ = X_train_.reshape(X_train_.shape[0], -1)\n",
        "    y_train_ = y_train_.reshape(y_train_.shape[0], -1)\n",
        "\n",
        "    X_train_ = X_train_ / 255\n",
        "    y_train_ = y_train_ / 255\n",
        "\n",
        "    # Use 32-bit instead of 64-bit float\n",
        "    X_train_ = X_train_.astype(\"float32\")\n",
        "    y_train_ = y_train_.astype(\"float32\")\n",
        "\n",
        "    return X_train_, y_train_\n",
        "\n",
        "def PCA_SS_func(input_train,input_test):\n",
        "  input_d=100\n",
        "  # Make an instance of the Model\n",
        "  pca = PCA(n_components=input_d)\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  train_img = pca.fit_transform(input_train)\n",
        "  print(np.sum(pca.explained_variance_ratio_[:]))\n",
        "  train_img =scaler.fit_transform(train_img)\n",
        "  test_img = pca.transform(input_test)\n",
        "  test_img =scaler.transform(test_img)\n",
        "  print('Train:',train_img.shape)\n",
        "  print('Test:',test_img.shape)\n",
        "  return train_img, test_img, pca, scaler\n",
        "\n",
        "\n",
        "\n",
        "class LogEpochIntermediateCallcack(Callback):\n",
        "    def __init__(self, layer_name_list, model_num):\n",
        "        self.layer_name_list = layer_name_list\n",
        "        self.spin_dict = {key: [] for key in self.layer_name_list}\n",
        "        self.nextMeas = 1\n",
        "        self.model_num = model_num\n",
        "\n",
        "    def on_train_begin(self, batch, logs=None):\n",
        "        self.spin_dict['time'] = [0]\n",
        "\n",
        "        for l in self.layer_name_list:\n",
        "            intermediate_layer_model = tf.keras.Model(inputs=self.model.input, outputs=self.model.get_layer(l).output)\n",
        "\n",
        "            if CFG.M == 60000:\n",
        "                intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "            else:\n",
        "                intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "            tf.keras.backend.clear_session()\n",
        "            self.spin_dict[l].append(intermediate_output)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.ep = epoch\n",
        "\n",
        "    def on_epoch_end(self, batch, logs):\n",
        "        if self.ep + 1 == self.nextMeas:\n",
        "            for l in self.layer_name_list:\n",
        "                intermediate_layer_model = tf.keras.Model(inputs=self.model.input, outputs=self.model.get_layer(l).output)\n",
        "\n",
        "                if CFG.M == 60000:\n",
        "                    intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "                else:\n",
        "                    intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "                tf.keras.backend.clear_session()\n",
        "                self.spin_dict[l].append(intermediate_output)\n",
        "\n",
        "            self.spin_dict['time'] += [self.ep + 1]\n",
        "            self.nextMeas = int(self.nextMeas * 1.1)\n",
        "\n",
        "            if self.ep + 1 == self.nextMeas:\n",
        "                self.nextMeas = self.nextMeas + 1\n",
        "\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        for l in self.layer_name_list:\n",
        "            self.spin_dict[l] = np.array(self.spin_dict[l])\n",
        "\n",
        "        with open(f'./Output/Spin/M{CFG.M}/model{self.model_num}_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt', 'wb') as handle:\n",
        "            pickle.dump(self.spin_dict, handle)\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean, std_dev, alpha):\n",
        "    noise = np.random.normal(mean, std_dev, image.shape)\n",
        "    noisy_image = image + alpha * noise\n",
        "    return np.clip(noisy_image, 0, 1)  # ピクセル値を0から1の範囲にクリップ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomConstraint(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, mask, const):\n",
        "        self.mask = mask\n",
        "        self.const = const\n",
        "\n",
        "    def __call__(self, w):\n",
        "        # マスク行列を使用して、指定された部分を0で固定する\n",
        "        w.assign(tf.math.multiply(w, self.mask) + self.const)\n",
        "        return w\n",
        "\n",
        "\n",
        "def get_mask(shape, C, specified_number, dtype=int):\n",
        "    masks = np.zeros(shape)\n",
        "    consts = np.random.normal(size=shape)\n",
        "    for col in range(shape[1]):\n",
        "        non_zero_indices = np.random.choice(shape[0], C, replace=False)\n",
        "        masks[non_zero_indices, col] = 1\n",
        "        consts[non_zero_indices, col] = 0\n",
        "    masks = tf.constant(masks, dtype=tf.float32)\n",
        "    consts = tf.constant(consts, dtype=tf.float32)\n",
        "    return masks, consts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model(params:dict,w_initializer,Mask_list,Const_list):\n",
        "    \"\"\"\n",
        "    Creates a neural network model based on the given parameters.\n",
        "\n",
        "    Args:\n",
        "        params (dict): Dictionary containing model parameters.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = Sequential(name='custom_model')\n",
        "    model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],input_shape=(params['input_size'],), name='Affine1',kernel_constraint=CustomConstraint(mask=Mask_list[0],const=Const_list[0])))\n",
        "    model.add(BatchNormalization(name='batch_normalization1'))\n",
        "    model.add(Activation('relu', name='activation1'))\n",
        "    for i in range(1, params['num_layers'] - 1):\n",
        "        model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name=f'Affine{i+1}',kernel_constraint=CustomConstraint(mask=Mask_list[i],const=Const_list[i])))\n",
        "        model.add(BatchNormalization(name=f'batch_normalization{i+1}'))\n",
        "        model.add(Activation('relu',name=f'activation{i+1}'))\n",
        "\n",
        "    model.add(Dense(params['output_size'],kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name='output',kernel_constraint=CustomConstraint(mask=Mask_list[9],const=Const_list[9])))\n",
        "    model.add(BatchNormalization(name=f'batch_normalization{params[\"num_layers\"]}'))\n",
        "    model.add(Activation('softmax', name=f'activation{params[\"num_layers\"]}'))\n",
        "    model.compile(loss=params['loss'], optimizer='adam',metrics=params['metrics']\n",
        "                  )\n",
        "    return model\n",
        "\n",
        "\n",
        "def calc_q_(A: np.ndarray, B: np.ndarray) -> float:\n",
        "    M, N = A.shape\n",
        "    dot_product = np.dot(A.T, B)\n",
        "    x = np.sum(dot_product ** 2)\n",
        "    x /= N * M * M\n",
        "    x -= N / M\n",
        "    return x\n",
        "\n",
        "def calc_sim_q(A: np.ndarray, B: np.ndarray) -> float:\n",
        "  mean = A * B\n",
        "  sim_q = np.mean(mean)\n",
        "  return sim_q\n",
        "\n",
        "def get_sim_q(spinA, spinB):\n",
        "  q_dict={'time':spin_A['time']}\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "      q_list=[]\n",
        "      for i in range(len(spin_A[l])):\n",
        "          q = calc_sim_q(spin_A[l][i],spin_B[l][i])\n",
        "          q_list.append(q)\n",
        "      q_dict[l]=q_list\n",
        "  with open(f'./Output/Overlap/q/M{CFG.M}/sim_q_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(q_dict, handle)\n",
        "  return q_dict\n",
        "\n",
        "def get_q2(spinA, spinB):\n",
        "    qab_dict={'time':spinA['time']}#時刻の初期化\n",
        "    qaa_dict={'time':spinA['time']}\n",
        "    q2_dict={'time':spinA['time']}\n",
        "    for l in tqdm(CFG.layer_name_list):\n",
        "        qab_list=[]\n",
        "        qaa_list=[]\n",
        "        q2_list=[]\n",
        "        for i in range(len(spinA[l])):\n",
        "            ab = calc_q_(spinA[l][i],spinB[l][i])\n",
        "            aa= calc_q_(spinA[l][i],spinA[l][i])\n",
        "            bb = calc_q_(spinB[l][i],spinB[l][i])\n",
        "            q2 = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
        "            qab_list.append(ab)\n",
        "            qaa_list.append(aa)\n",
        "            q2_list.append(q2)\n",
        "        qab_dict[l] = qab_list\n",
        "        qaa_dict[l] = qaa_list\n",
        "        q2_dict[l] = q2_list\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qab_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qab_dict, handle)\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qaa_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qaa_dict, handle)\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/M{CFG.M}/q2_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(q2_dict, handle)\n",
        "    return qab_dict, qaa_dict, q2_dict\n",
        "\n",
        "\n",
        "\n",
        "def get_layer_overlap(qab:dict,qaa:dict,q2:dict,sim_q:dict):\n",
        "  layer_dict={}\n",
        "  layer_q2=[]\n",
        "  layer_qab=[]\n",
        "  layer_qaa=[]\n",
        "  layer_sim_q=[]\n",
        "\n",
        "  for i, l in enumerate(CFG.layer_name_list):\n",
        "      layer_q2.append(q2[l][-1])#平衡状態のOverlapを取得\n",
        "      layer_qab.append(qab[l][-1])\n",
        "      layer_qaa.append(qaa[l][-1])\n",
        "      layer_sim_q.append(sim_q[l][-1])\n",
        "  layer_dict['q2']=layer_q2\n",
        "  layer_dict['qab']=layer_qab\n",
        "  layer_dict['qaa']=layer_qaa\n",
        "  layer_dict['sim_q']=layer_sim_q\n",
        "\n",
        "  with open(f'./Output/Overlap/Layer_q/M{CFG.M}/layerq_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(layer_dict, handle)\n",
        "  return layer_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_normalized_spin(SpinA, SpinB):\n",
        "  spinA_norm = SpinA.copy()\n",
        "  spinB_norm = SpinB.copy()\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "        squared_sum_A = np.sum(SpinA[l]**2, axis=2)\n",
        "        squared_sum_B = np.sum(SpinB[l]**2, axis=2)\n",
        "        # 規格化定数を計算\n",
        "        normalization_constA = np.sqrt(100 / squared_sum_A)\n",
        "        normalization_constB = np.sqrt(100 / squared_sum_B)\n",
        "        # 規格化した配列を計算\n",
        "        spinA_norm[l] = SpinA[l] * normalization_constA[:, :, np.newaxis]\n",
        "        spinB_norm[l] = SpinB[l] * normalization_constB[:, :, np.newaxis]\n",
        "\n",
        "  return spinA_norm, spinB_norm\n",
        "\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    'num_layers':CFG.L,\n",
        "    'input_size': 100,#width of network\n",
        "    'output_size': 10,\n",
        "    'batch_size':256,\n",
        "    'width':100,\n",
        "    'epochs':3000,\n",
        "    'metrics':'accuracy',\n",
        "    'loss':'sparse_categorical_crossentropy',\n",
        "    'activation':'relu',\n",
        "    'activation_last':'softmax',\n",
        "    #'weight_initializer': tf.keras.initializers.RandomNormal(mean=0.0, stddev=1),\n",
        "    'bias_initializer_value': 0.1,\n",
        "    'bias_initializer': tf.keras.initializers.Constant(0.1),\n",
        "    'optimizer':'adam',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZpwqvrqsisf",
        "outputId": "b4f2e4a7-bb91-4206-f5aa-0d420fbb343a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============Data Load===============\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "===============Preprocess data===============\n",
            "N_classes: 10\n",
            "Train size: (60000, 784) Test size: (60000,)\n",
            "===============PCA===============\n",
            "0.91186106\n",
            "Train: (60000, 100)\n",
            "Test: (10000, 100)\n",
            "Train size after PCA: (60000, 100) Test size after PCA: (10000, 100)\n",
            "M=60000\n",
            "X_train for mesure: (6000, 100) y_train for mesure: (6000,)\n",
            "===============get_mask===============\n",
            "===============task is classification===============\n",
            "===============Build model1===============\n",
            "initialize type B\n",
            "===============build model2===============\n",
            "initialize type B\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.6401437  -0.33340132  0.98882574 ... -0.75911707  0.82278544\n",
            "   2.4460115 ]\n",
            " [ 0.95194006  0.92104834  2.9945617  ...  0.19922836  0.2991733\n",
            "  -0.46256137]\n",
            " [-0.6983341  -0.36895558 -0.1844795  ... -0.37328297 -2.3215005\n",
            "   0.01210937]\n",
            " ...\n",
            " [ 1.1057978  -1.3620049  -0.18676303 ...  0.9649634   0.8570971\n",
            "  -0.75597304]\n",
            " [-1.9409086   1.2088009   0.7533919  ...  0.08570503 -0.02347519\n",
            "  -1.3256403 ]\n",
            " [ 1.377233   -0.5961148  -1.1672751  ...  0.73268723  0.24910629\n",
            "  -0.11387793]]\n",
            "===============Train model2===============\n",
            "188/188 [==============================] - 4s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "Epoch 1/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 17s 42ms/step - loss: 2.2929 - accuracy: 0.1986 - val_loss: 2.5292 - val_accuracy: 0.2490\n",
            "Epoch 2/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 1.8571 - accuracy: 0.3640 - val_loss: 1.6842 - val_accuracy: 0.4286\n",
            "Epoch 3/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 1.5364 - accuracy: 0.4906 - val_loss: 1.3876 - val_accuracy: 0.5353\n",
            "Epoch 4/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 1.2645 - accuracy: 0.5871 - val_loss: 1.1520 - val_accuracy: 0.6208\n",
            "Epoch 5/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 1.0535 - accuracy: 0.6569 - val_loss: 0.9818 - val_accuracy: 0.6745\n",
            "Epoch 6/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 0.8950 - accuracy: 0.7070 - val_loss: 0.8612 - val_accuracy: 0.7109\n",
            "Epoch 7/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 40ms/step - loss: 0.7820 - accuracy: 0.7430 - val_loss: 0.7749 - val_accuracy: 0.7376\n",
            "Epoch 8/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.6980 - accuracy: 0.7673 - val_loss: 0.7134 - val_accuracy: 0.7555\n",
            "Epoch 9/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 44ms/step - loss: 0.6394 - accuracy: 0.7858 - val_loss: 0.6676 - val_accuracy: 0.7699\n",
            "Epoch 10/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 40ms/step - loss: 0.5941 - accuracy: 0.7982 - val_loss: 0.6303 - val_accuracy: 0.7808\n",
            "Epoch 11/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 0.5547 - accuracy: 0.8115 - val_loss: 0.6014 - val_accuracy: 0.7895\n",
            "Epoch 12/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 0.5239 - accuracy: 0.8202 - val_loss: 0.5770 - val_accuracy: 0.7968\n",
            "Epoch 13/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 0.5008 - accuracy: 0.8286 - val_loss: 0.5579 - val_accuracy: 0.8027\n",
            "Epoch 14/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 0.4767 - accuracy: 0.8363 - val_loss: 0.5416 - val_accuracy: 0.8090\n",
            "Epoch 15/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 0.4578 - accuracy: 0.8405 - val_loss: 0.5269 - val_accuracy: 0.8130\n",
            "Epoch 16/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 38ms/step - loss: 0.4414 - accuracy: 0.8462 - val_loss: 0.5153 - val_accuracy: 0.8163\n",
            "Epoch 17/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 40ms/step - loss: 0.4259 - accuracy: 0.8515 - val_loss: 0.5049 - val_accuracy: 0.8195\n",
            "Epoch 18/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.4122 - accuracy: 0.8558 - val_loss: 0.4982 - val_accuracy: 0.8226\n",
            "Epoch 19/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.4021 - accuracy: 0.8582 - val_loss: 0.4905 - val_accuracy: 0.8240\n",
            "Epoch 20/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 43ms/step - loss: 0.3892 - accuracy: 0.8632 - val_loss: 0.4838 - val_accuracy: 0.8265\n",
            "Epoch 21/3000\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3777 - accuracy: 0.8659 - val_loss: 0.4795 - val_accuracy: 0.8290\n",
            "Epoch 22/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3704 - accuracy: 0.8689 - val_loss: 0.4761 - val_accuracy: 0.8310\n",
            "Epoch 23/3000\n",
            "235/235 [==============================] - 4s 12ms/step - loss: 0.3607 - accuracy: 0.8714 - val_loss: 0.4716 - val_accuracy: 0.8321\n",
            "Epoch 24/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.3521 - accuracy: 0.8742 - val_loss: 0.4681 - val_accuracy: 0.8331\n",
            "Epoch 25/3000\n",
            "235/235 [==============================] - 4s 12ms/step - loss: 0.3444 - accuracy: 0.8770 - val_loss: 0.4677 - val_accuracy: 0.8353\n",
            "Epoch 26/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.3364 - accuracy: 0.8800 - val_loss: 0.4654 - val_accuracy: 0.8368\n",
            "Epoch 27/3000\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.3287 - accuracy: 0.8831 - val_loss: 0.4653 - val_accuracy: 0.8378\n",
            "Epoch 28/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.3216 - accuracy: 0.8837 - val_loss: 0.4665 - val_accuracy: 0.8394\n",
            "Epoch 29/3000\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3150 - accuracy: 0.8871 - val_loss: 0.4629 - val_accuracy: 0.8389\n",
            "Epoch 30/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.3073 - accuracy: 0.8895 - val_loss: 0.4610 - val_accuracy: 0.8400\n",
            "Epoch 31/3000\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 0.3023 - accuracy: 0.8906 - val_loss: 0.4656 - val_accuracy: 0.8410\n",
            "Epoch 32/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2983 - accuracy: 0.8928 - val_loss: 0.4672 - val_accuracy: 0.8388\n",
            "Epoch 33/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.2927 - accuracy: 0.8943 - val_loss: 0.4670 - val_accuracy: 0.8380\n",
            "Epoch 34/3000\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2875 - accuracy: 0.8962 - val_loss: 0.4663 - val_accuracy: 0.8404\n",
            "Epoch 35/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.2795 - accuracy: 0.8980 - val_loss: 0.4692 - val_accuracy: 0.8400\n",
            "Epoch 36/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.2725 - accuracy: 0.9018 - val_loss: 0.4714 - val_accuracy: 0.8393\n",
            "Epoch 37/3000\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2720 - accuracy: 0.9010 - val_loss: 0.4737 - val_accuracy: 0.8407\n",
            "Epoch 38/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.2649 - accuracy: 0.9037 - val_loss: 0.4774 - val_accuracy: 0.8383\n",
            "Epoch 39/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "134/188 [====================>.........] - ETA: 0s"
          ]
        }
      ],
      "source": [
        "print('='*15+'Data Load'+'='*15)\n",
        "set_seed(seed=CFG.data_seed)\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "del fashion_mnist\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print('='*15+'Preprocess data'+'='*15)\n",
        "X_train, X_test = preprocess_data(X_train, X_test)\n",
        "\n",
        "\n",
        "idx = np.random.choice(X_train.shape[0], size=CFG.M, replace=False)\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "print('N_classes:',n_classes)\n",
        "print('Train size:',X_train.shape, 'Test size:', y_train.shape)\n",
        "\n",
        "\n",
        "print('='*15+'PCA'+'='*15)\n",
        "X_train,X_test, pca1, scaler1 = PCA_SS_func(X_train, X_test)\n",
        "print('Train size after PCA:',X_train.shape, 'Test size after PCA:', X_test.shape)\n",
        "\n",
        "if CFG.M == 60000:\n",
        "  print('M=60000')\n",
        "  idx = np.random.choice(X_train.shape[0], size=6000, replace=False)\n",
        "  X_train_ = X_train[idx]\n",
        "  y_train_ = y_train[idx]\n",
        "  print('X_train for mesure:',X_train_.shape,'y_train for mesure:',y_train_.shape, )\n",
        "\n",
        "print('='*15+'get_mask'+'='*15)\n",
        "mask_list = []\n",
        "const_list = []\n",
        "for i in range(CFG.L-1):\n",
        "  mask,const = get_mask(shape=(100,100),C=CFG.C,specified_number=5)\n",
        "  mask_list.append(mask)\n",
        "  const_list.append(const)\n",
        "\n",
        "if CFG.task == 'classification':\n",
        "  print('='*15+'task is classification'+'='*15)\n",
        "  mask, const = get_mask(shape=(100,10),C=CFG.C,specified_number=5)\n",
        "  mask_list.append(mask)\n",
        "  const_list.append(const)\n",
        "\n",
        "\n",
        "print('='*15+'Build model1'+'='*15)\n",
        "if CFG.ini_type == 'A':\n",
        "  print('initialize type A')\n",
        "  set_seed(CFG.seed1)\n",
        "  w_intializer1 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "elif CFG.ini_type == 'B':\n",
        "  print('initialize type B')\n",
        "  set_seed(CFG.seed3)\n",
        "  w_intializer1 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "\"\"\"\n",
        "model1 = create_model(params=model_params, w_initializer=w_intializer1,Mask_list=mask_list ,Const_list=const_list)\n",
        "print(model1.layers[3].get_weights()[0])\n",
        "\n",
        "print('='*15+'Train model1'+'='*15)\n",
        "history1 = model1.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='001')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform001_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history1.history, handle)\n",
        "\n",
        "\"\"\"\n",
        "print('='*15+'build model2'+'='*15)\n",
        "if CFG.ini_type == 'A':\n",
        "  print('initialize type A')\n",
        "  set_seed(CFG.seed2)\n",
        "  w_intializer2 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "elif CFG.ini_type == 'B':\n",
        "  print('initialize type B')\n",
        "  #w_intializer2 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "  set_seed(CFG.seed4)\n",
        "\n",
        "\n",
        "model2 = create_model(params=model_params, w_initializer=w_intializer1, Mask_list=mask_list ,Const_list=const_list)\n",
        "print(model2.layers[3].get_weights()[0])\n",
        "print('='*15+'Train model2'+'='*15)\n",
        "history2 = model2.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='002')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform002_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history2.history, handle)\n",
        "\n",
        "print('='*15+'get spin'+'='*15)\n",
        "with open(f'./Output/Spin/M{CFG.M}/model001_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_A=pickle.loads(f.read())\n",
        "\n",
        "with open(f'./Output/Spin/M{CFG.M}/model002_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_B=pickle.loads(f.read())\n",
        "\n",
        "\n",
        "print('='*15+'get calc'+'='*15)\n",
        "qab, qaa, q2 = get_q2(spin_A,spin_B)\n",
        "sim_q = get_sim_q(spin_A, spin_B)\n",
        "layer_q = get_layer_overlap(qab,qaa,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ2IH6evFdIH",
        "outputId": "004b32a0-dc02-4e09-99a2-7de5b7972e8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 172.13it/s]\n"
          ]
        }
      ],
      "source": [
        "sim_q = get_sim_q(spin_A, spin_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2AkBEzQ_BfK7",
        "outputId": "f85524f4-f6dd-4ae2-dbaf-a4ccc804ba7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c87a3da94b0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "for i, l in enumerate(CFG.layer_name_list):\n",
        "    ax.plot(sim_q['time'],sim_q[l],label=f'layer{i}')\n",
        "ax.set_xlabel('Epoch',fontsize=16)\n",
        "ax.set_ylabel('sim_q', fontsize=16)\n",
        "#ax.set_xscale('log')\n",
        "ax.set_title(f'Train Data (M:{CFG.M} L:{CFG.L})',fontsize=16)\n",
        "#ax.set_ylim(0,1)\n",
        "ax.grid(axis='y')\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaZMtXE_FiB6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMkhdh2tDUfZWN4LXXN0I6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}