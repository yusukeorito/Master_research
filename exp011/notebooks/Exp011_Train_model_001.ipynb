{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusukeorito/Master_research/blob/main/exp011/notebooks/Exp011_Train_model_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k4jttm-bBRQw",
        "outputId": "6ca4d530-3bcd-49e5-e0f1-534943148335"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n問題設定：分類問題\\n学習データサイズ M：訓練6000、テスト10000\\nレイヤー数L : 10 or 20\\nネットワークの幅N:100\\nノイズパラメータλ:1.5\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "問題設定：分類問題\n",
        "学習データサイズ M：訓練6000、テスト10000\n",
        "レイヤー数L : 10 or 20\n",
        "ネットワークの幅N:100\n",
        "ノイズパラメータλ:1.5\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJH8A7QCbdT",
        "outputId": "c488081b-9f18-4477-eefe-b9958646c400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_tPowEVCb-b",
        "outputId": "150eabce-184f-4a3c-88d8-615500b9cd24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master_research/exp011\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Master_research/exp011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW8siZNYCkfh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,Activation\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class CFG:\n",
        "    task = 'classification'\n",
        "    seed1 = 820\n",
        "    seed2=314\n",
        "    seed3=1228\n",
        "    seed4=1229\n",
        "    data_seed = 42\n",
        "    save_dir = '../Model/'\n",
        "    output_dir = '../Output/'\n",
        "    L=10\n",
        "    M=60000\n",
        "    N=100\n",
        "    #A=1.5#ノイズの強さ\n",
        "    C=50#結合を持つweightの個数\n",
        "    ini_type = 'B'\n",
        "    train='train'\n",
        "    mean = 0.5  # 平均\n",
        "    std_dev = 0.1  # 標準偏差\n",
        "    layer_name_list =['batch_normalization1', 'batch_normalization2', 'batch_normalization3',\n",
        "                   'batch_normalization4', 'batch_normalization5', 'batch_normalization6', 'batch_normalization7', 'batch_normalization8',\n",
        "                   'batch_normalization9','batch_normalization10',]\n",
        "\n",
        "def set_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    # optional\n",
        "    # for numpy.random\n",
        "    np.random.seed(seed)\n",
        "    # for built-in random\n",
        "    random.seed(seed)\n",
        "    # for hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "def preprocess_data(X_train_, y_train_):\n",
        "    # Rasterize and normalize samples\n",
        "\n",
        "    X_train_ = X_train_.reshape(X_train_.shape[0], -1)\n",
        "    y_train_ = y_train_.reshape(y_train_.shape[0], -1)\n",
        "\n",
        "    X_train_ = X_train_ / 255\n",
        "    y_train_ = y_train_ / 255\n",
        "\n",
        "    # Use 32-bit instead of 64-bit float\n",
        "    X_train_ = X_train_.astype(\"float32\")\n",
        "    y_train_ = y_train_.astype(\"float32\")\n",
        "\n",
        "    return X_train_, y_train_\n",
        "\n",
        "def PCA_SS_func(input_train,input_test):\n",
        "  input_d=100\n",
        "  # Make an instance of the Model\n",
        "  pca = PCA(n_components=input_d)\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  train_img = pca.fit_transform(input_train)\n",
        "  print(np.sum(pca.explained_variance_ratio_[:]))\n",
        "  train_img =scaler.fit_transform(train_img)\n",
        "  test_img = pca.transform(input_test)\n",
        "  test_img =scaler.transform(test_img)\n",
        "  print('Train:',train_img.shape)\n",
        "  print('Test:',test_img.shape)\n",
        "  return train_img, test_img, pca, scaler\n",
        "\n",
        "\n",
        "\n",
        "class LogEpochIntermediateCallcack(Callback):\n",
        "    def __init__(self, layer_name_list, model_num):\n",
        "        self.layer_name_list = layer_name_list\n",
        "        self.spin_dict = {key: [] for key in self.layer_name_list}\n",
        "        self.nextMeas = 1\n",
        "        self.model_num = model_num\n",
        "\n",
        "    def on_train_begin(self, batch, logs=None):\n",
        "        self.spin_dict['time'] = [0]\n",
        "\n",
        "        for l in self.layer_name_list:\n",
        "            intermediate_layer_model = tf.keras.Model(inputs=self.model.input, outputs=self.model.get_layer(l).output)\n",
        "\n",
        "            if CFG.M == 60000:\n",
        "                intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "            else:\n",
        "                intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "            tf.keras.backend.clear_session()\n",
        "            self.spin_dict[l].append(intermediate_output)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.ep = epoch\n",
        "\n",
        "    def on_epoch_end(self, batch, logs):\n",
        "        if self.ep + 1 == self.nextMeas:\n",
        "            for l in self.layer_name_list:\n",
        "                intermediate_layer_model = tf.keras.Model(inputs=self.model.input, outputs=self.model.get_layer(l).output)\n",
        "\n",
        "                if CFG.M == 60000:\n",
        "                    intermediate_output = intermediate_layer_model.predict(X_train_)\n",
        "                else:\n",
        "                    intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "                tf.keras.backend.clear_session()\n",
        "                self.spin_dict[l].append(intermediate_output)\n",
        "\n",
        "            self.spin_dict['time'] += [self.ep + 1]\n",
        "            self.nextMeas = int(self.nextMeas * 1.1)\n",
        "\n",
        "            if self.ep + 1 == self.nextMeas:\n",
        "                self.nextMeas = self.nextMeas + 1\n",
        "\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        for l in self.layer_name_list:\n",
        "            self.spin_dict[l] = np.array(self.spin_dict[l])\n",
        "\n",
        "        with open(f'./Output/Spin/M{CFG.M}/model{self.model_num}_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt', 'wb') as handle:\n",
        "            pickle.dump(self.spin_dict, handle)\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean, std_dev, alpha):\n",
        "    noise = np.random.normal(mean, std_dev, image.shape)\n",
        "    noisy_image = image + alpha * noise\n",
        "    return np.clip(noisy_image, 0, 1)  # ピクセル値を0から1の範囲にクリップ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomConstraint(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, mask, const):\n",
        "        self.mask = mask\n",
        "        self.const = const\n",
        "\n",
        "    def __call__(self, w):\n",
        "        # マスク行列を使用して、指定された部分を0で固定する\n",
        "        w.assign(tf.math.multiply(w, self.mask) + self.const)\n",
        "        return w\n",
        "\n",
        "\n",
        "def get_mask(shape, C, specified_number, dtype=int):\n",
        "    masks = np.zeros(shape)\n",
        "    consts = np.random.normal(size=shape)\n",
        "    for col in range(shape[1]):\n",
        "        non_zero_indices = np.random.choice(shape[0], C, replace=False)\n",
        "        masks[non_zero_indices, col] = 1\n",
        "        consts[non_zero_indices, col] = 0\n",
        "    masks = tf.constant(masks, dtype=tf.float32)\n",
        "    consts = tf.constant(consts, dtype=tf.float32)\n",
        "    return masks, consts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model(params:dict,w_initializer,Mask_list,Const_list):\n",
        "    \"\"\"\n",
        "    Creates a neural network model based on the given parameters.\n",
        "\n",
        "    Args:\n",
        "        params (dict): Dictionary containing model parameters.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = Sequential(name='custom_model')\n",
        "    model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],input_shape=(params['input_size'],), name='Affine1',kernel_constraint=CustomConstraint(mask=Mask_list[0],const=Const_list[0])))\n",
        "    model.add(BatchNormalization(name='batch_normalization1'))\n",
        "    model.add(Activation('relu', name='activation1'))\n",
        "    for i in range(1, params['num_layers'] - 1):\n",
        "        model.add(Dense(params['width'], kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name=f'Affine{i+1}',kernel_constraint=CustomConstraint(mask=Mask_list[i],const=Const_list[i])))\n",
        "        model.add(BatchNormalization(name=f'batch_normalization{i+1}'))\n",
        "        model.add(Activation('relu',name=f'activation{i+1}'))\n",
        "\n",
        "    model.add(Dense(params['output_size'],kernel_initializer=w_initializer,bias_initializer=params['bias_initializer'],name='output',kernel_constraint=CustomConstraint(mask=Mask_list[9],const=Const_list[9])))\n",
        "    model.add(BatchNormalization(name=f'batch_normalization{params[\"num_layers\"]}'))\n",
        "    model.add(Activation('softmax', name=f'activation{params[\"num_layers\"]}'))\n",
        "    model.compile(loss=params['loss'], optimizer='adam',metrics=params['metrics']\n",
        "                  )\n",
        "    return model\n",
        "\n",
        "\n",
        "def calc_q_(A: np.ndarray, B: np.ndarray) -> float:\n",
        "    M, N = A.shape\n",
        "    dot_product = np.dot(A.T, B)\n",
        "    x = np.sum(dot_product ** 2)\n",
        "    x /= N * M * M\n",
        "    x -= N / M\n",
        "    return x\n",
        "\n",
        "def calc_sim_q(A: np.ndarray, B: np.ndarray) -> float:\n",
        "  mean = A * B\n",
        "  sim_q = np.mean(mean)\n",
        "  return sim_q\n",
        "\n",
        "def get_sim_q(spinA, spinB):\n",
        "  qab_dict={'time':spinA['time']}#時刻の初期化\n",
        "  qaa_dict={'time':spinA['time']}\n",
        "  sim_q_dict={'time':spinA['time']}\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "      qab_list=[]\n",
        "      qaa_list=[]\n",
        "      sim_q_list=[]\n",
        "      for i in range(len(spin_A[l])):\n",
        "          ab = calc_sim_q(spin_A[l][i],spin_B[l][i])\n",
        "          aa = calc_sim_q(spin_A[l][i],spin_A[l][i])\n",
        "          bb = calc_sim_q(spin_B[l][i],spin_B[l][i])\n",
        "          sim_q = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
        "          qab_list.append(ab)\n",
        "          qaa_list.append(aa)\n",
        "          sim_q_list.append(sim_q)\n",
        "      qab_dict[l] = qab_list\n",
        "      qaa_dict[l] = qaa_list\n",
        "      sim_q_dict[l] = sim_q_list\n",
        "  with open(f'./Output/Overlap/q/M{CFG.M}/sim_q_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(sim_q_dict, handle)\n",
        "  return sim_q_dict\n",
        "\n",
        "\n",
        "def get_q2(spinA, spinB):\n",
        "    qab_dict={'time':spinA['time']}#時刻の初期化\n",
        "    qaa_dict={'time':spinA['time']}\n",
        "    q2_dict={'time':spinA['time']}\n",
        "    for l in tqdm(CFG.layer_name_list):\n",
        "        qab_list=[]\n",
        "        qaa_list=[]\n",
        "        q2_list=[]\n",
        "        for i in range(len(spinA[l])):\n",
        "            ab = calc_q_(spinA[l][i],spinB[l][i])\n",
        "            aa= calc_q_(spinA[l][i],spinA[l][i])\n",
        "            bb = calc_q_(spinB[l][i],spinB[l][i])\n",
        "            q2 = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
        "            qab_list.append(ab)\n",
        "            qaa_list.append(aa)\n",
        "            q2_list.append(q2)\n",
        "        qab_dict[l] = qab_list\n",
        "        qaa_dict[l] = qaa_list\n",
        "        q2_dict[l] = q2_list\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qab_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qab_dict, handle)\n",
        "    with open(f'./Output/Overlap/q/{CFG.alg}_qaa_norm_M{CFG.M}_L{CFG.L}_A{CFG.A}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(qaa_dict, handle)\n",
        "    \"\"\"\n",
        "    with open(f'./Output/Overlap/q/M{CFG.M}/q2_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(q2_dict, handle)\n",
        "    return qab_dict, qaa_dict, q2_dict\n",
        "\n",
        "\n",
        "\n",
        "def get_layer_overlap(qab:dict,qaa:dict,q2:dict,sim_q:dict):\n",
        "  layer_dict={}\n",
        "  layer_q2=[]\n",
        "  layer_qab=[]\n",
        "  layer_qaa=[]\n",
        "  layer_sim_q=[]\n",
        "\n",
        "  for i, l in enumerate(CFG.layer_name_list):\n",
        "      layer_q2.append(q2[l][-1])#平衡状態のOverlapを取得\n",
        "      layer_qab.append(qab[l][-1])\n",
        "      layer_qaa.append(qaa[l][-1])\n",
        "      layer_sim_q.append(sim_q[l][-1])\n",
        "  layer_dict['q2']=layer_q2\n",
        "  layer_dict['qab']=layer_qab\n",
        "  layer_dict['qaa']=layer_qaa\n",
        "  layer_dict['sim_q']=layer_sim_q\n",
        "\n",
        "  with open(f'./Output/Overlap/Layer_q/M{CFG.M}/layerq_stopW_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(layer_dict, handle)\n",
        "  return layer_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_normalized_spin(SpinA, SpinB):\n",
        "  spinA_norm = SpinA.copy()\n",
        "  spinB_norm = SpinB.copy()\n",
        "  for l in tqdm(CFG.layer_name_list):\n",
        "        squared_sum_A = np.sum(SpinA[l]**2, axis=2)\n",
        "        squared_sum_B = np.sum(SpinB[l]**2, axis=2)\n",
        "        # 規格化定数を計算\n",
        "        normalization_constA = np.sqrt(100 / squared_sum_A)\n",
        "        normalization_constB = np.sqrt(100 / squared_sum_B)\n",
        "        # 規格化した配列を計算\n",
        "        spinA_norm[l] = SpinA[l] * normalization_constA[:, :, np.newaxis]\n",
        "        spinB_norm[l] = SpinB[l] * normalization_constB[:, :, np.newaxis]\n",
        "\n",
        "  return spinA_norm, spinB_norm\n",
        "\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    'num_layers':CFG.L,\n",
        "    'input_size': 100,#width of network\n",
        "    'output_size': 10,\n",
        "    'batch_size':256,\n",
        "    'width':100,\n",
        "    'epochs':3000,\n",
        "    'metrics':'accuracy',\n",
        "    'loss':'sparse_categorical_crossentropy',\n",
        "    'activation':'relu',\n",
        "    'activation_last':'softmax',\n",
        "    #'weight_initializer': tf.keras.initializers.RandomNormal(mean=0.0, stddev=1),\n",
        "    'bias_initializer_value': 0.1,\n",
        "    'bias_initializer': tf.keras.initializers.Constant(0.1),\n",
        "    'optimizer':'adam',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "wZpwqvrqsisf",
        "outputId": "ac1ebb22-019d-43fc-ebba-c4a38ffca70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============Data Load===============\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "===============Preprocess data===============\n",
            "N_classes: 10\n",
            "Train size: (60000, 784) Test size: (60000,)\n",
            "===============PCA===============\n",
            "0.91186124\n",
            "Train: (60000, 100)\n",
            "Test: (10000, 100)\n",
            "Train size after PCA: (60000, 100) Test size after PCA: (10000, 100)\n",
            "M=60000\n",
            "X_train for mesure: (6000, 100) y_train for mesure: (6000,)\n",
            "===============get_mask===============\n",
            "===============task is classification===============\n",
            "===============Build model1===============\n",
            "initialize type B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2.2169037e-01  2.5152528e-01  5.3509170e-01 ... -3.1156749e-01\n",
            "   2.2287710e-01  1.8350242e-01]\n",
            " [ 1.2763370e+00  1.5121732e+00 -7.3075229e-01 ... -6.1593682e-01\n",
            "   2.6053604e-01  1.5594426e-01]\n",
            " [-4.2724130e-01 -1.7028670e-01  4.0260607e-01 ... -1.3374084e+00\n",
            "   7.7650487e-01 -2.1277781e+00]\n",
            " ...\n",
            " [-1.8695781e-01 -1.0467594e+00 -1.0421997e+00 ...  4.6834043e-01\n",
            "   3.3366442e-01  1.6493342e+00]\n",
            " [ 7.1734779e-02 -2.9102242e-01  1.2172666e+00 ... -7.5133204e-01\n",
            "  -2.8576047e+00  1.1690609e+00]\n",
            " [ 1.6195860e+00 -1.8539562e+00  4.8366028e-01 ...  3.8090289e-01\n",
            "   4.3907928e-01  1.7404248e-03]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\\'=\\'*15+\\'Train model1\\'+\\'=\\'*15)\\nhistory1 = model1.fit(X_train, y_train,\\n                batch_size=model_params[\"batch_size\"],\\n                epochs=model_params[\"epochs\"],\\n                verbose=1,\\n                shuffle=True,\\n                validation_data=(X_test, y_test),\\n                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num=\\'001\\')]\\n                )\\n\\nprint(\\'=\\'*15+\\'Save loss and acc\\'+\\'=\\'*15)\\nwith open(f\\'./Output/Loss/M{CFG.M}/perform001_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt\\',\\'wb\\') as handle:\\n        pickle.dump(history1.history, handle)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print('='*15+'Data Load'+'='*15)\n",
        "set_seed(seed=CFG.data_seed)\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
        "del fashion_mnist\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print('='*15+'Preprocess data'+'='*15)\n",
        "X_train, X_test = preprocess_data(X_train, X_test)\n",
        "\n",
        "\n",
        "idx = np.random.choice(X_train.shape[0], size=CFG.M, replace=False)\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "print('N_classes:',n_classes)\n",
        "print('Train size:',X_train.shape, 'Test size:', y_train.shape)\n",
        "\n",
        "\n",
        "print('='*15+'PCA'+'='*15)\n",
        "X_train,X_test, pca1, scaler1 = PCA_SS_func(X_train, X_test)\n",
        "print('Train size after PCA:',X_train.shape, 'Test size after PCA:', X_test.shape)\n",
        "\n",
        "if CFG.M == 60000:\n",
        "  print('M=60000')\n",
        "  idx = np.random.choice(X_train.shape[0], size=6000, replace=False)\n",
        "  X_train_ = X_train[idx]\n",
        "  y_train_ = y_train[idx]\n",
        "  print('X_train for mesure:',X_train_.shape,'y_train for mesure:',y_train_.shape, )\n",
        "\n",
        "print('='*15+'get_mask'+'='*15)\n",
        "mask_list = []\n",
        "const_list = []\n",
        "for i in range(CFG.L-1):\n",
        "  mask,const = get_mask(shape=(100,100),C=CFG.C,specified_number=5)\n",
        "  mask_list.append(mask)\n",
        "  const_list.append(const)\n",
        "\n",
        "if CFG.task == 'classification':\n",
        "  print('='*15+'task is classification'+'='*15)\n",
        "  mask, const = get_mask(shape=(100,10),C=CFG.C,specified_number=5)\n",
        "  mask_list.append(mask)\n",
        "  const_list.append(const)\n",
        "\n",
        "\n",
        "print('='*15+'Build model1'+'='*15)\n",
        "if CFG.ini_type == 'A':\n",
        "  print('initialize type A')\n",
        "  set_seed(CFG.seed1)\n",
        "  w_intializer1 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "elif CFG.ini_type == 'B':\n",
        "  print('initialize type B')\n",
        "  set_seed(CFG.seed3)\n",
        "  w_intializer1 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "\n",
        "model1 = create_model(params=model_params, w_initializer=w_intializer1,Mask_list=mask_list ,Const_list=const_list)\n",
        "print(model1.layers[3].get_weights()[0])\n",
        "\"\"\"\n",
        "print('='*15+'Train model1'+'='*15)\n",
        "history1 = model1.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='001')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform001_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history1.history, handle)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ2IH6evFdIH",
        "outputId": "3cf86635-6758-4123-85bb-0330b23344d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 1.1296 - val_accuracy: 0.8433\n",
            "Epoch 588/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 1.1382 - val_accuracy: 0.8427\n",
            "Epoch 589/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 1.1412 - val_accuracy: 0.8423\n",
            "Epoch 590/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 1.1314 - val_accuracy: 0.8420\n",
            "Epoch 591/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 1.1387 - val_accuracy: 0.8423\n",
            "Epoch 592/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 1.1485 - val_accuracy: 0.8423\n",
            "Epoch 593/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 1.1217 - val_accuracy: 0.8426\n",
            "Epoch 594/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 1.1368 - val_accuracy: 0.8440\n",
            "Epoch 595/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 1.1262 - val_accuracy: 0.8431\n",
            "Epoch 596/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 1.1228 - val_accuracy: 0.8442\n",
            "Epoch 597/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 1.1343 - val_accuracy: 0.8425\n",
            "Epoch 598/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 1.1498 - val_accuracy: 0.8448\n",
            "Epoch 599/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 1.1394 - val_accuracy: 0.8431\n",
            "Epoch 600/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 1.1197 - val_accuracy: 0.8460\n",
            "Epoch 601/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 1.1295 - val_accuracy: 0.8421\n",
            "Epoch 602/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1358 - val_accuracy: 0.8448\n",
            "Epoch 603/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 1.1386 - val_accuracy: 0.8456\n",
            "Epoch 604/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 1.1333 - val_accuracy: 0.8431\n",
            "Epoch 605/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 1.1430 - val_accuracy: 0.8430\n",
            "Epoch 606/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 1.1419 - val_accuracy: 0.8423\n",
            "Epoch 607/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 1.1521 - val_accuracy: 0.8433\n",
            "Epoch 608/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 1.1503 - val_accuracy: 0.8456\n",
            "Epoch 609/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 1.1657 - val_accuracy: 0.8462\n",
            "Epoch 610/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 1.1645 - val_accuracy: 0.8432\n",
            "Epoch 611/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 1.1340 - val_accuracy: 0.8469\n",
            "Epoch 612/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 1.1389 - val_accuracy: 0.8466\n",
            "Epoch 613/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 1.1355 - val_accuracy: 0.8452\n",
            "Epoch 614/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 1.1345 - val_accuracy: 0.8449\n",
            "Epoch 615/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 1.1459 - val_accuracy: 0.8465\n",
            "Epoch 616/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 1.1579 - val_accuracy: 0.8420\n",
            "Epoch 617/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 1.1422 - val_accuracy: 0.8449\n",
            "Epoch 618/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 1.1442 - val_accuracy: 0.8463\n",
            "Epoch 619/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 1.1464 - val_accuracy: 0.8434\n",
            "Epoch 620/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 1.1415 - val_accuracy: 0.8419\n",
            "Epoch 621/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 1.1292 - val_accuracy: 0.8461\n",
            "Epoch 622/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 1.1463 - val_accuracy: 0.8430\n",
            "Epoch 623/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 1.1460 - val_accuracy: 0.8455\n",
            "Epoch 624/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 1.1419 - val_accuracy: 0.8458\n",
            "Epoch 625/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.1331 - val_accuracy: 0.8446\n",
            "Epoch 626/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 1.1495 - val_accuracy: 0.8428\n",
            "Epoch 627/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 1.1556 - val_accuracy: 0.8438\n",
            "Epoch 628/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 1.1566 - val_accuracy: 0.8428\n",
            "Epoch 629/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 1.1452 - val_accuracy: 0.8434\n",
            "Epoch 630/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 1.1415 - val_accuracy: 0.8421\n",
            "Epoch 631/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 1.1538 - val_accuracy: 0.8446\n",
            "Epoch 632/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 1.1369 - val_accuracy: 0.8447\n",
            "Epoch 633/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 1.1397 - val_accuracy: 0.8434\n",
            "Epoch 634/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 1.1425 - val_accuracy: 0.8453\n",
            "Epoch 635/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 1.1334 - val_accuracy: 0.8471\n",
            "Epoch 636/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 1.1341 - val_accuracy: 0.8444\n",
            "Epoch 637/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 1.1511 - val_accuracy: 0.8457\n",
            "Epoch 638/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 1.1433 - val_accuracy: 0.8459\n",
            "Epoch 639/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 1.1588 - val_accuracy: 0.8441\n",
            "Epoch 640/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 1.1557 - val_accuracy: 0.8438\n",
            "Epoch 641/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 1.1500 - val_accuracy: 0.8446\n",
            "Epoch 642/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 1.1637 - val_accuracy: 0.8444\n",
            "Epoch 643/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 1.1598 - val_accuracy: 0.8430\n",
            "Epoch 644/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 1.1388 - val_accuracy: 0.8483\n",
            "Epoch 645/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 1.1428 - val_accuracy: 0.8462\n",
            "Epoch 646/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 1.1402 - val_accuracy: 0.8435\n",
            "Epoch 647/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 1.1461 - val_accuracy: 0.8456\n",
            "Epoch 648/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1350 - val_accuracy: 0.8452\n",
            "Epoch 649/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0219 - accuracy: 0.9923 - val_loss: 1.1542 - val_accuracy: 0.8444\n",
            "Epoch 650/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0227 - accuracy: 0.9918 - val_loss: 1.1579 - val_accuracy: 0.8441\n",
            "Epoch 651/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 1.1470 - val_accuracy: 0.8465\n",
            "Epoch 652/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 1.1639 - val_accuracy: 0.8454\n",
            "Epoch 653/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 1.1557 - val_accuracy: 0.8448\n",
            "Epoch 654/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 1.1644 - val_accuracy: 0.8419\n",
            "Epoch 655/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 1.1562 - val_accuracy: 0.8426\n",
            "Epoch 656/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 1.1630 - val_accuracy: 0.8429\n",
            "Epoch 657/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 1.1611 - val_accuracy: 0.8444\n",
            "Epoch 658/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 1.1688 - val_accuracy: 0.8449\n",
            "Epoch 659/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 1.1611 - val_accuracy: 0.8441\n",
            "Epoch 660/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 1.1659 - val_accuracy: 0.8470\n",
            "Epoch 661/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 1.1490 - val_accuracy: 0.8430\n",
            "Epoch 662/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 1.1562 - val_accuracy: 0.8450\n",
            "Epoch 663/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 1.1560 - val_accuracy: 0.8444\n",
            "Epoch 664/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 1.1415 - val_accuracy: 0.8419\n",
            "Epoch 665/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 1.1627 - val_accuracy: 0.8443\n",
            "Epoch 666/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 1.1591 - val_accuracy: 0.8477\n",
            "Epoch 667/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 1.1600 - val_accuracy: 0.8458\n",
            "Epoch 668/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 1.1423 - val_accuracy: 0.8440\n",
            "Epoch 669/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 1.1358 - val_accuracy: 0.8453\n",
            "Epoch 670/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1528 - val_accuracy: 0.8449\n",
            "Epoch 671/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 1.1598 - val_accuracy: 0.8450\n",
            "Epoch 672/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 1.1695 - val_accuracy: 0.8475\n",
            "Epoch 673/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 1.1547 - val_accuracy: 0.8462\n",
            "Epoch 674/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 1.1666 - val_accuracy: 0.8480\n",
            "Epoch 675/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 1.1642 - val_accuracy: 0.8450\n",
            "Epoch 676/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 1.1760 - val_accuracy: 0.8460\n",
            "Epoch 677/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 1.1636 - val_accuracy: 0.8459\n",
            "Epoch 678/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 1.1683 - val_accuracy: 0.8461\n",
            "Epoch 679/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 1.1678 - val_accuracy: 0.8442\n",
            "Epoch 680/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 1.1867 - val_accuracy: 0.8464\n",
            "Epoch 681/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 1.1805 - val_accuracy: 0.8436\n",
            "Epoch 682/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 1.1665 - val_accuracy: 0.8443\n",
            "Epoch 683/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.1521 - val_accuracy: 0.8433\n",
            "Epoch 684/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 1.1540 - val_accuracy: 0.8445\n",
            "Epoch 685/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 1.1704 - val_accuracy: 0.8465\n",
            "Epoch 686/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 1.1870 - val_accuracy: 0.8461\n",
            "Epoch 687/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 1.1741 - val_accuracy: 0.8445\n",
            "Epoch 688/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 1.1829 - val_accuracy: 0.8444\n",
            "Epoch 689/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 1.1845 - val_accuracy: 0.8438\n",
            "Epoch 690/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 1.1866 - val_accuracy: 0.8446\n",
            "Epoch 691/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 1.1780 - val_accuracy: 0.8419\n",
            "Epoch 692/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.1697 - val_accuracy: 0.8446\n",
            "Epoch 693/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1772 - val_accuracy: 0.8456\n",
            "Epoch 694/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 1.1813 - val_accuracy: 0.8437\n",
            "Epoch 695/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.1689 - val_accuracy: 0.8434\n",
            "Epoch 696/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 1.1954 - val_accuracy: 0.8442\n",
            "Epoch 697/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 1.1961 - val_accuracy: 0.8456\n",
            "Epoch 698/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 1.1805 - val_accuracy: 0.8451\n",
            "Epoch 699/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 1.1825 - val_accuracy: 0.8417\n",
            "Epoch 700/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 1.1860 - val_accuracy: 0.8437\n",
            "Epoch 701/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 1.1941 - val_accuracy: 0.8452\n",
            "Epoch 702/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 1.1942 - val_accuracy: 0.8450\n",
            "Epoch 703/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 1.1860 - val_accuracy: 0.8448\n",
            "Epoch 704/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 1.1875 - val_accuracy: 0.8439\n",
            "Epoch 705/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 1.1706 - val_accuracy: 0.8433\n",
            "Epoch 706/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 1.1815 - val_accuracy: 0.8452\n",
            "Epoch 707/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 1.1718 - val_accuracy: 0.8439\n",
            "Epoch 708/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 1.1622 - val_accuracy: 0.8452\n",
            "Epoch 709/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 1.1811 - val_accuracy: 0.8452\n",
            "Epoch 710/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 1.1837 - val_accuracy: 0.8471\n",
            "Epoch 711/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 1.1760 - val_accuracy: 0.8463\n",
            "Epoch 712/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.1649 - val_accuracy: 0.8466\n",
            "Epoch 713/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 1.1748 - val_accuracy: 0.8467\n",
            "Epoch 714/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 1.1664 - val_accuracy: 0.8456\n",
            "Epoch 715/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 1.1797 - val_accuracy: 0.8471\n",
            "Epoch 716/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 1.1737 - val_accuracy: 0.8459\n",
            "Epoch 717/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.1799 - val_accuracy: 0.8455\n",
            "Epoch 718/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 1.1745 - val_accuracy: 0.8445\n",
            "Epoch 719/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 1.1803 - val_accuracy: 0.8442\n",
            "Epoch 720/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 1.1756 - val_accuracy: 0.8442\n",
            "Epoch 721/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 1.1764 - val_accuracy: 0.8461\n",
            "Epoch 722/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.1870 - val_accuracy: 0.8466\n",
            "Epoch 723/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 1.1896 - val_accuracy: 0.8438\n",
            "Epoch 724/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.1762 - val_accuracy: 0.8444\n",
            "Epoch 725/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 1.1794 - val_accuracy: 0.8439\n",
            "Epoch 726/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 1.1727 - val_accuracy: 0.8457\n",
            "Epoch 727/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 1.1786 - val_accuracy: 0.8425\n",
            "Epoch 728/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 1.1866 - val_accuracy: 0.8469\n",
            "Epoch 729/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 1.1705 - val_accuracy: 0.8479\n",
            "Epoch 730/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 1.1704 - val_accuracy: 0.8455\n",
            "Epoch 731/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 1.1576 - val_accuracy: 0.8469\n",
            "Epoch 732/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 1.1673 - val_accuracy: 0.8457\n",
            "Epoch 733/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.1642 - val_accuracy: 0.8447\n",
            "Epoch 734/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 1.1773 - val_accuracy: 0.8432\n",
            "Epoch 735/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 1.1673 - val_accuracy: 0.8463\n",
            "Epoch 736/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 1.1856 - val_accuracy: 0.8445\n",
            "Epoch 737/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 1.1974 - val_accuracy: 0.8435\n",
            "Epoch 738/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 1.1880 - val_accuracy: 0.8469\n",
            "Epoch 739/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 1.1786 - val_accuracy: 0.8478\n",
            "Epoch 740/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.1877 - val_accuracy: 0.8470\n",
            "Epoch 741/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 1.1863 - val_accuracy: 0.8447\n",
            "Epoch 742/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 1.1844 - val_accuracy: 0.8423\n",
            "Epoch 743/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 1.1791 - val_accuracy: 0.8441\n",
            "Epoch 744/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 1.1731 - val_accuracy: 0.8443\n",
            "Epoch 745/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 1.1690 - val_accuracy: 0.8460\n",
            "Epoch 746/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 1.1700 - val_accuracy: 0.8457\n",
            "Epoch 747/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.1786 - val_accuracy: 0.8455\n",
            "Epoch 748/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 1.1792 - val_accuracy: 0.8461\n",
            "Epoch 749/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 1.1833 - val_accuracy: 0.8438\n",
            "Epoch 750/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 1.1844 - val_accuracy: 0.8424\n",
            "Epoch 751/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.1741 - val_accuracy: 0.8456\n",
            "Epoch 752/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 1.1833 - val_accuracy: 0.8448\n",
            "Epoch 753/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.1907 - val_accuracy: 0.8429\n",
            "Epoch 754/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 1.2070 - val_accuracy: 0.8445\n",
            "Epoch 755/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 1.1958 - val_accuracy: 0.8441\n",
            "Epoch 756/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 1.1891 - val_accuracy: 0.8443\n",
            "Epoch 757/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.1878 - val_accuracy: 0.8454\n",
            "Epoch 758/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 1.1762 - val_accuracy: 0.8476\n",
            "Epoch 759/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 1.1708 - val_accuracy: 0.8457\n",
            "Epoch 760/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 1.1847 - val_accuracy: 0.8452\n",
            "Epoch 761/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.1923 - val_accuracy: 0.8472\n",
            "Epoch 762/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 1.1918 - val_accuracy: 0.8472\n",
            "Epoch 763/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.1953 - val_accuracy: 0.8468\n",
            "Epoch 764/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 1.1790 - val_accuracy: 0.8437\n",
            "Epoch 765/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 1.1759 - val_accuracy: 0.8435\n",
            "Epoch 766/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 1.1835 - val_accuracy: 0.8457\n",
            "Epoch 767/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.2001 - val_accuracy: 0.8452\n",
            "Epoch 768/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 1.1799 - val_accuracy: 0.8483\n",
            "Epoch 769/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 1.2074 - val_accuracy: 0.8461\n",
            "Epoch 770/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 1.1906 - val_accuracy: 0.8483\n",
            "Epoch 771/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.1808 - val_accuracy: 0.8457\n",
            "Epoch 772/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.1926 - val_accuracy: 0.8457\n",
            "Epoch 773/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 1.1966 - val_accuracy: 0.8454\n",
            "Epoch 774/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.1794 - val_accuracy: 0.8478\n",
            "Epoch 775/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.1890 - val_accuracy: 0.8480\n",
            "Epoch 776/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 1.1722 - val_accuracy: 0.8489\n",
            "Epoch 777/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 1.1854 - val_accuracy: 0.8480\n",
            "Epoch 778/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 1.1578 - val_accuracy: 0.8475\n",
            "Epoch 779/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 1.1839 - val_accuracy: 0.8483\n",
            "Epoch 780/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 1.1799 - val_accuracy: 0.8467\n",
            "Epoch 781/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 1.1861 - val_accuracy: 0.8442\n",
            "Epoch 782/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.1685 - val_accuracy: 0.8483\n",
            "Epoch 783/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 1.1929 - val_accuracy: 0.8466\n",
            "Epoch 784/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 1.1909 - val_accuracy: 0.8468\n",
            "Epoch 785/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.1838 - val_accuracy: 0.8464\n",
            "Epoch 786/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 1.2048 - val_accuracy: 0.8451\n",
            "Epoch 787/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 1.1891 - val_accuracy: 0.8475\n",
            "Epoch 788/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.1837 - val_accuracy: 0.8439\n",
            "Epoch 789/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.1878 - val_accuracy: 0.8453\n",
            "Epoch 790/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 1.1881 - val_accuracy: 0.8458\n",
            "Epoch 791/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 1.1858 - val_accuracy: 0.8469\n",
            "Epoch 792/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 1.1747 - val_accuracy: 0.8468\n",
            "Epoch 793/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 1.1725 - val_accuracy: 0.8464\n",
            "Epoch 794/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.1813 - val_accuracy: 0.8460\n",
            "Epoch 795/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 1.1723 - val_accuracy: 0.8467\n",
            "Epoch 796/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 1.1826 - val_accuracy: 0.8450\n",
            "Epoch 797/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 1.1807 - val_accuracy: 0.8441\n",
            "Epoch 798/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 1.1655 - val_accuracy: 0.8480\n",
            "Epoch 799/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 1.1781 - val_accuracy: 0.8467\n",
            "Epoch 800/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 1.1838 - val_accuracy: 0.8458\n",
            "Epoch 801/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 1.1953 - val_accuracy: 0.8466\n",
            "Epoch 802/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 1.1899 - val_accuracy: 0.8463\n",
            "Epoch 803/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 1.1914 - val_accuracy: 0.8454\n",
            "Epoch 804/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.1929 - val_accuracy: 0.8456\n",
            "Epoch 805/3000\n",
            "235/235 [==============================] - 5s 15ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 1.2025 - val_accuracy: 0.8471\n",
            "Epoch 806/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 1.1843 - val_accuracy: 0.8489\n",
            "Epoch 807/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 1.1964 - val_accuracy: 0.8463\n",
            "Epoch 808/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 1.1837 - val_accuracy: 0.8450\n",
            "Epoch 809/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 1.1825 - val_accuracy: 0.8450\n",
            "Epoch 810/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 1.1960 - val_accuracy: 0.8471\n",
            "Epoch 811/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 1.2012 - val_accuracy: 0.8463\n",
            "Epoch 812/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.2022 - val_accuracy: 0.8457\n",
            "Epoch 813/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 1.2033 - val_accuracy: 0.8452\n",
            "Epoch 814/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 1.2024 - val_accuracy: 0.8463\n",
            "Epoch 815/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 1.2060 - val_accuracy: 0.8452\n",
            "Epoch 816/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.2018 - val_accuracy: 0.8462\n",
            "Epoch 817/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 1.1831 - val_accuracy: 0.8441\n",
            "Epoch 818/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 1.1892 - val_accuracy: 0.8430\n",
            "Epoch 819/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 1.2171 - val_accuracy: 0.8450\n",
            "Epoch 820/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 1.1954 - val_accuracy: 0.8445\n",
            "Epoch 821/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 1.1873 - val_accuracy: 0.8484\n",
            "Epoch 822/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 1.1758 - val_accuracy: 0.8478\n",
            "Epoch 823/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.1940 - val_accuracy: 0.8455\n",
            "Epoch 824/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.1922 - val_accuracy: 0.8467\n",
            "Epoch 825/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 1.1920 - val_accuracy: 0.8467\n",
            "Epoch 826/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.1886 - val_accuracy: 0.8449\n",
            "Epoch 827/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 1.2009 - val_accuracy: 0.8502\n",
            "Epoch 828/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 1.2106 - val_accuracy: 0.8441\n",
            "Epoch 829/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 1.1910 - val_accuracy: 0.8448\n",
            "Epoch 830/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 1.1905 - val_accuracy: 0.8458\n",
            "Epoch 831/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 1.2012 - val_accuracy: 0.8462\n",
            "Epoch 832/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.2027 - val_accuracy: 0.8484\n",
            "Epoch 833/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 1.2065 - val_accuracy: 0.8453\n",
            "Epoch 834/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 1.1937 - val_accuracy: 0.8478\n",
            "Epoch 835/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 1.1930 - val_accuracy: 0.8471\n",
            "Epoch 836/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 1.2001 - val_accuracy: 0.8458\n",
            "Epoch 837/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 1.2018 - val_accuracy: 0.8460\n",
            "Epoch 838/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.2052 - val_accuracy: 0.8451\n",
            "Epoch 839/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 1.2090 - val_accuracy: 0.8438\n",
            "Epoch 840/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.1985 - val_accuracy: 0.8430\n",
            "Epoch 841/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.1995 - val_accuracy: 0.8472\n",
            "Epoch 842/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 1.1862 - val_accuracy: 0.8475\n",
            "Epoch 843/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 1.2094 - val_accuracy: 0.8456\n",
            "Epoch 844/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.2126 - val_accuracy: 0.8433\n",
            "Epoch 845/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 1.2059 - val_accuracy: 0.8459\n",
            "Epoch 846/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 1.1946 - val_accuracy: 0.8451\n",
            "Epoch 847/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 1.2066 - val_accuracy: 0.8449\n",
            "Epoch 848/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 1.1956 - val_accuracy: 0.8449\n",
            "Epoch 849/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 1.2102 - val_accuracy: 0.8481\n",
            "Epoch 850/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 1.2108 - val_accuracy: 0.8444\n",
            "Epoch 851/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 1.2104 - val_accuracy: 0.8447\n",
            "Epoch 852/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 1.1930 - val_accuracy: 0.8450\n",
            "Epoch 853/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.1945 - val_accuracy: 0.8484\n",
            "Epoch 854/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 1.1865 - val_accuracy: 0.8483\n",
            "Epoch 855/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 1.1940 - val_accuracy: 0.8459\n",
            "Epoch 856/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 1.2003 - val_accuracy: 0.8465\n",
            "Epoch 857/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 1.1912 - val_accuracy: 0.8470\n",
            "Epoch 858/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 1.1957 - val_accuracy: 0.8450\n",
            "Epoch 859/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 1.1974 - val_accuracy: 0.8472\n",
            "Epoch 860/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.1795 - val_accuracy: 0.8446\n",
            "Epoch 861/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 1.2059 - val_accuracy: 0.8466\n",
            "Epoch 862/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 1.1919 - val_accuracy: 0.8430\n",
            "Epoch 863/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 1.2041 - val_accuracy: 0.8455\n",
            "Epoch 864/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 1.1977 - val_accuracy: 0.8457\n",
            "Epoch 865/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.1863 - val_accuracy: 0.8460\n",
            "Epoch 866/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.2020 - val_accuracy: 0.8436\n",
            "Epoch 867/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 1.2066 - val_accuracy: 0.8459\n",
            "Epoch 868/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.2217 - val_accuracy: 0.8468\n",
            "Epoch 869/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 1.2213 - val_accuracy: 0.8465\n",
            "Epoch 870/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 1.2099 - val_accuracy: 0.8469\n",
            "Epoch 871/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 1.2207 - val_accuracy: 0.8456\n",
            "Epoch 872/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 1.2189 - val_accuracy: 0.8471\n",
            "Epoch 873/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 1.2127 - val_accuracy: 0.8468\n",
            "Epoch 874/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 1.2011 - val_accuracy: 0.8486\n",
            "Epoch 875/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.2134 - val_accuracy: 0.8458\n",
            "Epoch 876/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.2196 - val_accuracy: 0.8455\n",
            "Epoch 877/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 1.2271 - val_accuracy: 0.8463\n",
            "Epoch 878/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 1.2225 - val_accuracy: 0.8469\n",
            "Epoch 879/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 1.2119 - val_accuracy: 0.8451\n",
            "Epoch 880/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 1.2200 - val_accuracy: 0.8448\n",
            "Epoch 881/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 1.2200 - val_accuracy: 0.8435\n",
            "Epoch 882/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.2233 - val_accuracy: 0.8464\n",
            "Epoch 883/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 1.2078 - val_accuracy: 0.8484\n",
            "Epoch 884/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 1.2124 - val_accuracy: 0.8485\n",
            "Epoch 885/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 1.2100 - val_accuracy: 0.8456\n",
            "Epoch 886/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.2117 - val_accuracy: 0.8443\n",
            "Epoch 887/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 1.2187 - val_accuracy: 0.8460\n",
            "Epoch 888/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 1.2207 - val_accuracy: 0.8441\n",
            "Epoch 889/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.2183 - val_accuracy: 0.8461\n",
            "Epoch 890/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 1.2249 - val_accuracy: 0.8448\n",
            "Epoch 891/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.2283 - val_accuracy: 0.8438\n",
            "Epoch 892/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.2241 - val_accuracy: 0.8460\n",
            "Epoch 893/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.2115 - val_accuracy: 0.8459\n",
            "Epoch 894/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 1.2098 - val_accuracy: 0.8475\n",
            "Epoch 895/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 1.2269 - val_accuracy: 0.8461\n",
            "Epoch 896/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 1.2199 - val_accuracy: 0.8478\n",
            "Epoch 897/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 1.2278 - val_accuracy: 0.8485\n",
            "Epoch 898/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 1.2139 - val_accuracy: 0.8465\n",
            "Epoch 899/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 1.2266 - val_accuracy: 0.8469\n",
            "Epoch 900/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 1.2091 - val_accuracy: 0.8472\n",
            "Epoch 901/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2219 - val_accuracy: 0.8468\n",
            "Epoch 902/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 1.2107 - val_accuracy: 0.8452\n",
            "Epoch 903/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 1.2127 - val_accuracy: 0.8473\n",
            "Epoch 904/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 1.2224 - val_accuracy: 0.8473\n",
            "Epoch 905/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 1.2069 - val_accuracy: 0.8476\n",
            "Epoch 906/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 1.1822 - val_accuracy: 0.8490\n",
            "Epoch 907/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 1.1963 - val_accuracy: 0.8447\n",
            "Epoch 908/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 1.2153 - val_accuracy: 0.8454\n",
            "Epoch 909/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 1.2229 - val_accuracy: 0.8450\n",
            "Epoch 910/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 1.2348 - val_accuracy: 0.8470\n",
            "Epoch 911/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.2047 - val_accuracy: 0.8457\n",
            "Epoch 912/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 1.2170 - val_accuracy: 0.8481\n",
            "Epoch 913/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 1.1982 - val_accuracy: 0.8463\n",
            "Epoch 914/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 1.2021 - val_accuracy: 0.8473\n",
            "Epoch 915/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 1.2044 - val_accuracy: 0.8477\n",
            "Epoch 916/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 1.1958 - val_accuracy: 0.8468\n",
            "Epoch 917/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 1.2041 - val_accuracy: 0.8450\n",
            "Epoch 918/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 1.2156 - val_accuracy: 0.8475\n",
            "Epoch 919/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 1.2138 - val_accuracy: 0.8463\n",
            "Epoch 920/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0162 - accuracy: 0.9941 - val_loss: 1.2244 - val_accuracy: 0.8454\n",
            "Epoch 921/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 1.2201 - val_accuracy: 0.8460\n",
            "Epoch 922/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 1.2019 - val_accuracy: 0.8475\n",
            "Epoch 923/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 1.2085 - val_accuracy: 0.8476\n",
            "Epoch 924/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 1.2170 - val_accuracy: 0.8464\n",
            "Epoch 925/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.2043 - val_accuracy: 0.8458\n",
            "Epoch 926/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.2030 - val_accuracy: 0.8485\n",
            "Epoch 927/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.1965 - val_accuracy: 0.8476\n",
            "Epoch 928/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 1.2062 - val_accuracy: 0.8467\n",
            "Epoch 929/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 1.2326 - val_accuracy: 0.8458\n",
            "Epoch 930/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 1.2333 - val_accuracy: 0.8464\n",
            "Epoch 931/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 1.2093 - val_accuracy: 0.8459\n",
            "Epoch 932/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 1.2158 - val_accuracy: 0.8470\n",
            "Epoch 933/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.2309 - val_accuracy: 0.8460\n",
            "Epoch 934/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 1.2233 - val_accuracy: 0.8461\n",
            "Epoch 935/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 1.2125 - val_accuracy: 0.8473\n",
            "Epoch 936/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 1.2163 - val_accuracy: 0.8478\n",
            "Epoch 937/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.2292 - val_accuracy: 0.8474\n",
            "Epoch 938/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 1.2167 - val_accuracy: 0.8456\n",
            "Epoch 939/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 1.1994 - val_accuracy: 0.8480\n",
            "Epoch 940/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 1.1979 - val_accuracy: 0.8491\n",
            "Epoch 941/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 1.1831 - val_accuracy: 0.8490\n",
            "Epoch 942/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 1.1936 - val_accuracy: 0.8457\n",
            "Epoch 943/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 1.2077 - val_accuracy: 0.8468\n",
            "Epoch 944/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 1.2198 - val_accuracy: 0.8477\n",
            "Epoch 945/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 1.2158 - val_accuracy: 0.8469\n",
            "Epoch 946/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 1.2366 - val_accuracy: 0.8457\n",
            "Epoch 947/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 1.2319 - val_accuracy: 0.8455\n",
            "Epoch 948/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 1.2361 - val_accuracy: 0.8470\n",
            "Epoch 949/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 1.2231 - val_accuracy: 0.8480\n",
            "Epoch 950/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 1.2093 - val_accuracy: 0.8481\n",
            "Epoch 951/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 1.2020 - val_accuracy: 0.8482\n",
            "Epoch 952/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2136 - val_accuracy: 0.8471\n",
            "Epoch 953/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 1.2250 - val_accuracy: 0.8462\n",
            "Epoch 954/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.2260 - val_accuracy: 0.8467\n",
            "Epoch 955/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 1.2357 - val_accuracy: 0.8491\n",
            "Epoch 956/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 1.2376 - val_accuracy: 0.8477\n",
            "Epoch 957/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.2320 - val_accuracy: 0.8479\n",
            "Epoch 958/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 1.2317 - val_accuracy: 0.8491\n",
            "Epoch 959/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 1.2083 - val_accuracy: 0.8488\n",
            "Epoch 960/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.2081 - val_accuracy: 0.8476\n",
            "Epoch 961/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 1.2243 - val_accuracy: 0.8465\n",
            "Epoch 962/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 1.2179 - val_accuracy: 0.8472\n",
            "Epoch 963/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 1.2280 - val_accuracy: 0.8476\n",
            "Epoch 964/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 1.2289 - val_accuracy: 0.8486\n",
            "Epoch 965/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 1.1997 - val_accuracy: 0.8495\n",
            "Epoch 966/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 1.2084 - val_accuracy: 0.8454\n",
            "Epoch 967/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 1.2098 - val_accuracy: 0.8441\n",
            "Epoch 968/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2079 - val_accuracy: 0.8475\n",
            "Epoch 969/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2011 - val_accuracy: 0.8479\n",
            "Epoch 970/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2116 - val_accuracy: 0.8466\n",
            "Epoch 971/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.2159 - val_accuracy: 0.8442\n",
            "Epoch 972/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 1.2162 - val_accuracy: 0.8477\n",
            "Epoch 973/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 1.2145 - val_accuracy: 0.8484\n",
            "Epoch 974/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 1.2079 - val_accuracy: 0.8465\n",
            "Epoch 975/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 1.2069 - val_accuracy: 0.8483\n",
            "Epoch 976/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 1.2174 - val_accuracy: 0.8467\n",
            "Epoch 977/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.2075 - val_accuracy: 0.8470\n",
            "Epoch 978/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 1.2023 - val_accuracy: 0.8483\n",
            "Epoch 979/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.2041 - val_accuracy: 0.8467\n",
            "Epoch 980/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 1.2289 - val_accuracy: 0.8475\n",
            "Epoch 981/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 1.2135 - val_accuracy: 0.8454\n",
            "Epoch 982/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 1.2143 - val_accuracy: 0.8447\n",
            "Epoch 983/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.2121 - val_accuracy: 0.8474\n",
            "Epoch 984/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 1.2175 - val_accuracy: 0.8461\n",
            "Epoch 985/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.2238 - val_accuracy: 0.8470\n",
            "Epoch 986/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 1.2180 - val_accuracy: 0.8464\n",
            "Epoch 987/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 1.2210 - val_accuracy: 0.8457\n",
            "Epoch 988/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.2259 - val_accuracy: 0.8485\n",
            "Epoch 989/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 1.2148 - val_accuracy: 0.8471\n",
            "Epoch 990/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.2321 - val_accuracy: 0.8465\n",
            "Epoch 991/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.2377 - val_accuracy: 0.8474\n",
            "Epoch 992/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 1.2206 - val_accuracy: 0.8461\n",
            "Epoch 993/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0187 - accuracy: 0.9934 - val_loss: 1.2187 - val_accuracy: 0.8456\n",
            "Epoch 994/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 1.2242 - val_accuracy: 0.8439\n",
            "Epoch 995/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.2120 - val_accuracy: 0.8456\n",
            "Epoch 996/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 1.2384 - val_accuracy: 0.8464\n",
            "Epoch 997/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 1.2246 - val_accuracy: 0.8448\n",
            "Epoch 998/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.2257 - val_accuracy: 0.8481\n",
            "Epoch 999/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.2113 - val_accuracy: 0.8472\n",
            "Epoch 1000/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 1.2084 - val_accuracy: 0.8467\n",
            "Epoch 1001/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 1.2126 - val_accuracy: 0.8471\n",
            "Epoch 1002/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 1.2163 - val_accuracy: 0.8459\n",
            "Epoch 1003/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.2300 - val_accuracy: 0.8490\n",
            "Epoch 1004/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.2305 - val_accuracy: 0.8493\n",
            "Epoch 1005/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2235 - val_accuracy: 0.8506\n",
            "Epoch 1006/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.2187 - val_accuracy: 0.8490\n",
            "Epoch 1007/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.2137 - val_accuracy: 0.8482\n",
            "Epoch 1008/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 1.2180 - val_accuracy: 0.8476\n",
            "Epoch 1009/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.2150 - val_accuracy: 0.8453\n",
            "Epoch 1010/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.2086 - val_accuracy: 0.8467\n",
            "Epoch 1011/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.2098 - val_accuracy: 0.8477\n",
            "Epoch 1012/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 1.2339 - val_accuracy: 0.8478\n",
            "Epoch 1013/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 1.2262 - val_accuracy: 0.8454\n",
            "Epoch 1014/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 1.2202 - val_accuracy: 0.8496\n",
            "Epoch 1015/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.2128 - val_accuracy: 0.8467\n",
            "Epoch 1016/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 1.2091 - val_accuracy: 0.8485\n",
            "Epoch 1017/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 1.2080 - val_accuracy: 0.8460\n",
            "Epoch 1018/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 1.2124 - val_accuracy: 0.8491\n",
            "Epoch 1019/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2082 - val_accuracy: 0.8469\n",
            "Epoch 1020/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 1.2062 - val_accuracy: 0.8445\n",
            "Epoch 1021/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 1.2376 - val_accuracy: 0.8452\n",
            "Epoch 1022/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 1.2229 - val_accuracy: 0.8452\n",
            "Epoch 1023/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.2343 - val_accuracy: 0.8468\n",
            "Epoch 1024/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 1.2430 - val_accuracy: 0.8473\n",
            "Epoch 1025/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.2456 - val_accuracy: 0.8502\n",
            "Epoch 1026/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.2327 - val_accuracy: 0.8460\n",
            "Epoch 1027/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 1.2199 - val_accuracy: 0.8470\n",
            "Epoch 1028/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 1.2307 - val_accuracy: 0.8442\n",
            "Epoch 1029/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.2561 - val_accuracy: 0.8464\n",
            "Epoch 1030/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 1.2316 - val_accuracy: 0.8460\n",
            "Epoch 1031/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 1.2326 - val_accuracy: 0.8459\n",
            "Epoch 1032/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 1.2366 - val_accuracy: 0.8438\n",
            "Epoch 1033/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 1.2196 - val_accuracy: 0.8450\n",
            "Epoch 1034/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 1.2201 - val_accuracy: 0.8452\n",
            "Epoch 1035/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 1.2442 - val_accuracy: 0.8467\n",
            "Epoch 1036/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 1.2291 - val_accuracy: 0.8468\n",
            "Epoch 1037/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 1.2299 - val_accuracy: 0.8433\n",
            "Epoch 1038/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 1.2323 - val_accuracy: 0.8465\n",
            "Epoch 1039/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 1.2336 - val_accuracy: 0.8452\n",
            "Epoch 1040/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 1.2354 - val_accuracy: 0.8469\n",
            "Epoch 1041/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 1.2289 - val_accuracy: 0.8468\n",
            "Epoch 1042/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.2371 - val_accuracy: 0.8475\n",
            "Epoch 1043/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 1.2411 - val_accuracy: 0.8458\n",
            "Epoch 1044/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 1.2371 - val_accuracy: 0.8480\n",
            "Epoch 1045/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 1.2329 - val_accuracy: 0.8473\n",
            "Epoch 1046/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 1.2572 - val_accuracy: 0.8434\n",
            "Epoch 1047/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 1.2424 - val_accuracy: 0.8465\n",
            "Epoch 1048/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 1.2388 - val_accuracy: 0.8457\n",
            "Epoch 1049/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2473 - val_accuracy: 0.8479\n",
            "Epoch 1050/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 1.2306 - val_accuracy: 0.8486\n",
            "Epoch 1051/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 1.2501 - val_accuracy: 0.8474\n",
            "Epoch 1052/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2430 - val_accuracy: 0.8452\n",
            "Epoch 1053/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 1.2500 - val_accuracy: 0.8469\n",
            "Epoch 1054/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 1.2239 - val_accuracy: 0.8464\n",
            "Epoch 1055/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 1.2392 - val_accuracy: 0.8478\n",
            "Epoch 1056/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 1.2496 - val_accuracy: 0.8471\n",
            "Epoch 1057/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.2374 - val_accuracy: 0.8458\n",
            "Epoch 1058/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 1.2362 - val_accuracy: 0.8469\n",
            "Epoch 1059/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.2436 - val_accuracy: 0.8453\n",
            "Epoch 1060/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 1.2319 - val_accuracy: 0.8438\n",
            "Epoch 1061/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 1.2200 - val_accuracy: 0.8468\n",
            "Epoch 1062/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 1.2301 - val_accuracy: 0.8454\n",
            "Epoch 1063/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 1.2431 - val_accuracy: 0.8476\n",
            "Epoch 1064/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 1.2304 - val_accuracy: 0.8481\n",
            "Epoch 1065/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 1.2246 - val_accuracy: 0.8469\n",
            "Epoch 1066/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 1.2238 - val_accuracy: 0.8476\n",
            "Epoch 1067/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 1.2297 - val_accuracy: 0.8448\n",
            "Epoch 1068/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 1.2146 - val_accuracy: 0.8477\n",
            "Epoch 1069/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 1.2274 - val_accuracy: 0.8461\n",
            "Epoch 1070/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2365 - val_accuracy: 0.8493\n",
            "Epoch 1071/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.2342 - val_accuracy: 0.8471\n",
            "Epoch 1072/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 1.2451 - val_accuracy: 0.8462\n",
            "Epoch 1073/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 1.2231 - val_accuracy: 0.8468\n",
            "Epoch 1074/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 1.2343 - val_accuracy: 0.8462\n",
            "Epoch 1075/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 1.2316 - val_accuracy: 0.8462\n",
            "Epoch 1076/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 1.2377 - val_accuracy: 0.8445\n",
            "Epoch 1077/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.2382 - val_accuracy: 0.8471\n",
            "Epoch 1078/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 1.2301 - val_accuracy: 0.8472\n",
            "Epoch 1079/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 1.2114 - val_accuracy: 0.8461\n",
            "Epoch 1080/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 1.2273 - val_accuracy: 0.8443\n",
            "Epoch 1081/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 1.2268 - val_accuracy: 0.8475\n",
            "Epoch 1082/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.2429 - val_accuracy: 0.8469\n",
            "Epoch 1083/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 1.2391 - val_accuracy: 0.8467\n",
            "Epoch 1084/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.2391 - val_accuracy: 0.8466\n",
            "Epoch 1085/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 1.2576 - val_accuracy: 0.8468\n",
            "Epoch 1086/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 1.2590 - val_accuracy: 0.8474\n",
            "Epoch 1087/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 1.2480 - val_accuracy: 0.8464\n",
            "Epoch 1088/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 1.2522 - val_accuracy: 0.8451\n",
            "Epoch 1089/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.2440 - val_accuracy: 0.8475\n",
            "Epoch 1090/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.2503 - val_accuracy: 0.8451\n",
            "Epoch 1091/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.2614 - val_accuracy: 0.8440\n",
            "Epoch 1092/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.2342 - val_accuracy: 0.8443\n",
            "Epoch 1093/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.2454 - val_accuracy: 0.8450\n",
            "Epoch 1094/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 1.2363 - val_accuracy: 0.8481\n",
            "Epoch 1095/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 1.2537 - val_accuracy: 0.8455\n",
            "Epoch 1096/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 1.2567 - val_accuracy: 0.8486\n",
            "Epoch 1097/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 1.2478 - val_accuracy: 0.8456\n",
            "Epoch 1098/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 1.2483 - val_accuracy: 0.8489\n",
            "Epoch 1099/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 1.2439 - val_accuracy: 0.8478\n",
            "Epoch 1100/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.2463 - val_accuracy: 0.8479\n",
            "Epoch 1101/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 1.2460 - val_accuracy: 0.8475\n",
            "Epoch 1102/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 1.2462 - val_accuracy: 0.8458\n",
            "Epoch 1103/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.2648 - val_accuracy: 0.8482\n",
            "Epoch 1104/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 1.2439 - val_accuracy: 0.8479\n",
            "Epoch 1105/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 1.2421 - val_accuracy: 0.8462\n",
            "Epoch 1106/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 1.2488 - val_accuracy: 0.8488\n",
            "Epoch 1107/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 1.2527 - val_accuracy: 0.8483\n",
            "Epoch 1108/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 1.2353 - val_accuracy: 0.8478\n",
            "Epoch 1109/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2357 - val_accuracy: 0.8497\n",
            "Epoch 1110/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 1.2421 - val_accuracy: 0.8497\n",
            "Epoch 1111/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 1.2462 - val_accuracy: 0.8495\n",
            "Epoch 1112/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.2416 - val_accuracy: 0.8467\n",
            "Epoch 1113/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.2664 - val_accuracy: 0.8471\n",
            "Epoch 1114/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 1.2638 - val_accuracy: 0.8481\n",
            "Epoch 1115/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.2579 - val_accuracy: 0.8443\n",
            "Epoch 1116/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.2367 - val_accuracy: 0.8452\n",
            "Epoch 1117/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2499 - val_accuracy: 0.8481\n",
            "Epoch 1118/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.2463 - val_accuracy: 0.8473\n",
            "Epoch 1119/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.2150 - val_accuracy: 0.8486\n",
            "Epoch 1120/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 1.2159 - val_accuracy: 0.8463\n",
            "Epoch 1121/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 1.2213 - val_accuracy: 0.8467\n",
            "Epoch 1122/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 1.2299 - val_accuracy: 0.8459\n",
            "Epoch 1123/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 1.2280 - val_accuracy: 0.8472\n",
            "Epoch 1124/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 1.2355 - val_accuracy: 0.8475\n",
            "Epoch 1125/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 1.2352 - val_accuracy: 0.8457\n",
            "Epoch 1126/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.2461 - val_accuracy: 0.8473\n",
            "Epoch 1127/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 1.2448 - val_accuracy: 0.8471\n",
            "Epoch 1128/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 1.2504 - val_accuracy: 0.8472\n",
            "Epoch 1129/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 1.2294 - val_accuracy: 0.8492\n",
            "Epoch 1130/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 1.2413 - val_accuracy: 0.8477\n",
            "Epoch 1131/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.2576 - val_accuracy: 0.8502\n",
            "Epoch 1132/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 1.2566 - val_accuracy: 0.8475\n",
            "Epoch 1133/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 1.2416 - val_accuracy: 0.8442\n",
            "Epoch 1134/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2488 - val_accuracy: 0.8462\n",
            "Epoch 1135/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.2546 - val_accuracy: 0.8482\n",
            "Epoch 1136/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.2442 - val_accuracy: 0.8494\n",
            "Epoch 1137/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.2489 - val_accuracy: 0.8474\n",
            "Epoch 1138/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 1.2536 - val_accuracy: 0.8489\n",
            "Epoch 1139/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 1.2406 - val_accuracy: 0.8467\n",
            "Epoch 1140/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.2422 - val_accuracy: 0.8478\n",
            "Epoch 1141/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 1.2350 - val_accuracy: 0.8484\n",
            "Epoch 1142/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 1.2339 - val_accuracy: 0.8488\n",
            "Epoch 1143/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 1.2213 - val_accuracy: 0.8496\n",
            "Epoch 1144/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.2432 - val_accuracy: 0.8499\n",
            "Epoch 1145/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 1.2408 - val_accuracy: 0.8472\n",
            "Epoch 1146/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.2422 - val_accuracy: 0.8491\n",
            "Epoch 1147/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 1.2459 - val_accuracy: 0.8472\n",
            "Epoch 1148/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 1.2432 - val_accuracy: 0.8504\n",
            "Epoch 1149/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 1.2403 - val_accuracy: 0.8481\n",
            "Epoch 1150/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2484 - val_accuracy: 0.8510\n",
            "Epoch 1151/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.2564 - val_accuracy: 0.8493\n",
            "Epoch 1152/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 1.2547 - val_accuracy: 0.8511\n",
            "Epoch 1153/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 1.2521 - val_accuracy: 0.8495\n",
            "Epoch 1154/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.2545 - val_accuracy: 0.8485\n",
            "Epoch 1155/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.2472 - val_accuracy: 0.8496\n",
            "Epoch 1156/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.2355 - val_accuracy: 0.8477\n",
            "Epoch 1157/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 1.2389 - val_accuracy: 0.8473\n",
            "Epoch 1158/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 1.2224 - val_accuracy: 0.8470\n",
            "Epoch 1159/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 1.2243 - val_accuracy: 0.8476\n",
            "Epoch 1160/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 1.2332 - val_accuracy: 0.8482\n",
            "Epoch 1161/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 1.2453 - val_accuracy: 0.8506\n",
            "Epoch 1162/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 1.2357 - val_accuracy: 0.8483\n",
            "Epoch 1163/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 1.2462 - val_accuracy: 0.8509\n",
            "Epoch 1164/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2452 - val_accuracy: 0.8472\n",
            "Epoch 1165/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 1.2340 - val_accuracy: 0.8485\n",
            "Epoch 1166/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.2237 - val_accuracy: 0.8472\n",
            "Epoch 1167/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2306 - val_accuracy: 0.8476\n",
            "Epoch 1168/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.2436 - val_accuracy: 0.8490\n",
            "Epoch 1169/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.2615 - val_accuracy: 0.8471\n",
            "Epoch 1170/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 1.2374 - val_accuracy: 0.8501\n",
            "Epoch 1171/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.2432 - val_accuracy: 0.8482\n",
            "Epoch 1172/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 1.2554 - val_accuracy: 0.8494\n",
            "Epoch 1173/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2411 - val_accuracy: 0.8482\n",
            "Epoch 1174/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 1.2504 - val_accuracy: 0.8485\n",
            "Epoch 1175/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 1.2340 - val_accuracy: 0.8494\n",
            "Epoch 1176/3000\n",
            "235/235 [==============================] - 5s 17ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 1.2351 - val_accuracy: 0.8491\n",
            "Epoch 1177/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.2459 - val_accuracy: 0.8489\n",
            "Epoch 1178/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 1.2705 - val_accuracy: 0.8496\n",
            "Epoch 1179/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 1.2570 - val_accuracy: 0.8487\n",
            "Epoch 1180/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 1.2669 - val_accuracy: 0.8485\n",
            "Epoch 1181/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2573 - val_accuracy: 0.8471\n",
            "Epoch 1182/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 1.2519 - val_accuracy: 0.8469\n",
            "Epoch 1183/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 1.2689 - val_accuracy: 0.8488\n",
            "Epoch 1184/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 1.2614 - val_accuracy: 0.8454\n",
            "Epoch 1185/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 1.2395 - val_accuracy: 0.8454\n",
            "Epoch 1186/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2584 - val_accuracy: 0.8455\n",
            "Epoch 1187/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 1.2536 - val_accuracy: 0.8468\n",
            "Epoch 1188/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.2582 - val_accuracy: 0.8467\n",
            "Epoch 1189/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.2478 - val_accuracy: 0.8483\n",
            "Epoch 1190/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 1.2676 - val_accuracy: 0.8491\n",
            "Epoch 1191/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.2604 - val_accuracy: 0.8458\n",
            "Epoch 1192/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 1.2704 - val_accuracy: 0.8471\n",
            "Epoch 1193/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.2700 - val_accuracy: 0.8465\n",
            "Epoch 1194/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 1.2636 - val_accuracy: 0.8466\n",
            "Epoch 1195/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 1.2603 - val_accuracy: 0.8461\n",
            "Epoch 1196/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2552 - val_accuracy: 0.8459\n",
            "Epoch 1197/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.2661 - val_accuracy: 0.8470\n",
            "Epoch 1198/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 1.2458 - val_accuracy: 0.8482\n",
            "Epoch 1199/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.2475 - val_accuracy: 0.8484\n",
            "Epoch 1200/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.2512 - val_accuracy: 0.8480\n",
            "Epoch 1201/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 1.2621 - val_accuracy: 0.8481\n",
            "Epoch 1202/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 1.2568 - val_accuracy: 0.8475\n",
            "Epoch 1203/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 1.2625 - val_accuracy: 0.8461\n",
            "Epoch 1204/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.2594 - val_accuracy: 0.8462\n",
            "Epoch 1205/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2531 - val_accuracy: 0.8465\n",
            "Epoch 1206/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.2668 - val_accuracy: 0.8474\n",
            "Epoch 1207/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 1.2466 - val_accuracy: 0.8473\n",
            "Epoch 1208/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 1.2416 - val_accuracy: 0.8463\n",
            "Epoch 1209/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 1.2286 - val_accuracy: 0.8460\n",
            "Epoch 1210/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.2509 - val_accuracy: 0.8471\n",
            "Epoch 1211/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2675 - val_accuracy: 0.8487\n",
            "Epoch 1212/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 1.2804 - val_accuracy: 0.8455\n",
            "Epoch 1213/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.2637 - val_accuracy: 0.8446\n",
            "Epoch 1214/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.2640 - val_accuracy: 0.8479\n",
            "Epoch 1215/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 1.2552 - val_accuracy: 0.8474\n",
            "Epoch 1216/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 1.2589 - val_accuracy: 0.8489\n",
            "Epoch 1217/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.2643 - val_accuracy: 0.8463\n",
            "Epoch 1218/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.2530 - val_accuracy: 0.8474\n",
            "Epoch 1219/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2609 - val_accuracy: 0.8482\n",
            "Epoch 1220/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 1.2497 - val_accuracy: 0.8518\n",
            "Epoch 1221/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 1.2503 - val_accuracy: 0.8486\n",
            "Epoch 1222/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2650 - val_accuracy: 0.8467\n",
            "Epoch 1223/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 1.2440 - val_accuracy: 0.8484\n",
            "Epoch 1224/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.2482 - val_accuracy: 0.8493\n",
            "Epoch 1225/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 1.2529 - val_accuracy: 0.8491\n",
            "Epoch 1226/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.2678 - val_accuracy: 0.8507\n",
            "Epoch 1227/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 1.2614 - val_accuracy: 0.8500\n",
            "Epoch 1228/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 1.2639 - val_accuracy: 0.8493\n",
            "Epoch 1229/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 1.2609 - val_accuracy: 0.8460\n",
            "Epoch 1230/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 1.2627 - val_accuracy: 0.8474\n",
            "Epoch 1231/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 1.2591 - val_accuracy: 0.8485\n",
            "Epoch 1232/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 1.2629 - val_accuracy: 0.8480\n",
            "Epoch 1233/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.2691 - val_accuracy: 0.8437\n",
            "Epoch 1234/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.2645 - val_accuracy: 0.8461\n",
            "Epoch 1235/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 1.2456 - val_accuracy: 0.8463\n",
            "Epoch 1236/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2730 - val_accuracy: 0.8475\n",
            "Epoch 1237/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 1.2820 - val_accuracy: 0.8489\n",
            "Epoch 1238/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.2660 - val_accuracy: 0.8481\n",
            "Epoch 1239/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 1.2803 - val_accuracy: 0.8490\n",
            "Epoch 1240/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 1.2666 - val_accuracy: 0.8463\n",
            "Epoch 1241/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 1.2804 - val_accuracy: 0.8505\n",
            "Epoch 1242/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2780 - val_accuracy: 0.8490\n",
            "Epoch 1243/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.2524 - val_accuracy: 0.8492\n",
            "Epoch 1244/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2560 - val_accuracy: 0.8490\n",
            "Epoch 1245/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 1.2745 - val_accuracy: 0.8480\n",
            "Epoch 1246/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 1.2759 - val_accuracy: 0.8483\n",
            "Epoch 1247/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 1.2655 - val_accuracy: 0.8486\n",
            "Epoch 1248/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 1.2830 - val_accuracy: 0.8487\n",
            "Epoch 1249/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 1.2825 - val_accuracy: 0.8461\n",
            "Epoch 1250/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 1.2712 - val_accuracy: 0.8468\n",
            "Epoch 1251/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 1.2569 - val_accuracy: 0.8480\n",
            "Epoch 1252/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 1.2568 - val_accuracy: 0.8510\n",
            "Epoch 1253/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 1.2587 - val_accuracy: 0.8484\n",
            "Epoch 1254/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 1.2683 - val_accuracy: 0.8512\n",
            "Epoch 1255/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.2637 - val_accuracy: 0.8490\n",
            "Epoch 1256/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.2603 - val_accuracy: 0.8472\n",
            "Epoch 1257/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2639 - val_accuracy: 0.8478\n",
            "Epoch 1258/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 1.2538 - val_accuracy: 0.8496\n",
            "Epoch 1259/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 1.2622 - val_accuracy: 0.8464\n",
            "Epoch 1260/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 1.2730 - val_accuracy: 0.8465\n",
            "Epoch 1261/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 1.2768 - val_accuracy: 0.8464\n",
            "Epoch 1262/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 1.2559 - val_accuracy: 0.8467\n",
            "Epoch 1263/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2706 - val_accuracy: 0.8437\n",
            "Epoch 1264/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 1.2582 - val_accuracy: 0.8459\n",
            "Epoch 1265/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2493 - val_accuracy: 0.8456\n",
            "Epoch 1266/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 1.2500 - val_accuracy: 0.8480\n",
            "Epoch 1267/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 1.2661 - val_accuracy: 0.8473\n",
            "Epoch 1268/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 1.2490 - val_accuracy: 0.8486\n",
            "Epoch 1269/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 1.2618 - val_accuracy: 0.8464\n",
            "Epoch 1270/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 1.2394 - val_accuracy: 0.8472\n",
            "Epoch 1271/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.2506 - val_accuracy: 0.8484\n",
            "Epoch 1272/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 1.2580 - val_accuracy: 0.8484\n",
            "Epoch 1273/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 1.2521 - val_accuracy: 0.8480\n",
            "Epoch 1274/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2664 - val_accuracy: 0.8462\n",
            "Epoch 1275/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.2597 - val_accuracy: 0.8488\n",
            "Epoch 1276/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.2571 - val_accuracy: 0.8511\n",
            "Epoch 1277/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 1.2638 - val_accuracy: 0.8482\n",
            "Epoch 1278/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 1.2552 - val_accuracy: 0.8477\n",
            "Epoch 1279/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.2391 - val_accuracy: 0.8496\n",
            "Epoch 1280/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 1.2382 - val_accuracy: 0.8473\n",
            "Epoch 1281/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 1.2484 - val_accuracy: 0.8467\n",
            "Epoch 1282/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 1.2618 - val_accuracy: 0.8460\n",
            "Epoch 1283/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.2590 - val_accuracy: 0.8456\n",
            "Epoch 1284/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.2696 - val_accuracy: 0.8455\n",
            "Epoch 1285/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 1.2666 - val_accuracy: 0.8454\n",
            "Epoch 1286/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2650 - val_accuracy: 0.8451\n",
            "Epoch 1287/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 1.2652 - val_accuracy: 0.8453\n",
            "Epoch 1288/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 1.2603 - val_accuracy: 0.8467\n",
            "Epoch 1289/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.2564 - val_accuracy: 0.8477\n",
            "Epoch 1290/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 1.2593 - val_accuracy: 0.8477\n",
            "Epoch 1291/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 1.2723 - val_accuracy: 0.8513\n",
            "Epoch 1292/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.2716 - val_accuracy: 0.8476\n",
            "Epoch 1293/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 1.2693 - val_accuracy: 0.8481\n",
            "Epoch 1294/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.2764 - val_accuracy: 0.8461\n",
            "Epoch 1295/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 1.2670 - val_accuracy: 0.8460\n",
            "Epoch 1296/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 1.2772 - val_accuracy: 0.8490\n",
            "Epoch 1297/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 1.2876 - val_accuracy: 0.8459\n",
            "Epoch 1298/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.2864 - val_accuracy: 0.8469\n",
            "Epoch 1299/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 1.2824 - val_accuracy: 0.8479\n",
            "Epoch 1300/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2863 - val_accuracy: 0.8485\n",
            "Epoch 1301/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 1.2918 - val_accuracy: 0.8463\n",
            "Epoch 1302/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 1.2867 - val_accuracy: 0.8459\n",
            "Epoch 1303/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 1.2659 - val_accuracy: 0.8452\n",
            "Epoch 1304/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2830 - val_accuracy: 0.8477\n",
            "Epoch 1305/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 1.2716 - val_accuracy: 0.8462\n",
            "Epoch 1306/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2551 - val_accuracy: 0.8499\n",
            "Epoch 1307/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 1.2632 - val_accuracy: 0.8487\n",
            "Epoch 1308/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 1.2714 - val_accuracy: 0.8483\n",
            "Epoch 1309/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 1.2793 - val_accuracy: 0.8467\n",
            "Epoch 1310/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 1.2698 - val_accuracy: 0.8458\n",
            "Epoch 1311/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 1.2686 - val_accuracy: 0.8495\n",
            "Epoch 1312/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2802 - val_accuracy: 0.8486\n",
            "Epoch 1313/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2711 - val_accuracy: 0.8451\n",
            "Epoch 1314/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.2720 - val_accuracy: 0.8490\n",
            "Epoch 1315/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 1.2808 - val_accuracy: 0.8488\n",
            "Epoch 1316/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 1.2730 - val_accuracy: 0.8453\n",
            "Epoch 1317/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 1.2751 - val_accuracy: 0.8466\n",
            "Epoch 1318/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 1.2916 - val_accuracy: 0.8474\n",
            "Epoch 1319/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.2723 - val_accuracy: 0.8476\n",
            "Epoch 1320/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 1.2905 - val_accuracy: 0.8437\n",
            "Epoch 1321/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2998 - val_accuracy: 0.8467\n",
            "Epoch 1322/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 1.2792 - val_accuracy: 0.8464\n",
            "Epoch 1323/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.2946 - val_accuracy: 0.8459\n",
            "Epoch 1324/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.2829 - val_accuracy: 0.8453\n",
            "Epoch 1325/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 1.3016 - val_accuracy: 0.8455\n",
            "Epoch 1326/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 1.2799 - val_accuracy: 0.8469\n",
            "Epoch 1327/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 1.2638 - val_accuracy: 0.8470\n",
            "Epoch 1328/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.2634 - val_accuracy: 0.8478\n",
            "Epoch 1329/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.2795 - val_accuracy: 0.8452\n",
            "Epoch 1330/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.2843 - val_accuracy: 0.8491\n",
            "Epoch 1331/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.2981 - val_accuracy: 0.8465\n",
            "Epoch 1332/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 1.2928 - val_accuracy: 0.8475\n",
            "Epoch 1333/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 1.2745 - val_accuracy: 0.8467\n",
            "Epoch 1334/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 1.2911 - val_accuracy: 0.8498\n",
            "Epoch 1335/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 1.2675 - val_accuracy: 0.8446\n",
            "Epoch 1336/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 1.2488 - val_accuracy: 0.8482\n",
            "Epoch 1337/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2561 - val_accuracy: 0.8478\n",
            "Epoch 1338/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 1.2573 - val_accuracy: 0.8442\n",
            "Epoch 1339/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.2715 - val_accuracy: 0.8455\n",
            "Epoch 1340/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 1.2620 - val_accuracy: 0.8485\n",
            "Epoch 1341/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.2757 - val_accuracy: 0.8471\n",
            "Epoch 1342/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 1.2702 - val_accuracy: 0.8475\n",
            "Epoch 1343/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.2831 - val_accuracy: 0.8504\n",
            "Epoch 1344/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.2726 - val_accuracy: 0.8502\n",
            "Epoch 1345/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.2585 - val_accuracy: 0.8493\n",
            "Epoch 1346/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.2651 - val_accuracy: 0.8490\n",
            "Epoch 1347/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 1.2674 - val_accuracy: 0.8519\n",
            "Epoch 1348/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2608 - val_accuracy: 0.8477\n",
            "Epoch 1349/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.2664 - val_accuracy: 0.8453\n",
            "Epoch 1350/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 1.2539 - val_accuracy: 0.8475\n",
            "Epoch 1351/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.2635 - val_accuracy: 0.8474\n",
            "Epoch 1352/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 1.2664 - val_accuracy: 0.8467\n",
            "Epoch 1353/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 1.2776 - val_accuracy: 0.8481\n",
            "Epoch 1354/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.2713 - val_accuracy: 0.8469\n",
            "Epoch 1355/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 1.2512 - val_accuracy: 0.8481\n",
            "Epoch 1356/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 1.2609 - val_accuracy: 0.8486\n",
            "Epoch 1357/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 1.2542 - val_accuracy: 0.8501\n",
            "Epoch 1358/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 1.2560 - val_accuracy: 0.8469\n",
            "Epoch 1359/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 1.2562 - val_accuracy: 0.8494\n",
            "Epoch 1360/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2623 - val_accuracy: 0.8502\n",
            "Epoch 1361/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 1.2953 - val_accuracy: 0.8486\n",
            "Epoch 1362/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.2736 - val_accuracy: 0.8468\n",
            "Epoch 1363/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2902 - val_accuracy: 0.8481\n",
            "Epoch 1364/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 1.2765 - val_accuracy: 0.8491\n",
            "Epoch 1365/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.2815 - val_accuracy: 0.8495\n",
            "Epoch 1366/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2876 - val_accuracy: 0.8475\n",
            "Epoch 1367/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.2880 - val_accuracy: 0.8491\n",
            "Epoch 1368/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.2728 - val_accuracy: 0.8476\n",
            "Epoch 1369/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 1.2773 - val_accuracy: 0.8490\n",
            "Epoch 1370/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 1.2845 - val_accuracy: 0.8496\n",
            "Epoch 1371/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 1.2824 - val_accuracy: 0.8494\n",
            "Epoch 1372/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 1.2833 - val_accuracy: 0.8475\n",
            "Epoch 1373/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 1.2835 - val_accuracy: 0.8467\n",
            "Epoch 1374/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.2766 - val_accuracy: 0.8491\n",
            "Epoch 1375/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.2618 - val_accuracy: 0.8461\n",
            "Epoch 1376/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2731 - val_accuracy: 0.8496\n",
            "Epoch 1377/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 1.2854 - val_accuracy: 0.8493\n",
            "Epoch 1378/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2954 - val_accuracy: 0.8494\n",
            "Epoch 1379/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.2718 - val_accuracy: 0.8473\n",
            "Epoch 1380/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.2747 - val_accuracy: 0.8495\n",
            "Epoch 1381/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 1.2666 - val_accuracy: 0.8487\n",
            "Epoch 1382/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 1.2663 - val_accuracy: 0.8482\n",
            "Epoch 1383/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 1.2647 - val_accuracy: 0.8515\n",
            "Epoch 1384/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.2739 - val_accuracy: 0.8485\n",
            "Epoch 1385/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.2716 - val_accuracy: 0.8461\n",
            "Epoch 1386/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.2631 - val_accuracy: 0.8462\n",
            "Epoch 1387/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.2612 - val_accuracy: 0.8493\n",
            "Epoch 1388/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 1.2609 - val_accuracy: 0.8503\n",
            "Epoch 1389/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 1.2394 - val_accuracy: 0.8452\n",
            "Epoch 1390/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 1.2518 - val_accuracy: 0.8492\n",
            "Epoch 1391/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.2541 - val_accuracy: 0.8502\n",
            "Epoch 1392/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 1.2689 - val_accuracy: 0.8473\n",
            "Epoch 1393/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.2751 - val_accuracy: 0.8483\n",
            "Epoch 1394/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 1.2487 - val_accuracy: 0.8479\n",
            "Epoch 1395/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2629 - val_accuracy: 0.8502\n",
            "Epoch 1396/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2690 - val_accuracy: 0.8466\n",
            "Epoch 1397/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2780 - val_accuracy: 0.8491\n",
            "Epoch 1398/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 1.2680 - val_accuracy: 0.8480\n",
            "Epoch 1399/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 1.2665 - val_accuracy: 0.8492\n",
            "Epoch 1400/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.2704 - val_accuracy: 0.8481\n",
            "Epoch 1401/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.2635 - val_accuracy: 0.8496\n",
            "Epoch 1402/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2426 - val_accuracy: 0.8490\n",
            "Epoch 1403/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2570 - val_accuracy: 0.8524\n",
            "Epoch 1404/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.2423 - val_accuracy: 0.8518\n",
            "Epoch 1405/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 1.2532 - val_accuracy: 0.8488\n",
            "Epoch 1406/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 1.2565 - val_accuracy: 0.8506\n",
            "Epoch 1407/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2725 - val_accuracy: 0.8481\n",
            "Epoch 1408/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.2572 - val_accuracy: 0.8506\n",
            "Epoch 1409/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2698 - val_accuracy: 0.8497\n",
            "Epoch 1410/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.2805 - val_accuracy: 0.8493\n",
            "Epoch 1411/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.2626 - val_accuracy: 0.8503\n",
            "Epoch 1412/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.2611 - val_accuracy: 0.8495\n",
            "Epoch 1413/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.2752 - val_accuracy: 0.8489\n",
            "Epoch 1414/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 1.2739 - val_accuracy: 0.8503\n",
            "Epoch 1415/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.2806 - val_accuracy: 0.8497\n",
            "Epoch 1416/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 1.2868 - val_accuracy: 0.8466\n",
            "Epoch 1417/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.2655 - val_accuracy: 0.8514\n",
            "Epoch 1418/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 1.2614 - val_accuracy: 0.8497\n",
            "Epoch 1419/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 1.2622 - val_accuracy: 0.8511\n",
            "Epoch 1420/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 1.2813 - val_accuracy: 0.8486\n",
            "Epoch 1421/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.2648 - val_accuracy: 0.8488\n",
            "Epoch 1422/3000\n",
            "235/235 [==============================] - 6s 17ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.2777 - val_accuracy: 0.8486\n",
            "Epoch 1423/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 1.2688 - val_accuracy: 0.8487\n",
            "Epoch 1424/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.2522 - val_accuracy: 0.8505\n",
            "Epoch 1425/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.2704 - val_accuracy: 0.8502\n",
            "Epoch 1426/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 1.2783 - val_accuracy: 0.8496\n",
            "Epoch 1427/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.2670 - val_accuracy: 0.8521\n",
            "Epoch 1428/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2778 - val_accuracy: 0.8510\n",
            "Epoch 1429/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 1.2850 - val_accuracy: 0.8499\n",
            "Epoch 1430/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 1.2788 - val_accuracy: 0.8512\n",
            "Epoch 1431/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2943 - val_accuracy: 0.8501\n",
            "Epoch 1432/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 1.2842 - val_accuracy: 0.8499\n",
            "Epoch 1433/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.2797 - val_accuracy: 0.8481\n",
            "Epoch 1434/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.2828 - val_accuracy: 0.8485\n",
            "Epoch 1435/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 1.2750 - val_accuracy: 0.8477\n",
            "Epoch 1436/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.2637 - val_accuracy: 0.8482\n",
            "Epoch 1437/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.2748 - val_accuracy: 0.8492\n",
            "Epoch 1438/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 1.2677 - val_accuracy: 0.8484\n",
            "Epoch 1439/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2686 - val_accuracy: 0.8475\n",
            "Epoch 1440/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.2743 - val_accuracy: 0.8478\n",
            "Epoch 1441/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.2669 - val_accuracy: 0.8506\n",
            "Epoch 1442/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.2665 - val_accuracy: 0.8465\n",
            "Epoch 1443/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.2729 - val_accuracy: 0.8477\n",
            "Epoch 1444/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.2781 - val_accuracy: 0.8494\n",
            "Epoch 1445/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.2682 - val_accuracy: 0.8499\n",
            "Epoch 1446/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 1.2657 - val_accuracy: 0.8510\n",
            "Epoch 1447/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 1.2884 - val_accuracy: 0.8479\n",
            "Epoch 1448/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 1.2771 - val_accuracy: 0.8495\n",
            "Epoch 1449/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 1.2776 - val_accuracy: 0.8460\n",
            "Epoch 1450/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.2735 - val_accuracy: 0.8485\n",
            "Epoch 1451/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2571 - val_accuracy: 0.8473\n",
            "Epoch 1452/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.2651 - val_accuracy: 0.8486\n",
            "Epoch 1453/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.2778 - val_accuracy: 0.8506\n",
            "Epoch 1454/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.3046 - val_accuracy: 0.8485\n",
            "Epoch 1455/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.2880 - val_accuracy: 0.8472\n",
            "Epoch 1456/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 1.3044 - val_accuracy: 0.8484\n",
            "Epoch 1457/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 1.2885 - val_accuracy: 0.8480\n",
            "Epoch 1458/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.2834 - val_accuracy: 0.8484\n",
            "Epoch 1459/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.2908 - val_accuracy: 0.8500\n",
            "Epoch 1460/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 1.2862 - val_accuracy: 0.8473\n",
            "Epoch 1461/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 1.3077 - val_accuracy: 0.8451\n",
            "Epoch 1462/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.2834 - val_accuracy: 0.8497\n",
            "Epoch 1463/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 1.2675 - val_accuracy: 0.8485\n",
            "Epoch 1464/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.2628 - val_accuracy: 0.8505\n",
            "Epoch 1465/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.2920 - val_accuracy: 0.8486\n",
            "Epoch 1466/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.3007 - val_accuracy: 0.8504\n",
            "Epoch 1467/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.3063 - val_accuracy: 0.8470\n",
            "Epoch 1468/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.3044 - val_accuracy: 0.8485\n",
            "Epoch 1469/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.3248 - val_accuracy: 0.8459\n",
            "Epoch 1470/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3072 - val_accuracy: 0.8468\n",
            "Epoch 1471/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.3069 - val_accuracy: 0.8479\n",
            "Epoch 1472/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.3130 - val_accuracy: 0.8477\n",
            "Epoch 1473/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.3054 - val_accuracy: 0.8473\n",
            "Epoch 1474/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 1.2816 - val_accuracy: 0.8461\n",
            "Epoch 1475/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 1.2844 - val_accuracy: 0.8490\n",
            "Epoch 1476/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 1.2758 - val_accuracy: 0.8460\n",
            "Epoch 1477/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2794 - val_accuracy: 0.8460\n",
            "Epoch 1478/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.2713 - val_accuracy: 0.8470\n",
            "Epoch 1479/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 1.2890 - val_accuracy: 0.8444\n",
            "Epoch 1480/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2732 - val_accuracy: 0.8480\n",
            "Epoch 1481/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.2515 - val_accuracy: 0.8506\n",
            "Epoch 1482/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2632 - val_accuracy: 0.8505\n",
            "Epoch 1483/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 1.2691 - val_accuracy: 0.8457\n",
            "Epoch 1484/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.2814 - val_accuracy: 0.8500\n",
            "Epoch 1485/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.2796 - val_accuracy: 0.8473\n",
            "Epoch 1486/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2927 - val_accuracy: 0.8465\n",
            "Epoch 1487/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.3036 - val_accuracy: 0.8482\n",
            "Epoch 1488/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.3087 - val_accuracy: 0.8475\n",
            "Epoch 1489/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.2971 - val_accuracy: 0.8472\n",
            "Epoch 1490/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2841 - val_accuracy: 0.8469\n",
            "Epoch 1491/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.2840 - val_accuracy: 0.8506\n",
            "Epoch 1492/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.2639 - val_accuracy: 0.8484\n",
            "Epoch 1493/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 1.2748 - val_accuracy: 0.8490\n",
            "Epoch 1494/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 1.2927 - val_accuracy: 0.8518\n",
            "Epoch 1495/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.2709 - val_accuracy: 0.8506\n",
            "Epoch 1496/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2837 - val_accuracy: 0.8523\n",
            "Epoch 1497/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.2919 - val_accuracy: 0.8503\n",
            "Epoch 1498/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 1.2853 - val_accuracy: 0.8514\n",
            "Epoch 1499/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2865 - val_accuracy: 0.8522\n",
            "Epoch 1500/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.2730 - val_accuracy: 0.8490\n",
            "Epoch 1501/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 1.2880 - val_accuracy: 0.8512\n",
            "Epoch 1502/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2637 - val_accuracy: 0.8516\n",
            "Epoch 1503/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.2770 - val_accuracy: 0.8494\n",
            "Epoch 1504/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.2840 - val_accuracy: 0.8501\n",
            "Epoch 1505/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 1.2816 - val_accuracy: 0.8488\n",
            "Epoch 1506/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 1.3026 - val_accuracy: 0.8470\n",
            "Epoch 1507/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 1.2817 - val_accuracy: 0.8505\n",
            "Epoch 1508/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.2911 - val_accuracy: 0.8511\n",
            "Epoch 1509/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.2845 - val_accuracy: 0.8484\n",
            "Epoch 1510/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2861 - val_accuracy: 0.8471\n",
            "Epoch 1511/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.3081 - val_accuracy: 0.8500\n",
            "Epoch 1512/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2821 - val_accuracy: 0.8490\n",
            "Epoch 1513/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2961 - val_accuracy: 0.8481\n",
            "Epoch 1514/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 1.2675 - val_accuracy: 0.8489\n",
            "Epoch 1515/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2831 - val_accuracy: 0.8487\n",
            "Epoch 1516/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.3070 - val_accuracy: 0.8484\n",
            "Epoch 1517/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.3080 - val_accuracy: 0.8489\n",
            "Epoch 1518/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2737 - val_accuracy: 0.8480\n",
            "Epoch 1519/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.2766 - val_accuracy: 0.8489\n",
            "Epoch 1520/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.3018 - val_accuracy: 0.8503\n",
            "Epoch 1521/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.2937 - val_accuracy: 0.8500\n",
            "Epoch 1522/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2996 - val_accuracy: 0.8500\n",
            "Epoch 1523/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.3041 - val_accuracy: 0.8491\n",
            "Epoch 1524/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.3009 - val_accuracy: 0.8481\n",
            "Epoch 1525/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.2970 - val_accuracy: 0.8499\n",
            "Epoch 1526/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 1.2729 - val_accuracy: 0.8489\n",
            "Epoch 1527/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.2615 - val_accuracy: 0.8488\n",
            "Epoch 1528/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 1.2525 - val_accuracy: 0.8481\n",
            "Epoch 1529/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 1.2580 - val_accuracy: 0.8485\n",
            "Epoch 1530/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.2679 - val_accuracy: 0.8497\n",
            "Epoch 1531/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.2550 - val_accuracy: 0.8511\n",
            "Epoch 1532/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 1.2462 - val_accuracy: 0.8512\n",
            "Epoch 1533/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 1.2480 - val_accuracy: 0.8498\n",
            "Epoch 1534/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 1.2575 - val_accuracy: 0.8482\n",
            "Epoch 1535/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.2755 - val_accuracy: 0.8491\n",
            "Epoch 1536/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 1.2805 - val_accuracy: 0.8497\n",
            "Epoch 1537/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 1.2809 - val_accuracy: 0.8515\n",
            "Epoch 1538/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 1.2842 - val_accuracy: 0.8505\n",
            "Epoch 1539/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.2815 - val_accuracy: 0.8510\n",
            "Epoch 1540/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.2743 - val_accuracy: 0.8502\n",
            "Epoch 1541/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.2670 - val_accuracy: 0.8512\n",
            "Epoch 1542/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.2785 - val_accuracy: 0.8519\n",
            "Epoch 1543/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.3009 - val_accuracy: 0.8494\n",
            "Epoch 1544/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2989 - val_accuracy: 0.8499\n",
            "Epoch 1545/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 1.2818 - val_accuracy: 0.8489\n",
            "Epoch 1546/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.2655 - val_accuracy: 0.8507\n",
            "Epoch 1547/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 1.2613 - val_accuracy: 0.8522\n",
            "Epoch 1548/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.2770 - val_accuracy: 0.8510\n",
            "Epoch 1549/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.2715 - val_accuracy: 0.8480\n",
            "Epoch 1550/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 1.2635 - val_accuracy: 0.8489\n",
            "Epoch 1551/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2652 - val_accuracy: 0.8491\n",
            "Epoch 1552/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2772 - val_accuracy: 0.8499\n",
            "Epoch 1553/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 1.2704 - val_accuracy: 0.8507\n",
            "Epoch 1554/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.2617 - val_accuracy: 0.8509\n",
            "Epoch 1555/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.2677 - val_accuracy: 0.8508\n",
            "Epoch 1556/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.2701 - val_accuracy: 0.8507\n",
            "Epoch 1557/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2650 - val_accuracy: 0.8507\n",
            "Epoch 1558/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 1.2702 - val_accuracy: 0.8506\n",
            "Epoch 1559/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 1.2757 - val_accuracy: 0.8500\n",
            "Epoch 1560/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.2802 - val_accuracy: 0.8480\n",
            "Epoch 1561/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 1.2619 - val_accuracy: 0.8506\n",
            "Epoch 1562/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.2818 - val_accuracy: 0.8502\n",
            "Epoch 1563/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "235/235 [==============================] - 10s 45ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 1.2860 - val_accuracy: 0.8489\n",
            "Epoch 1564/3000\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.3004 - val_accuracy: 0.8502\n",
            "Epoch 1565/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.3029 - val_accuracy: 0.8494\n",
            "Epoch 1566/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.3011 - val_accuracy: 0.8497\n",
            "Epoch 1567/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 1.2913 - val_accuracy: 0.8484\n",
            "Epoch 1568/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.2928 - val_accuracy: 0.8486\n",
            "Epoch 1569/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.2800 - val_accuracy: 0.8494\n",
            "Epoch 1570/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.3102 - val_accuracy: 0.8508\n",
            "Epoch 1571/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 1.3079 - val_accuracy: 0.8512\n",
            "Epoch 1572/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.2841 - val_accuracy: 0.8472\n",
            "Epoch 1573/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2911 - val_accuracy: 0.8487\n",
            "Epoch 1574/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.3007 - val_accuracy: 0.8491\n",
            "Epoch 1575/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2851 - val_accuracy: 0.8522\n",
            "Epoch 1576/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.2764 - val_accuracy: 0.8480\n",
            "Epoch 1577/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.2826 - val_accuracy: 0.8502\n",
            "Epoch 1578/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 1.2918 - val_accuracy: 0.8491\n",
            "Epoch 1579/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.3093 - val_accuracy: 0.8488\n",
            "Epoch 1580/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.2958 - val_accuracy: 0.8489\n",
            "Epoch 1581/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.2684 - val_accuracy: 0.8495\n",
            "Epoch 1582/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.2811 - val_accuracy: 0.8496\n",
            "Epoch 1583/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.3015 - val_accuracy: 0.8484\n",
            "Epoch 1584/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 1.3162 - val_accuracy: 0.8518\n",
            "Epoch 1585/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 1.3063 - val_accuracy: 0.8493\n",
            "Epoch 1586/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.2747 - val_accuracy: 0.8512\n",
            "Epoch 1587/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.2749 - val_accuracy: 0.8523\n",
            "Epoch 1588/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.2896 - val_accuracy: 0.8517\n",
            "Epoch 1589/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.2612 - val_accuracy: 0.8500\n",
            "Epoch 1590/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.2683 - val_accuracy: 0.8510\n",
            "Epoch 1591/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 1.2750 - val_accuracy: 0.8490\n",
            "Epoch 1592/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.2834 - val_accuracy: 0.8496\n",
            "Epoch 1593/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.2675 - val_accuracy: 0.8507\n",
            "Epoch 1594/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.2839 - val_accuracy: 0.8491\n",
            "Epoch 1595/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 1.2922 - val_accuracy: 0.8500\n",
            "Epoch 1596/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.2847 - val_accuracy: 0.8483\n",
            "Epoch 1597/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.2922 - val_accuracy: 0.8499\n",
            "Epoch 1598/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.2813 - val_accuracy: 0.8493\n",
            "Epoch 1599/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2921 - val_accuracy: 0.8484\n",
            "Epoch 1600/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 1.2942 - val_accuracy: 0.8472\n",
            "Epoch 1601/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 1.2956 - val_accuracy: 0.8501\n",
            "Epoch 1602/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.2917 - val_accuracy: 0.8490\n",
            "Epoch 1603/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.3056 - val_accuracy: 0.8495\n",
            "Epoch 1604/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.3133 - val_accuracy: 0.8477\n",
            "Epoch 1605/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.2928 - val_accuracy: 0.8484\n",
            "Epoch 1606/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 1.2871 - val_accuracy: 0.8474\n",
            "Epoch 1607/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.2873 - val_accuracy: 0.8477\n",
            "Epoch 1608/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.3040 - val_accuracy: 0.8500\n",
            "Epoch 1609/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.2933 - val_accuracy: 0.8486\n",
            "Epoch 1610/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 1.2994 - val_accuracy: 0.8490\n",
            "Epoch 1611/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.2888 - val_accuracy: 0.8514\n",
            "Epoch 1612/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.3033 - val_accuracy: 0.8482\n",
            "Epoch 1613/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.3234 - val_accuracy: 0.8498\n",
            "Epoch 1614/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.3254 - val_accuracy: 0.8480\n",
            "Epoch 1615/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.2941 - val_accuracy: 0.8478\n",
            "Epoch 1616/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 1.2786 - val_accuracy: 0.8496\n",
            "Epoch 1617/3000\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.2870 - val_accuracy: 0.8482\n",
            "Epoch 1618/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.2866 - val_accuracy: 0.8494\n",
            "Epoch 1619/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 1.2909 - val_accuracy: 0.8489\n",
            "Epoch 1620/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.2894 - val_accuracy: 0.8494\n",
            "Epoch 1621/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 1.2820 - val_accuracy: 0.8470\n",
            "Epoch 1622/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.2801 - val_accuracy: 0.8505\n",
            "Epoch 1623/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2842 - val_accuracy: 0.8496\n",
            "Epoch 1624/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.3012 - val_accuracy: 0.8499\n",
            "Epoch 1625/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.2917 - val_accuracy: 0.8490\n",
            "Epoch 1626/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 1.2779 - val_accuracy: 0.8529\n",
            "Epoch 1627/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.2840 - val_accuracy: 0.8500\n",
            "Epoch 1628/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2704 - val_accuracy: 0.8506\n",
            "Epoch 1629/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 1.2799 - val_accuracy: 0.8499\n",
            "Epoch 1630/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 1.2851 - val_accuracy: 0.8492\n",
            "Epoch 1631/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.2797 - val_accuracy: 0.8485\n",
            "Epoch 1632/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 1.2918 - val_accuracy: 0.8487\n",
            "Epoch 1633/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.2960 - val_accuracy: 0.8484\n",
            "Epoch 1634/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.3159 - val_accuracy: 0.8473\n",
            "Epoch 1635/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3041 - val_accuracy: 0.8491\n",
            "Epoch 1636/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3056 - val_accuracy: 0.8483\n",
            "Epoch 1637/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2985 - val_accuracy: 0.8481\n",
            "Epoch 1638/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.3020 - val_accuracy: 0.8500\n",
            "Epoch 1639/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.2808 - val_accuracy: 0.8503\n",
            "Epoch 1640/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2883 - val_accuracy: 0.8473\n",
            "Epoch 1641/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.2824 - val_accuracy: 0.8505\n",
            "Epoch 1642/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.2854 - val_accuracy: 0.8520\n",
            "Epoch 1643/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 1.2810 - val_accuracy: 0.8512\n",
            "Epoch 1644/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.2538 - val_accuracy: 0.8518\n",
            "Epoch 1645/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2935 - val_accuracy: 0.8493\n",
            "Epoch 1646/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2848 - val_accuracy: 0.8496\n",
            "Epoch 1647/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.2907 - val_accuracy: 0.8522\n",
            "Epoch 1648/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.2813 - val_accuracy: 0.8493\n",
            "Epoch 1649/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 1.2652 - val_accuracy: 0.8495\n",
            "Epoch 1650/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.2812 - val_accuracy: 0.8500\n",
            "Epoch 1651/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2625 - val_accuracy: 0.8515\n",
            "Epoch 1652/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 1.2585 - val_accuracy: 0.8489\n",
            "Epoch 1653/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.2822 - val_accuracy: 0.8481\n",
            "Epoch 1654/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 1.2713 - val_accuracy: 0.8497\n",
            "Epoch 1655/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 1.2705 - val_accuracy: 0.8504\n",
            "Epoch 1656/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.2899 - val_accuracy: 0.8505\n",
            "Epoch 1657/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.2825 - val_accuracy: 0.8505\n",
            "Epoch 1658/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.2738 - val_accuracy: 0.8509\n",
            "Epoch 1659/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.2900 - val_accuracy: 0.8495\n",
            "Epoch 1660/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2904 - val_accuracy: 0.8475\n",
            "Epoch 1661/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.2776 - val_accuracy: 0.8495\n",
            "Epoch 1662/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.2720 - val_accuracy: 0.8496\n",
            "Epoch 1663/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 1.2621 - val_accuracy: 0.8515\n",
            "Epoch 1664/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2812 - val_accuracy: 0.8509\n",
            "Epoch 1665/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.2896 - val_accuracy: 0.8527\n",
            "Epoch 1666/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 1.2815 - val_accuracy: 0.8492\n",
            "Epoch 1667/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.2792 - val_accuracy: 0.8506\n",
            "Epoch 1668/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.2820 - val_accuracy: 0.8517\n",
            "Epoch 1669/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.2780 - val_accuracy: 0.8509\n",
            "Epoch 1670/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 1.2784 - val_accuracy: 0.8519\n",
            "Epoch 1671/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.2980 - val_accuracy: 0.8528\n",
            "Epoch 1672/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 1.2995 - val_accuracy: 0.8502\n",
            "Epoch 1673/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.2774 - val_accuracy: 0.8520\n",
            "Epoch 1674/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.2893 - val_accuracy: 0.8500\n",
            "Epoch 1675/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.2984 - val_accuracy: 0.8482\n",
            "Epoch 1676/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.3077 - val_accuracy: 0.8472\n",
            "Epoch 1677/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.2972 - val_accuracy: 0.8497\n",
            "Epoch 1678/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.3049 - val_accuracy: 0.8519\n",
            "Epoch 1679/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.2823 - val_accuracy: 0.8508\n",
            "Epoch 1680/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.3081 - val_accuracy: 0.8507\n",
            "Epoch 1681/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.2877 - val_accuracy: 0.8503\n",
            "Epoch 1682/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.3005 - val_accuracy: 0.8522\n",
            "Epoch 1683/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.3030 - val_accuracy: 0.8471\n",
            "Epoch 1684/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.3024 - val_accuracy: 0.8490\n",
            "Epoch 1685/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.3059 - val_accuracy: 0.8497\n",
            "Epoch 1686/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3113 - val_accuracy: 0.8489\n",
            "Epoch 1687/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3122 - val_accuracy: 0.8499\n",
            "Epoch 1688/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.3086 - val_accuracy: 0.8493\n",
            "Epoch 1689/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 1.3042 - val_accuracy: 0.8509\n",
            "Epoch 1690/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2829 - val_accuracy: 0.8495\n",
            "Epoch 1691/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.2855 - val_accuracy: 0.8516\n",
            "Epoch 1692/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 1.2958 - val_accuracy: 0.8509\n",
            "Epoch 1693/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.3133 - val_accuracy: 0.8496\n",
            "Epoch 1694/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.2949 - val_accuracy: 0.8498\n",
            "Epoch 1695/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.3088 - val_accuracy: 0.8495\n",
            "Epoch 1696/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3025 - val_accuracy: 0.8481\n",
            "Epoch 1697/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.3125 - val_accuracy: 0.8517\n",
            "Epoch 1698/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 1.2836 - val_accuracy: 0.8505\n",
            "Epoch 1699/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 1.2813 - val_accuracy: 0.8516\n",
            "Epoch 1700/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2682 - val_accuracy: 0.8524\n",
            "Epoch 1701/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.2845 - val_accuracy: 0.8502\n",
            "Epoch 1702/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.2971 - val_accuracy: 0.8488\n",
            "Epoch 1703/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.2896 - val_accuracy: 0.8513\n",
            "Epoch 1704/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.2871 - val_accuracy: 0.8483\n",
            "Epoch 1705/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.3036 - val_accuracy: 0.8490\n",
            "Epoch 1706/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.2784 - val_accuracy: 0.8495\n",
            "Epoch 1707/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 1.2968 - val_accuracy: 0.8473\n",
            "Epoch 1708/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.2900 - val_accuracy: 0.8472\n",
            "Epoch 1709/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.2973 - val_accuracy: 0.8475\n",
            "Epoch 1710/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.2887 - val_accuracy: 0.8483\n",
            "Epoch 1711/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 1.3012 - val_accuracy: 0.8480\n",
            "Epoch 1712/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3024 - val_accuracy: 0.8499\n",
            "Epoch 1713/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3122 - val_accuracy: 0.8472\n",
            "Epoch 1714/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2971 - val_accuracy: 0.8490\n",
            "Epoch 1715/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.3089 - val_accuracy: 0.8511\n",
            "Epoch 1716/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.3123 - val_accuracy: 0.8499\n",
            "Epoch 1717/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.3132 - val_accuracy: 0.8484\n",
            "Epoch 1718/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.3182 - val_accuracy: 0.8490\n",
            "Epoch 1719/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 1.2965 - val_accuracy: 0.8500\n",
            "Epoch 1720/3000\n",
            "235/235 [==============================] - 5s 17ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.3130 - val_accuracy: 0.8482\n",
            "Epoch 1721/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.2931 - val_accuracy: 0.8495\n",
            "Epoch 1722/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.3006 - val_accuracy: 0.8467\n",
            "Epoch 1723/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 1.2973 - val_accuracy: 0.8495\n",
            "Epoch 1724/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.3084 - val_accuracy: 0.8483\n",
            "Epoch 1725/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 1.3057 - val_accuracy: 0.8479\n",
            "Epoch 1726/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3180 - val_accuracy: 0.8477\n",
            "Epoch 1727/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 1.3133 - val_accuracy: 0.8477\n",
            "Epoch 1728/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3212 - val_accuracy: 0.8462\n",
            "Epoch 1729/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.3127 - val_accuracy: 0.8459\n",
            "Epoch 1730/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 1.2901 - val_accuracy: 0.8465\n",
            "Epoch 1731/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.2770 - val_accuracy: 0.8504\n",
            "Epoch 1732/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 1.2925 - val_accuracy: 0.8488\n",
            "Epoch 1733/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 1.2722 - val_accuracy: 0.8506\n",
            "Epoch 1734/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.3027 - val_accuracy: 0.8487\n",
            "Epoch 1735/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2982 - val_accuracy: 0.8474\n",
            "Epoch 1736/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.2991 - val_accuracy: 0.8479\n",
            "Epoch 1737/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.3077 - val_accuracy: 0.8466\n",
            "Epoch 1738/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.3008 - val_accuracy: 0.8512\n",
            "Epoch 1739/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.2982 - val_accuracy: 0.8494\n",
            "Epoch 1740/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.3046 - val_accuracy: 0.8497\n",
            "Epoch 1741/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.2921 - val_accuracy: 0.8473\n",
            "Epoch 1742/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.2970 - val_accuracy: 0.8498\n",
            "Epoch 1743/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.2925 - val_accuracy: 0.8510\n",
            "Epoch 1744/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.3016 - val_accuracy: 0.8486\n",
            "Epoch 1745/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 1.3114 - val_accuracy: 0.8502\n",
            "Epoch 1746/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 1.3084 - val_accuracy: 0.8483\n",
            "Epoch 1747/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.2991 - val_accuracy: 0.8489\n",
            "Epoch 1748/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3040 - val_accuracy: 0.8492\n",
            "Epoch 1749/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2948 - val_accuracy: 0.8488\n",
            "Epoch 1750/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 1.3125 - val_accuracy: 0.8488\n",
            "Epoch 1751/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2981 - val_accuracy: 0.8471\n",
            "Epoch 1752/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.2918 - val_accuracy: 0.8482\n",
            "Epoch 1753/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2928 - val_accuracy: 0.8488\n",
            "Epoch 1754/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.3117 - val_accuracy: 0.8470\n",
            "Epoch 1755/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.2773 - val_accuracy: 0.8477\n",
            "Epoch 1756/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2949 - val_accuracy: 0.8492\n",
            "Epoch 1757/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 1.2785 - val_accuracy: 0.8482\n",
            "Epoch 1758/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.2798 - val_accuracy: 0.8500\n",
            "Epoch 1759/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.2826 - val_accuracy: 0.8491\n",
            "Epoch 1760/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.2946 - val_accuracy: 0.8473\n",
            "Epoch 1761/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.2723 - val_accuracy: 0.8488\n",
            "Epoch 1762/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2884 - val_accuracy: 0.8488\n",
            "Epoch 1763/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.2813 - val_accuracy: 0.8482\n",
            "Epoch 1764/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 1.2921 - val_accuracy: 0.8520\n",
            "Epoch 1765/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2873 - val_accuracy: 0.8516\n",
            "Epoch 1766/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 1.2902 - val_accuracy: 0.8494\n",
            "Epoch 1767/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.2973 - val_accuracy: 0.8501\n",
            "Epoch 1768/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.3064 - val_accuracy: 0.8504\n",
            "Epoch 1769/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.3162 - val_accuracy: 0.8462\n",
            "Epoch 1770/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.3036 - val_accuracy: 0.8482\n",
            "Epoch 1771/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.3130 - val_accuracy: 0.8503\n",
            "Epoch 1772/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.3073 - val_accuracy: 0.8504\n",
            "Epoch 1773/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.3042 - val_accuracy: 0.8491\n",
            "Epoch 1774/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 1.2960 - val_accuracy: 0.8513\n",
            "Epoch 1775/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.2959 - val_accuracy: 0.8520\n",
            "Epoch 1776/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 1.3093 - val_accuracy: 0.8508\n",
            "Epoch 1777/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 1.2974 - val_accuracy: 0.8518\n",
            "Epoch 1778/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.2986 - val_accuracy: 0.8506\n",
            "Epoch 1779/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.2846 - val_accuracy: 0.8499\n",
            "Epoch 1780/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.2971 - val_accuracy: 0.8480\n",
            "Epoch 1781/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3031 - val_accuracy: 0.8493\n",
            "Epoch 1782/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2965 - val_accuracy: 0.8480\n",
            "Epoch 1783/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.2924 - val_accuracy: 0.8496\n",
            "Epoch 1784/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.2894 - val_accuracy: 0.8482\n",
            "Epoch 1785/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.2937 - val_accuracy: 0.8479\n",
            "Epoch 1786/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.3102 - val_accuracy: 0.8476\n",
            "Epoch 1787/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 1.2950 - val_accuracy: 0.8479\n",
            "Epoch 1788/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.3131 - val_accuracy: 0.8475\n",
            "Epoch 1789/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.3042 - val_accuracy: 0.8498\n",
            "Epoch 1790/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 1.2983 - val_accuracy: 0.8476\n",
            "Epoch 1791/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.2970 - val_accuracy: 0.8491\n",
            "Epoch 1792/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.3144 - val_accuracy: 0.8506\n",
            "Epoch 1793/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3040 - val_accuracy: 0.8523\n",
            "Epoch 1794/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.3196 - val_accuracy: 0.8513\n",
            "Epoch 1795/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.2882 - val_accuracy: 0.8494\n",
            "Epoch 1796/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2885 - val_accuracy: 0.8524\n",
            "Epoch 1797/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2861 - val_accuracy: 0.8494\n",
            "Epoch 1798/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.2726 - val_accuracy: 0.8504\n",
            "Epoch 1799/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.2895 - val_accuracy: 0.8513\n",
            "Epoch 1800/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.2950 - val_accuracy: 0.8506\n",
            "Epoch 1801/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.2974 - val_accuracy: 0.8488\n",
            "Epoch 1802/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.3076 - val_accuracy: 0.8502\n",
            "Epoch 1803/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.2803 - val_accuracy: 0.8508\n",
            "Epoch 1804/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.2961 - val_accuracy: 0.8529\n",
            "Epoch 1805/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2713 - val_accuracy: 0.8534\n",
            "Epoch 1806/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 1.2911 - val_accuracy: 0.8497\n",
            "Epoch 1807/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3020 - val_accuracy: 0.8533\n",
            "Epoch 1808/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 1.3103 - val_accuracy: 0.8510\n",
            "Epoch 1809/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3034 - val_accuracy: 0.8520\n",
            "Epoch 1810/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.3110 - val_accuracy: 0.8485\n",
            "Epoch 1811/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.3201 - val_accuracy: 0.8474\n",
            "Epoch 1812/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.3185 - val_accuracy: 0.8489\n",
            "Epoch 1813/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2881 - val_accuracy: 0.8519\n",
            "Epoch 1814/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.2934 - val_accuracy: 0.8509\n",
            "Epoch 1815/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.2800 - val_accuracy: 0.8515\n",
            "Epoch 1816/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.2687 - val_accuracy: 0.8521\n",
            "Epoch 1817/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.2810 - val_accuracy: 0.8515\n",
            "Epoch 1818/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.2985 - val_accuracy: 0.8490\n",
            "Epoch 1819/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.2957 - val_accuracy: 0.8517\n",
            "Epoch 1820/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.2980 - val_accuracy: 0.8519\n",
            "Epoch 1821/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 1.2895 - val_accuracy: 0.8511\n",
            "Epoch 1822/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.2959 - val_accuracy: 0.8532\n",
            "Epoch 1823/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2875 - val_accuracy: 0.8518\n",
            "Epoch 1824/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.2814 - val_accuracy: 0.8494\n",
            "Epoch 1825/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.2974 - val_accuracy: 0.8507\n",
            "Epoch 1826/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.3047 - val_accuracy: 0.8505\n",
            "Epoch 1827/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2925 - val_accuracy: 0.8506\n",
            "Epoch 1828/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3015 - val_accuracy: 0.8529\n",
            "Epoch 1829/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.3003 - val_accuracy: 0.8509\n",
            "Epoch 1830/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3060 - val_accuracy: 0.8514\n",
            "Epoch 1831/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 1.3096 - val_accuracy: 0.8526\n",
            "Epoch 1832/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.2898 - val_accuracy: 0.8524\n",
            "Epoch 1833/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.2845 - val_accuracy: 0.8512\n",
            "Epoch 1834/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.2870 - val_accuracy: 0.8523\n",
            "Epoch 1835/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.2994 - val_accuracy: 0.8535\n",
            "Epoch 1836/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2869 - val_accuracy: 0.8544\n",
            "Epoch 1837/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 1.2992 - val_accuracy: 0.8515\n",
            "Epoch 1838/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.2950 - val_accuracy: 0.8513\n",
            "Epoch 1839/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.2923 - val_accuracy: 0.8501\n",
            "Epoch 1840/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.2971 - val_accuracy: 0.8515\n",
            "Epoch 1841/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.2971 - val_accuracy: 0.8492\n",
            "Epoch 1842/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 1.2929 - val_accuracy: 0.8498\n",
            "Epoch 1843/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.2838 - val_accuracy: 0.8508\n",
            "Epoch 1844/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 1.3004 - val_accuracy: 0.8502\n",
            "Epoch 1845/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.3001 - val_accuracy: 0.8510\n",
            "Epoch 1846/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.2933 - val_accuracy: 0.8518\n",
            "Epoch 1847/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.2925 - val_accuracy: 0.8515\n",
            "Epoch 1848/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3098 - val_accuracy: 0.8525\n",
            "Epoch 1849/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.3044 - val_accuracy: 0.8490\n",
            "Epoch 1850/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.2890 - val_accuracy: 0.8517\n",
            "Epoch 1851/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 1.2860 - val_accuracy: 0.8515\n",
            "Epoch 1852/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 1.2735 - val_accuracy: 0.8523\n",
            "Epoch 1853/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.2821 - val_accuracy: 0.8529\n",
            "Epoch 1854/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.2767 - val_accuracy: 0.8526\n",
            "Epoch 1855/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3026 - val_accuracy: 0.8547\n",
            "Epoch 1856/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2822 - val_accuracy: 0.8538\n",
            "Epoch 1857/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.2856 - val_accuracy: 0.8536\n",
            "Epoch 1858/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.3142 - val_accuracy: 0.8515\n",
            "Epoch 1859/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 1.2972 - val_accuracy: 0.8524\n",
            "Epoch 1860/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 1.2987 - val_accuracy: 0.8538\n",
            "Epoch 1861/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.2851 - val_accuracy: 0.8504\n",
            "Epoch 1862/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3062 - val_accuracy: 0.8514\n",
            "Epoch 1863/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.2907 - val_accuracy: 0.8517\n",
            "Epoch 1864/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.2815 - val_accuracy: 0.8510\n",
            "Epoch 1865/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2977 - val_accuracy: 0.8494\n",
            "Epoch 1866/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.3160 - val_accuracy: 0.8502\n",
            "Epoch 1867/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.2940 - val_accuracy: 0.8522\n",
            "Epoch 1868/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.2897 - val_accuracy: 0.8464\n",
            "Epoch 1869/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.2838 - val_accuracy: 0.8486\n",
            "Epoch 1870/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.2848 - val_accuracy: 0.8499\n",
            "Epoch 1871/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.2812 - val_accuracy: 0.8515\n",
            "Epoch 1872/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2851 - val_accuracy: 0.8514\n",
            "Epoch 1873/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.3038 - val_accuracy: 0.8502\n",
            "Epoch 1874/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.2925 - val_accuracy: 0.8474\n",
            "Epoch 1875/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.2809 - val_accuracy: 0.8494\n",
            "Epoch 1876/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.2877 - val_accuracy: 0.8499\n",
            "Epoch 1877/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 1.2952 - val_accuracy: 0.8527\n",
            "Epoch 1878/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 1.2813 - val_accuracy: 0.8508\n",
            "Epoch 1879/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2964 - val_accuracy: 0.8486\n",
            "Epoch 1880/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.2807 - val_accuracy: 0.8536\n",
            "Epoch 1881/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.2928 - val_accuracy: 0.8519\n",
            "Epoch 1882/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.2974 - val_accuracy: 0.8517\n",
            "Epoch 1883/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2918 - val_accuracy: 0.8540\n",
            "Epoch 1884/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.2969 - val_accuracy: 0.8521\n",
            "Epoch 1885/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 1.3074 - val_accuracy: 0.8494\n",
            "Epoch 1886/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 1.3077 - val_accuracy: 0.8503\n",
            "Epoch 1887/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.3201 - val_accuracy: 0.8493\n",
            "Epoch 1888/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.3300 - val_accuracy: 0.8507\n",
            "Epoch 1889/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3178 - val_accuracy: 0.8533\n",
            "Epoch 1890/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3231 - val_accuracy: 0.8496\n",
            "Epoch 1891/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.3296 - val_accuracy: 0.8491\n",
            "Epoch 1892/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 1.2898 - val_accuracy: 0.8494\n",
            "Epoch 1893/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3052 - val_accuracy: 0.8510\n",
            "Epoch 1894/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.3046 - val_accuracy: 0.8518\n",
            "Epoch 1895/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.2893 - val_accuracy: 0.8515\n",
            "Epoch 1896/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3118 - val_accuracy: 0.8494\n",
            "Epoch 1897/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.3140 - val_accuracy: 0.8478\n",
            "Epoch 1898/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.3220 - val_accuracy: 0.8497\n",
            "Epoch 1899/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.3297 - val_accuracy: 0.8496\n",
            "Epoch 1900/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.3110 - val_accuracy: 0.8489\n",
            "Epoch 1901/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.3267 - val_accuracy: 0.8511\n",
            "Epoch 1902/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.3246 - val_accuracy: 0.8485\n",
            "Epoch 1903/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 1.3049 - val_accuracy: 0.8495\n",
            "Epoch 1904/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.3129 - val_accuracy: 0.8499\n",
            "Epoch 1905/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.2969 - val_accuracy: 0.8505\n",
            "Epoch 1906/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.2916 - val_accuracy: 0.8497\n",
            "Epoch 1907/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 1.3003 - val_accuracy: 0.8487\n",
            "Epoch 1908/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.2919 - val_accuracy: 0.8505\n",
            "Epoch 1909/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.3069 - val_accuracy: 0.8483\n",
            "Epoch 1910/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 1.2873 - val_accuracy: 0.8492\n",
            "Epoch 1911/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.2883 - val_accuracy: 0.8477\n",
            "Epoch 1912/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3089 - val_accuracy: 0.8502\n",
            "Epoch 1913/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 1.2986 - val_accuracy: 0.8518\n",
            "Epoch 1914/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.2977 - val_accuracy: 0.8498\n",
            "Epoch 1915/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.2849 - val_accuracy: 0.8488\n",
            "Epoch 1916/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 1.3003 - val_accuracy: 0.8493\n",
            "Epoch 1917/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3042 - val_accuracy: 0.8490\n",
            "Epoch 1918/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 1.2838 - val_accuracy: 0.8477\n",
            "Epoch 1919/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.2962 - val_accuracy: 0.8462\n",
            "Epoch 1920/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.2970 - val_accuracy: 0.8488\n",
            "Epoch 1921/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.2998 - val_accuracy: 0.8490\n",
            "Epoch 1922/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3056 - val_accuracy: 0.8501\n",
            "Epoch 1923/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 1.2998 - val_accuracy: 0.8492\n",
            "Epoch 1924/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 1.3236 - val_accuracy: 0.8509\n",
            "Epoch 1925/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 1.3036 - val_accuracy: 0.8484\n",
            "Epoch 1926/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.3087 - val_accuracy: 0.8497\n",
            "Epoch 1927/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.3067 - val_accuracy: 0.8467\n",
            "Epoch 1928/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.3132 - val_accuracy: 0.8471\n",
            "Epoch 1929/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.3028 - val_accuracy: 0.8497\n",
            "Epoch 1930/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3177 - val_accuracy: 0.8496\n",
            "Epoch 1931/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3213 - val_accuracy: 0.8504\n",
            "Epoch 1932/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.3248 - val_accuracy: 0.8487\n",
            "Epoch 1933/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3252 - val_accuracy: 0.8480\n",
            "Epoch 1934/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.3127 - val_accuracy: 0.8492\n",
            "Epoch 1935/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.3315 - val_accuracy: 0.8492\n",
            "Epoch 1936/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.3337 - val_accuracy: 0.8496\n",
            "Epoch 1937/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 1.3305 - val_accuracy: 0.8496\n",
            "Epoch 1938/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3335 - val_accuracy: 0.8473\n",
            "Epoch 1939/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.3282 - val_accuracy: 0.8470\n",
            "Epoch 1940/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 1.3275 - val_accuracy: 0.8458\n",
            "Epoch 1941/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 1.3209 - val_accuracy: 0.8460\n",
            "Epoch 1942/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 1.3248 - val_accuracy: 0.8461\n",
            "Epoch 1943/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.3274 - val_accuracy: 0.8461\n",
            "Epoch 1944/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.3104 - val_accuracy: 0.8472\n",
            "Epoch 1945/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 1.3041 - val_accuracy: 0.8483\n",
            "Epoch 1946/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3055 - val_accuracy: 0.8490\n",
            "Epoch 1947/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.2851 - val_accuracy: 0.8491\n",
            "Epoch 1948/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3057 - val_accuracy: 0.8488\n",
            "Epoch 1949/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.3184 - val_accuracy: 0.8511\n",
            "Epoch 1950/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3087 - val_accuracy: 0.8485\n",
            "Epoch 1951/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3082 - val_accuracy: 0.8515\n",
            "Epoch 1952/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3171 - val_accuracy: 0.8480\n",
            "Epoch 1953/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3151 - val_accuracy: 0.8502\n",
            "Epoch 1954/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3046 - val_accuracy: 0.8499\n",
            "Epoch 1955/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3061 - val_accuracy: 0.8502\n",
            "Epoch 1956/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.2978 - val_accuracy: 0.8493\n",
            "Epoch 1957/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 1.2970 - val_accuracy: 0.8497\n",
            "Epoch 1958/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.3106 - val_accuracy: 0.8513\n",
            "Epoch 1959/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3035 - val_accuracy: 0.8478\n",
            "Epoch 1960/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.3102 - val_accuracy: 0.8515\n",
            "Epoch 1961/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.3078 - val_accuracy: 0.8509\n",
            "Epoch 1962/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.2986 - val_accuracy: 0.8504\n",
            "Epoch 1963/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 1.2843 - val_accuracy: 0.8492\n",
            "Epoch 1964/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.2919 - val_accuracy: 0.8523\n",
            "Epoch 1965/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.2972 - val_accuracy: 0.8512\n",
            "Epoch 1966/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.3077 - val_accuracy: 0.8529\n",
            "Epoch 1967/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.2961 - val_accuracy: 0.8472\n",
            "Epoch 1968/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.2960 - val_accuracy: 0.8485\n",
            "Epoch 1969/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3077 - val_accuracy: 0.8495\n",
            "Epoch 1970/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.3092 - val_accuracy: 0.8509\n",
            "Epoch 1971/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.2984 - val_accuracy: 0.8489\n",
            "Epoch 1972/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 1.3245 - val_accuracy: 0.8489\n",
            "Epoch 1973/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3262 - val_accuracy: 0.8489\n",
            "Epoch 1974/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.3132 - val_accuracy: 0.8501\n",
            "Epoch 1975/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.3071 - val_accuracy: 0.8502\n",
            "Epoch 1976/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.2974 - val_accuracy: 0.8500\n",
            "Epoch 1977/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3026 - val_accuracy: 0.8491\n",
            "Epoch 1978/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.3158 - val_accuracy: 0.8494\n",
            "Epoch 1979/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.2877 - val_accuracy: 0.8504\n",
            "Epoch 1980/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 1.2972 - val_accuracy: 0.8534\n",
            "Epoch 1981/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3039 - val_accuracy: 0.8508\n",
            "Epoch 1982/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 1.2926 - val_accuracy: 0.8503\n",
            "Epoch 1983/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.3050 - val_accuracy: 0.8490\n",
            "Epoch 1984/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.2961 - val_accuracy: 0.8519\n",
            "Epoch 1985/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 1.2870 - val_accuracy: 0.8500\n",
            "Epoch 1986/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.2923 - val_accuracy: 0.8479\n",
            "Epoch 1987/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.2964 - val_accuracy: 0.8507\n",
            "Epoch 1988/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3050 - val_accuracy: 0.8500\n",
            "Epoch 1989/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3022 - val_accuracy: 0.8481\n",
            "Epoch 1990/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.3077 - val_accuracy: 0.8523\n",
            "Epoch 1991/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.2882 - val_accuracy: 0.8508\n",
            "Epoch 1992/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.2962 - val_accuracy: 0.8505\n",
            "Epoch 1993/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 1.3181 - val_accuracy: 0.8485\n",
            "Epoch 1994/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 1.3027 - val_accuracy: 0.8490\n",
            "Epoch 1995/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.3125 - val_accuracy: 0.8502\n",
            "Epoch 1996/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.3111 - val_accuracy: 0.8489\n",
            "Epoch 1997/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.3085 - val_accuracy: 0.8507\n",
            "Epoch 1998/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3030 - val_accuracy: 0.8500\n",
            "Epoch 1999/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3097 - val_accuracy: 0.8475\n",
            "Epoch 2000/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.3184 - val_accuracy: 0.8507\n",
            "Epoch 2001/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.3184 - val_accuracy: 0.8515\n",
            "Epoch 2002/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.3236 - val_accuracy: 0.8491\n",
            "Epoch 2003/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.3070 - val_accuracy: 0.8506\n",
            "Epoch 2004/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.3097 - val_accuracy: 0.8509\n",
            "Epoch 2005/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.2995 - val_accuracy: 0.8517\n",
            "Epoch 2006/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.2742 - val_accuracy: 0.8510\n",
            "Epoch 2007/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.2875 - val_accuracy: 0.8500\n",
            "Epoch 2008/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.3082 - val_accuracy: 0.8489\n",
            "Epoch 2009/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.3161 - val_accuracy: 0.8504\n",
            "Epoch 2010/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3104 - val_accuracy: 0.8491\n",
            "Epoch 2011/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.3149 - val_accuracy: 0.8487\n",
            "Epoch 2012/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.3141 - val_accuracy: 0.8478\n",
            "Epoch 2013/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3128 - val_accuracy: 0.8492\n",
            "Epoch 2014/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.3111 - val_accuracy: 0.8502\n",
            "Epoch 2015/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3229 - val_accuracy: 0.8493\n",
            "Epoch 2016/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.3182 - val_accuracy: 0.8512\n",
            "Epoch 2017/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3037 - val_accuracy: 0.8497\n",
            "Epoch 2018/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.3246 - val_accuracy: 0.8487\n",
            "Epoch 2019/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3134 - val_accuracy: 0.8521\n",
            "Epoch 2020/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.3092 - val_accuracy: 0.8503\n",
            "Epoch 2021/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3091 - val_accuracy: 0.8490\n",
            "Epoch 2022/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.3141 - val_accuracy: 0.8496\n",
            "Epoch 2023/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.3121 - val_accuracy: 0.8495\n",
            "Epoch 2024/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3129 - val_accuracy: 0.8484\n",
            "Epoch 2025/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.3053 - val_accuracy: 0.8489\n",
            "Epoch 2026/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.3020 - val_accuracy: 0.8510\n",
            "Epoch 2027/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.2961 - val_accuracy: 0.8488\n",
            "Epoch 2028/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 1.3072 - val_accuracy: 0.8501\n",
            "Epoch 2029/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3149 - val_accuracy: 0.8462\n",
            "Epoch 2030/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.3022 - val_accuracy: 0.8479\n",
            "Epoch 2031/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.3155 - val_accuracy: 0.8487\n",
            "Epoch 2032/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.3091 - val_accuracy: 0.8496\n",
            "Epoch 2033/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3224 - val_accuracy: 0.8503\n",
            "Epoch 2034/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.3197 - val_accuracy: 0.8475\n",
            "Epoch 2035/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.3131 - val_accuracy: 0.8499\n",
            "Epoch 2036/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.3187 - val_accuracy: 0.8512\n",
            "Epoch 2037/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3203 - val_accuracy: 0.8500\n",
            "Epoch 2038/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3205 - val_accuracy: 0.8509\n",
            "Epoch 2039/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.3315 - val_accuracy: 0.8502\n",
            "Epoch 2040/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 1.3189 - val_accuracy: 0.8504\n",
            "Epoch 2041/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3277 - val_accuracy: 0.8502\n",
            "Epoch 2042/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.3210 - val_accuracy: 0.8504\n",
            "Epoch 2043/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 1.3026 - val_accuracy: 0.8535\n",
            "Epoch 2044/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 1.2954 - val_accuracy: 0.8505\n",
            "Epoch 2045/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.2992 - val_accuracy: 0.8489\n",
            "Epoch 2046/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.2897 - val_accuracy: 0.8519\n",
            "Epoch 2047/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.3050 - val_accuracy: 0.8478\n",
            "Epoch 2048/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.2915 - val_accuracy: 0.8502\n",
            "Epoch 2049/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.2922 - val_accuracy: 0.8487\n",
            "Epoch 2050/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3063 - val_accuracy: 0.8495\n",
            "Epoch 2051/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.2995 - val_accuracy: 0.8511\n",
            "Epoch 2052/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.2785 - val_accuracy: 0.8509\n",
            "Epoch 2053/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.2885 - val_accuracy: 0.8517\n",
            "Epoch 2054/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.3055 - val_accuracy: 0.8523\n",
            "Epoch 2055/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.3091 - val_accuracy: 0.8519\n",
            "Epoch 2056/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3170 - val_accuracy: 0.8505\n",
            "Epoch 2057/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3267 - val_accuracy: 0.8521\n",
            "Epoch 2058/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3299 - val_accuracy: 0.8503\n",
            "Epoch 2059/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.3280 - val_accuracy: 0.8515\n",
            "Epoch 2060/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.3222 - val_accuracy: 0.8499\n",
            "Epoch 2061/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3472 - val_accuracy: 0.8502\n",
            "Epoch 2062/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.3402 - val_accuracy: 0.8514\n",
            "Epoch 2063/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3244 - val_accuracy: 0.8540\n",
            "Epoch 2064/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3325 - val_accuracy: 0.8522\n",
            "Epoch 2065/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3248 - val_accuracy: 0.8515\n",
            "Epoch 2066/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3384 - val_accuracy: 0.8504\n",
            "Epoch 2067/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.3317 - val_accuracy: 0.8491\n",
            "Epoch 2068/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3242 - val_accuracy: 0.8512\n",
            "Epoch 2069/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 1.3270 - val_accuracy: 0.8499\n",
            "Epoch 2070/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3097 - val_accuracy: 0.8472\n",
            "Epoch 2071/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3253 - val_accuracy: 0.8500\n",
            "Epoch 2072/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3458 - val_accuracy: 0.8519\n",
            "Epoch 2073/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3310 - val_accuracy: 0.8483\n",
            "Epoch 2074/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3386 - val_accuracy: 0.8501\n",
            "Epoch 2075/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.3242 - val_accuracy: 0.8499\n",
            "Epoch 2076/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3443 - val_accuracy: 0.8513\n",
            "Epoch 2077/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3309 - val_accuracy: 0.8509\n",
            "Epoch 2078/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 1.3233 - val_accuracy: 0.8510\n",
            "Epoch 2079/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.3047 - val_accuracy: 0.8515\n",
            "Epoch 2080/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3058 - val_accuracy: 0.8498\n",
            "Epoch 2081/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.2979 - val_accuracy: 0.8498\n",
            "Epoch 2082/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.3136 - val_accuracy: 0.8513\n",
            "Epoch 2083/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3272 - val_accuracy: 0.8513\n",
            "Epoch 2084/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3062 - val_accuracy: 0.8511\n",
            "Epoch 2085/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.2964 - val_accuracy: 0.8492\n",
            "Epoch 2086/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3087 - val_accuracy: 0.8512\n",
            "Epoch 2087/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3194 - val_accuracy: 0.8504\n",
            "Epoch 2088/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.3324 - val_accuracy: 0.8510\n",
            "Epoch 2089/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3239 - val_accuracy: 0.8491\n",
            "Epoch 2090/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3343 - val_accuracy: 0.8509\n",
            "Epoch 2091/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3335 - val_accuracy: 0.8506\n",
            "Epoch 2092/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3280 - val_accuracy: 0.8503\n",
            "Epoch 2093/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3240 - val_accuracy: 0.8503\n",
            "Epoch 2094/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3250 - val_accuracy: 0.8516\n",
            "Epoch 2095/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3354 - val_accuracy: 0.8503\n",
            "Epoch 2096/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.3380 - val_accuracy: 0.8507\n",
            "Epoch 2097/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3301 - val_accuracy: 0.8521\n",
            "Epoch 2098/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.3388 - val_accuracy: 0.8504\n",
            "Epoch 2099/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.3384 - val_accuracy: 0.8502\n",
            "Epoch 2100/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.3249 - val_accuracy: 0.8529\n",
            "Epoch 2101/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.3252 - val_accuracy: 0.8516\n",
            "Epoch 2102/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3290 - val_accuracy: 0.8507\n",
            "Epoch 2103/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3119 - val_accuracy: 0.8534\n",
            "Epoch 2104/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3331 - val_accuracy: 0.8511\n",
            "Epoch 2105/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3159 - val_accuracy: 0.8503\n",
            "Epoch 2106/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3316 - val_accuracy: 0.8527\n",
            "Epoch 2107/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.2869 - val_accuracy: 0.8525\n",
            "Epoch 2108/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.3068 - val_accuracy: 0.8501\n",
            "Epoch 2109/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 1.3010 - val_accuracy: 0.8511\n",
            "Epoch 2110/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.3052 - val_accuracy: 0.8505\n",
            "Epoch 2111/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.2986 - val_accuracy: 0.8493\n",
            "Epoch 2112/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.3115 - val_accuracy: 0.8519\n",
            "Epoch 2113/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3001 - val_accuracy: 0.8515\n",
            "Epoch 2114/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.2966 - val_accuracy: 0.8504\n",
            "Epoch 2115/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.3083 - val_accuracy: 0.8531\n",
            "Epoch 2116/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.3112 - val_accuracy: 0.8499\n",
            "Epoch 2117/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.3199 - val_accuracy: 0.8492\n",
            "Epoch 2118/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.3135 - val_accuracy: 0.8490\n",
            "Epoch 2119/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3217 - val_accuracy: 0.8482\n",
            "Epoch 2120/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.3129 - val_accuracy: 0.8508\n",
            "Epoch 2121/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 1.3095 - val_accuracy: 0.8497\n",
            "Epoch 2122/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.3065 - val_accuracy: 0.8517\n",
            "Epoch 2123/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3036 - val_accuracy: 0.8518\n",
            "Epoch 2124/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3015 - val_accuracy: 0.8494\n",
            "Epoch 2125/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.3038 - val_accuracy: 0.8476\n",
            "Epoch 2126/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3202 - val_accuracy: 0.8476\n",
            "Epoch 2127/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.2991 - val_accuracy: 0.8509\n",
            "Epoch 2128/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.2942 - val_accuracy: 0.8502\n",
            "Epoch 2129/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 1.3127 - val_accuracy: 0.8500\n",
            "Epoch 2130/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 1.3000 - val_accuracy: 0.8508\n",
            "Epoch 2131/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3077 - val_accuracy: 0.8504\n",
            "Epoch 2132/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.3297 - val_accuracy: 0.8494\n",
            "Epoch 2133/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3273 - val_accuracy: 0.8497\n",
            "Epoch 2134/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 1.3276 - val_accuracy: 0.8499\n",
            "Epoch 2135/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 1.3264 - val_accuracy: 0.8517\n",
            "Epoch 2136/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 1.3252 - val_accuracy: 0.8513\n",
            "Epoch 2137/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.3214 - val_accuracy: 0.8505\n",
            "Epoch 2138/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3306 - val_accuracy: 0.8484\n",
            "Epoch 2139/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.3297 - val_accuracy: 0.8498\n",
            "Epoch 2140/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3083 - val_accuracy: 0.8482\n",
            "Epoch 2141/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.3256 - val_accuracy: 0.8508\n",
            "Epoch 2142/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3227 - val_accuracy: 0.8490\n",
            "Epoch 2143/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 1.3022 - val_accuracy: 0.8508\n",
            "Epoch 2144/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3110 - val_accuracy: 0.8497\n",
            "Epoch 2145/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3092 - val_accuracy: 0.8507\n",
            "Epoch 2146/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.3150 - val_accuracy: 0.8484\n",
            "Epoch 2147/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3141 - val_accuracy: 0.8510\n",
            "Epoch 2148/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.3250 - val_accuracy: 0.8508\n",
            "Epoch 2149/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.3267 - val_accuracy: 0.8509\n",
            "Epoch 2150/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3145 - val_accuracy: 0.8500\n",
            "Epoch 2151/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 1.3232 - val_accuracy: 0.8495\n",
            "Epoch 2152/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3168 - val_accuracy: 0.8494\n",
            "Epoch 2153/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.3153 - val_accuracy: 0.8501\n",
            "Epoch 2154/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3159 - val_accuracy: 0.8493\n",
            "Epoch 2155/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3215 - val_accuracy: 0.8502\n",
            "Epoch 2156/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3371 - val_accuracy: 0.8484\n",
            "Epoch 2157/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3242 - val_accuracy: 0.8484\n",
            "Epoch 2158/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.3238 - val_accuracy: 0.8491\n",
            "Epoch 2159/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 1.3262 - val_accuracy: 0.8500\n",
            "Epoch 2160/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3172 - val_accuracy: 0.8522\n",
            "Epoch 2161/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.3087 - val_accuracy: 0.8527\n",
            "Epoch 2162/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3141 - val_accuracy: 0.8495\n",
            "Epoch 2163/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.3215 - val_accuracy: 0.8487\n",
            "Epoch 2164/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.3308 - val_accuracy: 0.8494\n",
            "Epoch 2165/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3299 - val_accuracy: 0.8493\n",
            "Epoch 2166/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.3378 - val_accuracy: 0.8488\n",
            "Epoch 2167/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.3380 - val_accuracy: 0.8488\n",
            "Epoch 2168/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3459 - val_accuracy: 0.8468\n",
            "Epoch 2169/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3321 - val_accuracy: 0.8473\n",
            "Epoch 2170/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.3415 - val_accuracy: 0.8476\n",
            "Epoch 2171/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3432 - val_accuracy: 0.8483\n",
            "Epoch 2172/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.3423 - val_accuracy: 0.8479\n",
            "Epoch 2173/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3332 - val_accuracy: 0.8500\n",
            "Epoch 2174/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.3428 - val_accuracy: 0.8477\n",
            "Epoch 2175/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3297 - val_accuracy: 0.8513\n",
            "Epoch 2176/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.3157 - val_accuracy: 0.8514\n",
            "Epoch 2177/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.3250 - val_accuracy: 0.8490\n",
            "Epoch 2178/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3329 - val_accuracy: 0.8517\n",
            "Epoch 2179/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.3287 - val_accuracy: 0.8504\n",
            "Epoch 2180/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3100 - val_accuracy: 0.8513\n",
            "Epoch 2181/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.3212 - val_accuracy: 0.8519\n",
            "Epoch 2182/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3200 - val_accuracy: 0.8512\n",
            "Epoch 2183/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3287 - val_accuracy: 0.8507\n",
            "Epoch 2184/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3265 - val_accuracy: 0.8498\n",
            "Epoch 2185/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3091 - val_accuracy: 0.8494\n",
            "Epoch 2186/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3426 - val_accuracy: 0.8499\n",
            "Epoch 2187/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3282 - val_accuracy: 0.8502\n",
            "Epoch 2188/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3363 - val_accuracy: 0.8504\n",
            "Epoch 2189/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.3324 - val_accuracy: 0.8519\n",
            "Epoch 2190/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 1.3217 - val_accuracy: 0.8537\n",
            "Epoch 2191/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 1.3411 - val_accuracy: 0.8517\n",
            "Epoch 2192/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.3299 - val_accuracy: 0.8504\n",
            "Epoch 2193/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3457 - val_accuracy: 0.8502\n",
            "Epoch 2194/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3368 - val_accuracy: 0.8505\n",
            "Epoch 2195/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.3321 - val_accuracy: 0.8490\n",
            "Epoch 2196/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.3209 - val_accuracy: 0.8498\n",
            "Epoch 2197/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.3040 - val_accuracy: 0.8519\n",
            "Epoch 2198/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.3147 - val_accuracy: 0.8492\n",
            "Epoch 2199/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3295 - val_accuracy: 0.8486\n",
            "Epoch 2200/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3265 - val_accuracy: 0.8506\n",
            "Epoch 2201/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.3247 - val_accuracy: 0.8519\n",
            "Epoch 2202/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 1.3248 - val_accuracy: 0.8516\n",
            "Epoch 2203/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3267 - val_accuracy: 0.8502\n",
            "Epoch 2204/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 1.3216 - val_accuracy: 0.8504\n",
            "Epoch 2205/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 1.3107 - val_accuracy: 0.8503\n",
            "Epoch 2206/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3188 - val_accuracy: 0.8521\n",
            "Epoch 2207/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3335 - val_accuracy: 0.8508\n",
            "Epoch 2208/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.3474 - val_accuracy: 0.8485\n",
            "Epoch 2209/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3270 - val_accuracy: 0.8501\n",
            "Epoch 2210/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3294 - val_accuracy: 0.8529\n",
            "Epoch 2211/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3390 - val_accuracy: 0.8510\n",
            "Epoch 2212/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.3142 - val_accuracy: 0.8509\n",
            "Epoch 2213/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3183 - val_accuracy: 0.8494\n",
            "Epoch 2214/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3332 - val_accuracy: 0.8508\n",
            "Epoch 2215/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3323 - val_accuracy: 0.8524\n",
            "Epoch 2216/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.3339 - val_accuracy: 0.8520\n",
            "Epoch 2217/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3102 - val_accuracy: 0.8509\n",
            "Epoch 2218/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.3247 - val_accuracy: 0.8501\n",
            "Epoch 2219/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.3334 - val_accuracy: 0.8513\n",
            "Epoch 2220/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3481 - val_accuracy: 0.8487\n",
            "Epoch 2221/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 1.3347 - val_accuracy: 0.8487\n",
            "Epoch 2222/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.3347 - val_accuracy: 0.8485\n",
            "Epoch 2223/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3178 - val_accuracy: 0.8518\n",
            "Epoch 2224/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3159 - val_accuracy: 0.8521\n",
            "Epoch 2225/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3265 - val_accuracy: 0.8508\n",
            "Epoch 2226/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.3198 - val_accuracy: 0.8505\n",
            "Epoch 2227/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3160 - val_accuracy: 0.8523\n",
            "Epoch 2228/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.2997 - val_accuracy: 0.8514\n",
            "Epoch 2229/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 1.3076 - val_accuracy: 0.8506\n",
            "Epoch 2230/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3005 - val_accuracy: 0.8502\n",
            "Epoch 2231/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 1.2830 - val_accuracy: 0.8492\n",
            "Epoch 2232/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.2968 - val_accuracy: 0.8459\n",
            "Epoch 2233/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3191 - val_accuracy: 0.8488\n",
            "Epoch 2234/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.3366 - val_accuracy: 0.8485\n",
            "Epoch 2235/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 1.3289 - val_accuracy: 0.8481\n",
            "Epoch 2236/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 1.3298 - val_accuracy: 0.8477\n",
            "Epoch 2237/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.3213 - val_accuracy: 0.8503\n",
            "Epoch 2238/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 1.3179 - val_accuracy: 0.8483\n",
            "Epoch 2239/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.3324 - val_accuracy: 0.8503\n",
            "Epoch 2240/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3263 - val_accuracy: 0.8498\n",
            "Epoch 2241/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 1.3356 - val_accuracy: 0.8504\n",
            "Epoch 2242/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3167 - val_accuracy: 0.8515\n",
            "Epoch 2243/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.3270 - val_accuracy: 0.8506\n",
            "Epoch 2244/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.3011 - val_accuracy: 0.8514\n",
            "Epoch 2245/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3252 - val_accuracy: 0.8494\n",
            "Epoch 2246/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3167 - val_accuracy: 0.8480\n",
            "Epoch 2247/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3147 - val_accuracy: 0.8471\n",
            "Epoch 2248/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 1.3173 - val_accuracy: 0.8493\n",
            "Epoch 2249/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3036 - val_accuracy: 0.8507\n",
            "Epoch 2250/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.3048 - val_accuracy: 0.8504\n",
            "Epoch 2251/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3042 - val_accuracy: 0.8492\n",
            "Epoch 2252/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.3179 - val_accuracy: 0.8491\n",
            "Epoch 2253/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3214 - val_accuracy: 0.8483\n",
            "Epoch 2254/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3055 - val_accuracy: 0.8487\n",
            "Epoch 2255/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3357 - val_accuracy: 0.8506\n",
            "Epoch 2256/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3198 - val_accuracy: 0.8485\n",
            "Epoch 2257/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 1.3294 - val_accuracy: 0.8516\n",
            "Epoch 2258/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.3227 - val_accuracy: 0.8518\n",
            "Epoch 2259/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.2935 - val_accuracy: 0.8512\n",
            "Epoch 2260/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 1.3270 - val_accuracy: 0.8478\n",
            "Epoch 2261/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3022 - val_accuracy: 0.8492\n",
            "Epoch 2262/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3214 - val_accuracy: 0.8498\n",
            "Epoch 2263/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 1.3109 - val_accuracy: 0.8519\n",
            "Epoch 2264/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 1.3149 - val_accuracy: 0.8512\n",
            "Epoch 2265/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.3052 - val_accuracy: 0.8486\n",
            "Epoch 2266/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.3220 - val_accuracy: 0.8502\n",
            "Epoch 2267/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.3120 - val_accuracy: 0.8529\n",
            "Epoch 2268/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.3153 - val_accuracy: 0.8497\n",
            "Epoch 2269/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.3134 - val_accuracy: 0.8539\n",
            "Epoch 2270/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.3263 - val_accuracy: 0.8490\n",
            "Epoch 2271/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3086 - val_accuracy: 0.8519\n",
            "Epoch 2272/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3082 - val_accuracy: 0.8506\n",
            "Epoch 2273/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3169 - val_accuracy: 0.8522\n",
            "Epoch 2274/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3236 - val_accuracy: 0.8492\n",
            "Epoch 2275/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.3078 - val_accuracy: 0.8484\n",
            "Epoch 2276/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3140 - val_accuracy: 0.8506\n",
            "Epoch 2277/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.3251 - val_accuracy: 0.8488\n",
            "Epoch 2278/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3364 - val_accuracy: 0.8482\n",
            "Epoch 2279/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3282 - val_accuracy: 0.8485\n",
            "Epoch 2280/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3161 - val_accuracy: 0.8490\n",
            "Epoch 2281/3000\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3327 - val_accuracy: 0.8482\n",
            "Epoch 2282/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3238 - val_accuracy: 0.8467\n",
            "Epoch 2283/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3283 - val_accuracy: 0.8477\n",
            "Epoch 2284/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3358 - val_accuracy: 0.8474\n",
            "Epoch 2285/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3263 - val_accuracy: 0.8488\n",
            "Epoch 2286/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3178 - val_accuracy: 0.8463\n",
            "Epoch 2287/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3048 - val_accuracy: 0.8490\n",
            "Epoch 2288/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3029 - val_accuracy: 0.8492\n",
            "Epoch 2289/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3031 - val_accuracy: 0.8507\n",
            "Epoch 2290/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3265 - val_accuracy: 0.8487\n",
            "Epoch 2291/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.3284 - val_accuracy: 0.8494\n",
            "Epoch 2292/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3237 - val_accuracy: 0.8492\n",
            "Epoch 2293/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.3284 - val_accuracy: 0.8485\n",
            "Epoch 2294/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3177 - val_accuracy: 0.8498\n",
            "Epoch 2295/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 1.3306 - val_accuracy: 0.8475\n",
            "Epoch 2296/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.3270 - val_accuracy: 0.8468\n",
            "Epoch 2297/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 1.3353 - val_accuracy: 0.8483\n",
            "Epoch 2298/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 1.3195 - val_accuracy: 0.8487\n",
            "Epoch 2299/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3307 - val_accuracy: 0.8480\n",
            "Epoch 2300/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3384 - val_accuracy: 0.8475\n",
            "Epoch 2301/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3271 - val_accuracy: 0.8483\n",
            "Epoch 2302/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.3213 - val_accuracy: 0.8483\n",
            "Epoch 2303/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.3137 - val_accuracy: 0.8490\n",
            "Epoch 2304/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.3328 - val_accuracy: 0.8507\n",
            "Epoch 2305/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3195 - val_accuracy: 0.8492\n",
            "Epoch 2306/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3312 - val_accuracy: 0.8491\n",
            "Epoch 2307/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.3317 - val_accuracy: 0.8480\n",
            "Epoch 2308/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3562 - val_accuracy: 0.8463\n",
            "Epoch 2309/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3462 - val_accuracy: 0.8473\n",
            "Epoch 2310/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.3422 - val_accuracy: 0.8528\n",
            "Epoch 2311/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.3381 - val_accuracy: 0.8500\n",
            "Epoch 2312/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3417 - val_accuracy: 0.8485\n",
            "Epoch 2313/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.3118 - val_accuracy: 0.8501\n",
            "Epoch 2314/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 1.3195 - val_accuracy: 0.8466\n",
            "Epoch 2315/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3379 - val_accuracy: 0.8501\n",
            "Epoch 2316/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.3264 - val_accuracy: 0.8497\n",
            "Epoch 2317/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3259 - val_accuracy: 0.8505\n",
            "Epoch 2318/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3170 - val_accuracy: 0.8493\n",
            "Epoch 2319/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 1.3064 - val_accuracy: 0.8505\n",
            "Epoch 2320/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3139 - val_accuracy: 0.8494\n",
            "Epoch 2321/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 1.3398 - val_accuracy: 0.8492\n",
            "Epoch 2322/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3244 - val_accuracy: 0.8515\n",
            "Epoch 2323/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 1.3141 - val_accuracy: 0.8508\n",
            "Epoch 2324/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3246 - val_accuracy: 0.8531\n",
            "Epoch 2325/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3225 - val_accuracy: 0.8498\n",
            "Epoch 2326/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3296 - val_accuracy: 0.8518\n",
            "Epoch 2327/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3296 - val_accuracy: 0.8481\n",
            "Epoch 2328/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3316 - val_accuracy: 0.8494\n",
            "Epoch 2329/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3243 - val_accuracy: 0.8505\n",
            "Epoch 2330/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3381 - val_accuracy: 0.8514\n",
            "Epoch 2331/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3459 - val_accuracy: 0.8510\n",
            "Epoch 2332/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.3324 - val_accuracy: 0.8507\n",
            "Epoch 2333/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3248 - val_accuracy: 0.8515\n",
            "Epoch 2334/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 1.3347 - val_accuracy: 0.8521\n",
            "Epoch 2335/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.3259 - val_accuracy: 0.8526\n",
            "Epoch 2336/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3323 - val_accuracy: 0.8537\n",
            "Epoch 2337/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3286 - val_accuracy: 0.8499\n",
            "Epoch 2338/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3219 - val_accuracy: 0.8518\n",
            "Epoch 2339/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3419 - val_accuracy: 0.8516\n",
            "Epoch 2340/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3513 - val_accuracy: 0.8512\n",
            "Epoch 2341/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3429 - val_accuracy: 0.8513\n",
            "Epoch 2342/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3346 - val_accuracy: 0.8517\n",
            "Epoch 2343/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 1.3258 - val_accuracy: 0.8514\n",
            "Epoch 2344/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3273 - val_accuracy: 0.8524\n",
            "Epoch 2345/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3408 - val_accuracy: 0.8517\n",
            "Epoch 2346/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3326 - val_accuracy: 0.8514\n",
            "Epoch 2347/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 1.3509 - val_accuracy: 0.8499\n",
            "Epoch 2348/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.3237 - val_accuracy: 0.8513\n",
            "Epoch 2349/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3204 - val_accuracy: 0.8545\n",
            "Epoch 2350/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3301 - val_accuracy: 0.8489\n",
            "Epoch 2351/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3246 - val_accuracy: 0.8521\n",
            "Epoch 2352/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3246 - val_accuracy: 0.8538\n",
            "Epoch 2353/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.3191 - val_accuracy: 0.8517\n",
            "Epoch 2354/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 1.3136 - val_accuracy: 0.8529\n",
            "Epoch 2355/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3043 - val_accuracy: 0.8538\n",
            "Epoch 2356/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3296 - val_accuracy: 0.8531\n",
            "Epoch 2357/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.3177 - val_accuracy: 0.8513\n",
            "Epoch 2358/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3287 - val_accuracy: 0.8515\n",
            "Epoch 2359/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3216 - val_accuracy: 0.8528\n",
            "Epoch 2360/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3194 - val_accuracy: 0.8516\n",
            "Epoch 2361/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3239 - val_accuracy: 0.8494\n",
            "Epoch 2362/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.3346 - val_accuracy: 0.8527\n",
            "Epoch 2363/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.3193 - val_accuracy: 0.8525\n",
            "Epoch 2364/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 1.3270 - val_accuracy: 0.8524\n",
            "Epoch 2365/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 1.3351 - val_accuracy: 0.8504\n",
            "Epoch 2366/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.3338 - val_accuracy: 0.8499\n",
            "Epoch 2367/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3128 - val_accuracy: 0.8493\n",
            "Epoch 2368/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 1.3292 - val_accuracy: 0.8503\n",
            "Epoch 2369/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3386 - val_accuracy: 0.8508\n",
            "Epoch 2370/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3277 - val_accuracy: 0.8500\n",
            "Epoch 2371/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3168 - val_accuracy: 0.8485\n",
            "Epoch 2372/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3327 - val_accuracy: 0.8514\n",
            "Epoch 2373/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3255 - val_accuracy: 0.8525\n",
            "Epoch 2374/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 1.3215 - val_accuracy: 0.8521\n",
            "Epoch 2375/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3188 - val_accuracy: 0.8489\n",
            "Epoch 2376/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3335 - val_accuracy: 0.8503\n",
            "Epoch 2377/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3323 - val_accuracy: 0.8527\n",
            "Epoch 2378/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3172 - val_accuracy: 0.8496\n",
            "Epoch 2379/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3563 - val_accuracy: 0.8499\n",
            "Epoch 2380/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.3302 - val_accuracy: 0.8494\n",
            "Epoch 2381/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3195 - val_accuracy: 0.8523\n",
            "Epoch 2382/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3336 - val_accuracy: 0.8505\n",
            "Epoch 2383/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3182 - val_accuracy: 0.8534\n",
            "Epoch 2384/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3333 - val_accuracy: 0.8488\n",
            "Epoch 2385/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3436 - val_accuracy: 0.8502\n",
            "Epoch 2386/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3395 - val_accuracy: 0.8492\n",
            "Epoch 2387/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.3390 - val_accuracy: 0.8484\n",
            "Epoch 2388/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3349 - val_accuracy: 0.8498\n",
            "Epoch 2389/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.3314 - val_accuracy: 0.8505\n",
            "Epoch 2390/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3207 - val_accuracy: 0.8510\n",
            "Epoch 2391/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.3427 - val_accuracy: 0.8488\n",
            "Epoch 2392/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.3405 - val_accuracy: 0.8507\n",
            "Epoch 2393/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3175 - val_accuracy: 0.8516\n",
            "Epoch 2394/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3285 - val_accuracy: 0.8508\n",
            "Epoch 2395/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 1.3305 - val_accuracy: 0.8493\n",
            "Epoch 2396/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3237 - val_accuracy: 0.8522\n",
            "Epoch 2397/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3280 - val_accuracy: 0.8493\n",
            "Epoch 2398/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3188 - val_accuracy: 0.8490\n",
            "Epoch 2399/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3422 - val_accuracy: 0.8480\n",
            "Epoch 2400/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3446 - val_accuracy: 0.8481\n",
            "Epoch 2401/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 1.3408 - val_accuracy: 0.8511\n",
            "Epoch 2402/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3367 - val_accuracy: 0.8490\n",
            "Epoch 2403/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3530 - val_accuracy: 0.8517\n",
            "Epoch 2404/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.3353 - val_accuracy: 0.8490\n",
            "Epoch 2405/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.3411 - val_accuracy: 0.8491\n",
            "Epoch 2406/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.3488 - val_accuracy: 0.8481\n",
            "Epoch 2407/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3482 - val_accuracy: 0.8499\n",
            "Epoch 2408/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3391 - val_accuracy: 0.8529\n",
            "Epoch 2409/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.3271 - val_accuracy: 0.8496\n",
            "Epoch 2410/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3339 - val_accuracy: 0.8481\n",
            "Epoch 2411/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3374 - val_accuracy: 0.8477\n",
            "Epoch 2412/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3251 - val_accuracy: 0.8498\n",
            "Epoch 2413/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3283 - val_accuracy: 0.8505\n",
            "Epoch 2414/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.3169 - val_accuracy: 0.8513\n",
            "Epoch 2415/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3073 - val_accuracy: 0.8471\n",
            "Epoch 2416/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.3150 - val_accuracy: 0.8510\n",
            "Epoch 2417/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3137 - val_accuracy: 0.8504\n",
            "Epoch 2418/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.3333 - val_accuracy: 0.8495\n",
            "Epoch 2419/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3191 - val_accuracy: 0.8487\n",
            "Epoch 2420/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3291 - val_accuracy: 0.8469\n",
            "Epoch 2421/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 1.3317 - val_accuracy: 0.8494\n",
            "Epoch 2422/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3235 - val_accuracy: 0.8490\n",
            "Epoch 2423/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3349 - val_accuracy: 0.8502\n",
            "Epoch 2424/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3302 - val_accuracy: 0.8499\n",
            "Epoch 2425/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3271 - val_accuracy: 0.8503\n",
            "Epoch 2426/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3518 - val_accuracy: 0.8496\n",
            "Epoch 2427/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3433 - val_accuracy: 0.8523\n",
            "Epoch 2428/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3449 - val_accuracy: 0.8529\n",
            "Epoch 2429/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.3374 - val_accuracy: 0.8522\n",
            "Epoch 2430/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3244 - val_accuracy: 0.8516\n",
            "Epoch 2431/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.3397 - val_accuracy: 0.8513\n",
            "Epoch 2432/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3328 - val_accuracy: 0.8500\n",
            "Epoch 2433/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.3390 - val_accuracy: 0.8511\n",
            "Epoch 2434/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3286 - val_accuracy: 0.8518\n",
            "Epoch 2435/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.3181 - val_accuracy: 0.8522\n",
            "Epoch 2436/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.3211 - val_accuracy: 0.8519\n",
            "Epoch 2437/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 1.3290 - val_accuracy: 0.8519\n",
            "Epoch 2438/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3279 - val_accuracy: 0.8485\n",
            "Epoch 2439/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3354 - val_accuracy: 0.8503\n",
            "Epoch 2440/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.3280 - val_accuracy: 0.8531\n",
            "Epoch 2441/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3445 - val_accuracy: 0.8499\n",
            "Epoch 2442/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3432 - val_accuracy: 0.8538\n",
            "Epoch 2443/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 1.3312 - val_accuracy: 0.8523\n",
            "Epoch 2444/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 1.3366 - val_accuracy: 0.8520\n",
            "Epoch 2445/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3296 - val_accuracy: 0.8510\n",
            "Epoch 2446/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3448 - val_accuracy: 0.8523\n",
            "Epoch 2447/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3338 - val_accuracy: 0.8512\n",
            "Epoch 2448/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3208 - val_accuracy: 0.8515\n",
            "Epoch 2449/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3403 - val_accuracy: 0.8521\n",
            "Epoch 2450/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3302 - val_accuracy: 0.8526\n",
            "Epoch 2451/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.3303 - val_accuracy: 0.8513\n",
            "Epoch 2452/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.3098 - val_accuracy: 0.8490\n",
            "Epoch 2453/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3158 - val_accuracy: 0.8485\n",
            "Epoch 2454/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3100 - val_accuracy: 0.8482\n",
            "Epoch 2455/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3282 - val_accuracy: 0.8515\n",
            "Epoch 2456/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3439 - val_accuracy: 0.8507\n",
            "Epoch 2457/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3460 - val_accuracy: 0.8499\n",
            "Epoch 2458/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3501 - val_accuracy: 0.8494\n",
            "Epoch 2459/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3669 - val_accuracy: 0.8487\n",
            "Epoch 2460/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.3234 - val_accuracy: 0.8505\n",
            "Epoch 2461/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3392 - val_accuracy: 0.8511\n",
            "Epoch 2462/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.3358 - val_accuracy: 0.8487\n",
            "Epoch 2463/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3316 - val_accuracy: 0.8515\n",
            "Epoch 2464/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3332 - val_accuracy: 0.8514\n",
            "Epoch 2465/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3230 - val_accuracy: 0.8492\n",
            "Epoch 2466/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.3377 - val_accuracy: 0.8502\n",
            "Epoch 2467/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.3304 - val_accuracy: 0.8511\n",
            "Epoch 2468/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 1.3191 - val_accuracy: 0.8507\n",
            "Epoch 2469/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.3232 - val_accuracy: 0.8495\n",
            "Epoch 2470/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3122 - val_accuracy: 0.8517\n",
            "Epoch 2471/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3188 - val_accuracy: 0.8523\n",
            "Epoch 2472/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3229 - val_accuracy: 0.8484\n",
            "Epoch 2473/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3140 - val_accuracy: 0.8485\n",
            "Epoch 2474/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.3451 - val_accuracy: 0.8522\n",
            "Epoch 2475/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3249 - val_accuracy: 0.8519\n",
            "Epoch 2476/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3174 - val_accuracy: 0.8517\n",
            "Epoch 2477/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3130 - val_accuracy: 0.8526\n",
            "Epoch 2478/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.3245 - val_accuracy: 0.8512\n",
            "Epoch 2479/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3379 - val_accuracy: 0.8517\n",
            "Epoch 2480/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.3369 - val_accuracy: 0.8500\n",
            "Epoch 2481/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3401 - val_accuracy: 0.8510\n",
            "Epoch 2482/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3480 - val_accuracy: 0.8525\n",
            "Epoch 2483/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3385 - val_accuracy: 0.8526\n",
            "Epoch 2484/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3394 - val_accuracy: 0.8530\n",
            "Epoch 2485/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3514 - val_accuracy: 0.8499\n",
            "Epoch 2486/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3379 - val_accuracy: 0.8489\n",
            "Epoch 2487/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3463 - val_accuracy: 0.8519\n",
            "Epoch 2488/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3557 - val_accuracy: 0.8518\n",
            "Epoch 2489/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.3644 - val_accuracy: 0.8503\n",
            "Epoch 2490/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.3279 - val_accuracy: 0.8512\n",
            "Epoch 2491/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3269 - val_accuracy: 0.8487\n",
            "Epoch 2492/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3296 - val_accuracy: 0.8490\n",
            "Epoch 2493/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3347 - val_accuracy: 0.8504\n",
            "Epoch 2494/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.3384 - val_accuracy: 0.8496\n",
            "Epoch 2495/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.3304 - val_accuracy: 0.8508\n",
            "Epoch 2496/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3347 - val_accuracy: 0.8513\n",
            "Epoch 2497/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.3504 - val_accuracy: 0.8513\n",
            "Epoch 2498/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 1.3689 - val_accuracy: 0.8517\n",
            "Epoch 2499/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 1.3565 - val_accuracy: 0.8499\n",
            "Epoch 2500/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3371 - val_accuracy: 0.8531\n",
            "Epoch 2501/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.3450 - val_accuracy: 0.8497\n",
            "Epoch 2502/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3386 - val_accuracy: 0.8526\n",
            "Epoch 2503/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3437 - val_accuracy: 0.8520\n",
            "Epoch 2504/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.3256 - val_accuracy: 0.8528\n",
            "Epoch 2505/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3384 - val_accuracy: 0.8525\n",
            "Epoch 2506/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3302 - val_accuracy: 0.8520\n",
            "Epoch 2507/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3201 - val_accuracy: 0.8526\n",
            "Epoch 2508/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.3384 - val_accuracy: 0.8533\n",
            "Epoch 2509/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3321 - val_accuracy: 0.8515\n",
            "Epoch 2510/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3438 - val_accuracy: 0.8517\n",
            "Epoch 2511/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3421 - val_accuracy: 0.8534\n",
            "Epoch 2512/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3364 - val_accuracy: 0.8521\n",
            "Epoch 2513/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.3302 - val_accuracy: 0.8512\n",
            "Epoch 2514/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3492 - val_accuracy: 0.8532\n",
            "Epoch 2515/3000\n",
            "235/235 [==============================] - 5s 16ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3326 - val_accuracy: 0.8527\n",
            "Epoch 2516/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.3449 - val_accuracy: 0.8516\n",
            "Epoch 2517/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3260 - val_accuracy: 0.8502\n",
            "Epoch 2518/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3394 - val_accuracy: 0.8513\n",
            "Epoch 2519/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3429 - val_accuracy: 0.8529\n",
            "Epoch 2520/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3345 - val_accuracy: 0.8498\n",
            "Epoch 2521/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3291 - val_accuracy: 0.8519\n",
            "Epoch 2522/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3200 - val_accuracy: 0.8503\n",
            "Epoch 2523/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.3434 - val_accuracy: 0.8492\n",
            "Epoch 2524/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3574 - val_accuracy: 0.8502\n",
            "Epoch 2525/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3553 - val_accuracy: 0.8526\n",
            "Epoch 2526/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.3443 - val_accuracy: 0.8522\n",
            "Epoch 2527/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.3406 - val_accuracy: 0.8523\n",
            "Epoch 2528/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3536 - val_accuracy: 0.8522\n",
            "Epoch 2529/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.3557 - val_accuracy: 0.8530\n",
            "Epoch 2530/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.3472 - val_accuracy: 0.8502\n",
            "Epoch 2531/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3468 - val_accuracy: 0.8506\n",
            "Epoch 2532/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 1.3546 - val_accuracy: 0.8498\n",
            "Epoch 2533/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3483 - val_accuracy: 0.8508\n",
            "Epoch 2534/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.3432 - val_accuracy: 0.8492\n",
            "Epoch 2535/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3343 - val_accuracy: 0.8492\n",
            "Epoch 2536/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3522 - val_accuracy: 0.8503\n",
            "Epoch 2537/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3362 - val_accuracy: 0.8517\n",
            "Epoch 2538/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 1.3422 - val_accuracy: 0.8509\n",
            "Epoch 2539/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3714 - val_accuracy: 0.8515\n",
            "Epoch 2540/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3715 - val_accuracy: 0.8504\n",
            "Epoch 2541/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3536 - val_accuracy: 0.8511\n",
            "Epoch 2542/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3610 - val_accuracy: 0.8488\n",
            "Epoch 2543/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.3347 - val_accuracy: 0.8494\n",
            "Epoch 2544/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.3479 - val_accuracy: 0.8513\n",
            "Epoch 2545/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.3209 - val_accuracy: 0.8532\n",
            "Epoch 2546/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.3359 - val_accuracy: 0.8526\n",
            "Epoch 2547/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 1.3422 - val_accuracy: 0.8524\n",
            "Epoch 2548/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3469 - val_accuracy: 0.8501\n",
            "Epoch 2549/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 1.3296 - val_accuracy: 0.8491\n",
            "Epoch 2550/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3221 - val_accuracy: 0.8507\n",
            "Epoch 2551/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.3324 - val_accuracy: 0.8492\n",
            "Epoch 2552/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 1.3409 - val_accuracy: 0.8498\n",
            "Epoch 2553/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3513 - val_accuracy: 0.8493\n",
            "Epoch 2554/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3384 - val_accuracy: 0.8486\n",
            "Epoch 2555/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3415 - val_accuracy: 0.8498\n",
            "Epoch 2556/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3305 - val_accuracy: 0.8497\n",
            "Epoch 2557/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3241 - val_accuracy: 0.8520\n",
            "Epoch 2558/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.3378 - val_accuracy: 0.8494\n",
            "Epoch 2559/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3305 - val_accuracy: 0.8508\n",
            "Epoch 2560/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3372 - val_accuracy: 0.8495\n",
            "Epoch 2561/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3369 - val_accuracy: 0.8510\n",
            "Epoch 2562/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.3362 - val_accuracy: 0.8493\n",
            "Epoch 2563/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3338 - val_accuracy: 0.8505\n",
            "Epoch 2564/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3290 - val_accuracy: 0.8505\n",
            "Epoch 2565/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3441 - val_accuracy: 0.8514\n",
            "Epoch 2566/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3358 - val_accuracy: 0.8517\n",
            "Epoch 2567/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.3503 - val_accuracy: 0.8475\n",
            "Epoch 2568/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 1.3591 - val_accuracy: 0.8500\n",
            "Epoch 2569/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3661 - val_accuracy: 0.8499\n",
            "Epoch 2570/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3485 - val_accuracy: 0.8498\n",
            "Epoch 2571/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3440 - val_accuracy: 0.8504\n",
            "Epoch 2572/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3518 - val_accuracy: 0.8474\n",
            "Epoch 2573/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3612 - val_accuracy: 0.8504\n",
            "Epoch 2574/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.3140 - val_accuracy: 0.8492\n",
            "Epoch 2575/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3336 - val_accuracy: 0.8508\n",
            "Epoch 2576/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.3196 - val_accuracy: 0.8503\n",
            "Epoch 2577/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.3410 - val_accuracy: 0.8509\n",
            "Epoch 2578/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3316 - val_accuracy: 0.8505\n",
            "Epoch 2579/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.3333 - val_accuracy: 0.8521\n",
            "Epoch 2580/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3312 - val_accuracy: 0.8502\n",
            "Epoch 2581/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3309 - val_accuracy: 0.8503\n",
            "Epoch 2582/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3466 - val_accuracy: 0.8510\n",
            "Epoch 2583/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3422 - val_accuracy: 0.8481\n",
            "Epoch 2584/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.3517 - val_accuracy: 0.8495\n",
            "Epoch 2585/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.3332 - val_accuracy: 0.8507\n",
            "Epoch 2586/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3367 - val_accuracy: 0.8500\n",
            "Epoch 2587/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 1.3440 - val_accuracy: 0.8524\n",
            "Epoch 2588/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3543 - val_accuracy: 0.8504\n",
            "Epoch 2589/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3685 - val_accuracy: 0.8514\n",
            "Epoch 2590/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.3613 - val_accuracy: 0.8520\n",
            "Epoch 2591/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 1.3500 - val_accuracy: 0.8523\n",
            "Epoch 2592/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.3645 - val_accuracy: 0.8505\n",
            "Epoch 2593/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.3701 - val_accuracy: 0.8513\n",
            "Epoch 2594/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3680 - val_accuracy: 0.8517\n",
            "Epoch 2595/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3738 - val_accuracy: 0.8526\n",
            "Epoch 2596/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3562 - val_accuracy: 0.8527\n",
            "Epoch 2597/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.3727 - val_accuracy: 0.8534\n",
            "Epoch 2598/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3667 - val_accuracy: 0.8518\n",
            "Epoch 2599/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.3764 - val_accuracy: 0.8507\n",
            "Epoch 2600/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3664 - val_accuracy: 0.8514\n",
            "Epoch 2601/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.3672 - val_accuracy: 0.8515\n",
            "Epoch 2602/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3496 - val_accuracy: 0.8523\n",
            "Epoch 2603/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.3235 - val_accuracy: 0.8530\n",
            "Epoch 2604/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3309 - val_accuracy: 0.8506\n",
            "Epoch 2605/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3265 - val_accuracy: 0.8505\n",
            "Epoch 2606/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.3343 - val_accuracy: 0.8523\n",
            "Epoch 2607/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.3383 - val_accuracy: 0.8515\n",
            "Epoch 2608/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.3313 - val_accuracy: 0.8520\n",
            "Epoch 2609/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3298 - val_accuracy: 0.8497\n",
            "Epoch 2610/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 1.3332 - val_accuracy: 0.8494\n",
            "Epoch 2611/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3201 - val_accuracy: 0.8521\n",
            "Epoch 2612/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3094 - val_accuracy: 0.8506\n",
            "Epoch 2613/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3301 - val_accuracy: 0.8515\n",
            "Epoch 2614/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3070 - val_accuracy: 0.8509\n",
            "Epoch 2615/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.3191 - val_accuracy: 0.8525\n",
            "Epoch 2616/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.3191 - val_accuracy: 0.8507\n",
            "Epoch 2617/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3466 - val_accuracy: 0.8524\n",
            "Epoch 2618/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3337 - val_accuracy: 0.8509\n",
            "Epoch 2619/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3219 - val_accuracy: 0.8492\n",
            "Epoch 2620/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3262 - val_accuracy: 0.8510\n",
            "Epoch 2621/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.3341 - val_accuracy: 0.8507\n",
            "Epoch 2622/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.3490 - val_accuracy: 0.8486\n",
            "Epoch 2623/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3556 - val_accuracy: 0.8491\n",
            "Epoch 2624/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.3580 - val_accuracy: 0.8518\n",
            "Epoch 2625/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.3523 - val_accuracy: 0.8500\n",
            "Epoch 2626/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3471 - val_accuracy: 0.8510\n",
            "Epoch 2627/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3296 - val_accuracy: 0.8500\n",
            "Epoch 2628/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.3423 - val_accuracy: 0.8524\n",
            "Epoch 2629/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 1.3405 - val_accuracy: 0.8498\n",
            "Epoch 2630/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3330 - val_accuracy: 0.8517\n",
            "Epoch 2631/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3411 - val_accuracy: 0.8512\n",
            "Epoch 2632/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3463 - val_accuracy: 0.8503\n",
            "Epoch 2633/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.3463 - val_accuracy: 0.8487\n",
            "Epoch 2634/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3677 - val_accuracy: 0.8510\n",
            "Epoch 2635/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3645 - val_accuracy: 0.8500\n",
            "Epoch 2636/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.3550 - val_accuracy: 0.8476\n",
            "Epoch 2637/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.3579 - val_accuracy: 0.8498\n",
            "Epoch 2638/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3486 - val_accuracy: 0.8504\n",
            "Epoch 2639/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3583 - val_accuracy: 0.8485\n",
            "Epoch 2640/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3309 - val_accuracy: 0.8500\n",
            "Epoch 2641/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3554 - val_accuracy: 0.8515\n",
            "Epoch 2642/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3460 - val_accuracy: 0.8516\n",
            "Epoch 2643/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3795 - val_accuracy: 0.8496\n",
            "Epoch 2644/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3526 - val_accuracy: 0.8480\n",
            "Epoch 2645/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 1.3511 - val_accuracy: 0.8492\n",
            "Epoch 2646/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3519 - val_accuracy: 0.8497\n",
            "Epoch 2647/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.3473 - val_accuracy: 0.8492\n",
            "Epoch 2648/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3516 - val_accuracy: 0.8514\n",
            "Epoch 2649/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.3565 - val_accuracy: 0.8510\n",
            "Epoch 2650/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.3470 - val_accuracy: 0.8486\n",
            "Epoch 2651/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.3531 - val_accuracy: 0.8507\n",
            "Epoch 2652/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.3448 - val_accuracy: 0.8503\n",
            "Epoch 2653/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3458 - val_accuracy: 0.8498\n",
            "Epoch 2654/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3374 - val_accuracy: 0.8480\n",
            "Epoch 2655/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3352 - val_accuracy: 0.8510\n",
            "Epoch 2656/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3610 - val_accuracy: 0.8506\n",
            "Epoch 2657/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3658 - val_accuracy: 0.8491\n",
            "Epoch 2658/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.3899 - val_accuracy: 0.8498\n",
            "Epoch 2659/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3652 - val_accuracy: 0.8485\n",
            "Epoch 2660/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3642 - val_accuracy: 0.8491\n",
            "Epoch 2661/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.3670 - val_accuracy: 0.8510\n",
            "Epoch 2662/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 1.3708 - val_accuracy: 0.8508\n",
            "Epoch 2663/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3766 - val_accuracy: 0.8505\n",
            "Epoch 2664/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.3595 - val_accuracy: 0.8493\n",
            "Epoch 2665/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.3658 - val_accuracy: 0.8518\n",
            "Epoch 2666/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3471 - val_accuracy: 0.8497\n",
            "Epoch 2667/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3263 - val_accuracy: 0.8527\n",
            "Epoch 2668/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.3384 - val_accuracy: 0.8516\n",
            "Epoch 2669/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3292 - val_accuracy: 0.8518\n",
            "Epoch 2670/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3570 - val_accuracy: 0.8519\n",
            "Epoch 2671/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3506 - val_accuracy: 0.8515\n",
            "Epoch 2672/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3507 - val_accuracy: 0.8515\n",
            "Epoch 2673/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.3369 - val_accuracy: 0.8528\n",
            "Epoch 2674/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3459 - val_accuracy: 0.8528\n",
            "Epoch 2675/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.3522 - val_accuracy: 0.8532\n",
            "Epoch 2676/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3407 - val_accuracy: 0.8521\n",
            "Epoch 2677/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3703 - val_accuracy: 0.8499\n",
            "Epoch 2678/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3426 - val_accuracy: 0.8506\n",
            "Epoch 2679/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3397 - val_accuracy: 0.8514\n",
            "Epoch 2680/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3479 - val_accuracy: 0.8502\n",
            "Epoch 2681/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.3364 - val_accuracy: 0.8549\n",
            "Epoch 2682/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3386 - val_accuracy: 0.8533\n",
            "Epoch 2683/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.3321 - val_accuracy: 0.8531\n",
            "Epoch 2684/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3228 - val_accuracy: 0.8527\n",
            "Epoch 2685/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3224 - val_accuracy: 0.8514\n",
            "Epoch 2686/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3293 - val_accuracy: 0.8518\n",
            "Epoch 2687/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3230 - val_accuracy: 0.8538\n",
            "Epoch 2688/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.3356 - val_accuracy: 0.8537\n",
            "Epoch 2689/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3112 - val_accuracy: 0.8528\n",
            "Epoch 2690/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 1.3384 - val_accuracy: 0.8523\n",
            "Epoch 2691/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3261 - val_accuracy: 0.8501\n",
            "Epoch 2692/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3253 - val_accuracy: 0.8519\n",
            "Epoch 2693/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3174 - val_accuracy: 0.8534\n",
            "Epoch 2694/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3347 - val_accuracy: 0.8505\n",
            "Epoch 2695/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3123 - val_accuracy: 0.8515\n",
            "Epoch 2696/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3161 - val_accuracy: 0.8507\n",
            "Epoch 2697/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.3100 - val_accuracy: 0.8501\n",
            "Epoch 2698/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3116 - val_accuracy: 0.8521\n",
            "Epoch 2699/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3247 - val_accuracy: 0.8504\n",
            "Epoch 2700/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.3117 - val_accuracy: 0.8531\n",
            "Epoch 2701/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3238 - val_accuracy: 0.8522\n",
            "Epoch 2702/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.3193 - val_accuracy: 0.8515\n",
            "Epoch 2703/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3557 - val_accuracy: 0.8485\n",
            "Epoch 2704/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.3476 - val_accuracy: 0.8516\n",
            "Epoch 2705/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.3619 - val_accuracy: 0.8498\n",
            "Epoch 2706/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3451 - val_accuracy: 0.8521\n",
            "Epoch 2707/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3438 - val_accuracy: 0.8526\n",
            "Epoch 2708/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3402 - val_accuracy: 0.8526\n",
            "Epoch 2709/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3431 - val_accuracy: 0.8518\n",
            "Epoch 2710/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3557 - val_accuracy: 0.8515\n",
            "Epoch 2711/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3556 - val_accuracy: 0.8530\n",
            "Epoch 2712/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3454 - val_accuracy: 0.8531\n",
            "Epoch 2713/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.3376 - val_accuracy: 0.8519\n",
            "Epoch 2714/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3628 - val_accuracy: 0.8494\n",
            "Epoch 2715/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.3304 - val_accuracy: 0.8518\n",
            "Epoch 2716/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3448 - val_accuracy: 0.8534\n",
            "Epoch 2717/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3337 - val_accuracy: 0.8509\n",
            "Epoch 2718/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.3342 - val_accuracy: 0.8496\n",
            "Epoch 2719/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.3292 - val_accuracy: 0.8506\n",
            "Epoch 2720/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 1.3179 - val_accuracy: 0.8514\n",
            "Epoch 2721/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3203 - val_accuracy: 0.8488\n",
            "Epoch 2722/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.3323 - val_accuracy: 0.8542\n",
            "Epoch 2723/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3257 - val_accuracy: 0.8528\n",
            "Epoch 2724/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.3311 - val_accuracy: 0.8493\n",
            "Epoch 2725/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.3387 - val_accuracy: 0.8515\n",
            "Epoch 2726/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3409 - val_accuracy: 0.8500\n",
            "Epoch 2727/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.3592 - val_accuracy: 0.8511\n",
            "Epoch 2728/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 1.3386 - val_accuracy: 0.8505\n",
            "Epoch 2729/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.3485 - val_accuracy: 0.8527\n",
            "Epoch 2730/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 1.3466 - val_accuracy: 0.8498\n",
            "Epoch 2731/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3559 - val_accuracy: 0.8489\n",
            "Epoch 2732/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.3597 - val_accuracy: 0.8508\n",
            "Epoch 2733/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3556 - val_accuracy: 0.8509\n",
            "Epoch 2734/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3695 - val_accuracy: 0.8515\n",
            "Epoch 2735/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3674 - val_accuracy: 0.8501\n",
            "Epoch 2736/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3494 - val_accuracy: 0.8512\n",
            "Epoch 2737/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.3342 - val_accuracy: 0.8533\n",
            "Epoch 2738/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3349 - val_accuracy: 0.8520\n",
            "Epoch 2739/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3101 - val_accuracy: 0.8517\n",
            "Epoch 2740/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.3265 - val_accuracy: 0.8514\n",
            "Epoch 2741/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.3122 - val_accuracy: 0.8524\n",
            "Epoch 2742/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.3104 - val_accuracy: 0.8495\n",
            "Epoch 2743/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3166 - val_accuracy: 0.8526\n",
            "Epoch 2744/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3216 - val_accuracy: 0.8511\n",
            "Epoch 2745/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.3306 - val_accuracy: 0.8535\n",
            "Epoch 2746/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3265 - val_accuracy: 0.8524\n",
            "Epoch 2747/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3366 - val_accuracy: 0.8537\n",
            "Epoch 2748/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.3515 - val_accuracy: 0.8522\n",
            "Epoch 2749/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.3351 - val_accuracy: 0.8528\n",
            "Epoch 2750/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.3628 - val_accuracy: 0.8543\n",
            "Epoch 2751/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.3528 - val_accuracy: 0.8534\n",
            "Epoch 2752/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3482 - val_accuracy: 0.8538\n",
            "Epoch 2753/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.3618 - val_accuracy: 0.8527\n",
            "Epoch 2754/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 1.3577 - val_accuracy: 0.8491\n",
            "Epoch 2755/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3757 - val_accuracy: 0.8522\n",
            "Epoch 2756/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.3544 - val_accuracy: 0.8518\n",
            "Epoch 2757/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.3510 - val_accuracy: 0.8509\n",
            "Epoch 2758/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3580 - val_accuracy: 0.8518\n",
            "Epoch 2759/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3557 - val_accuracy: 0.8502\n",
            "Epoch 2760/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 1.3456 - val_accuracy: 0.8502\n",
            "Epoch 2761/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.3454 - val_accuracy: 0.8509\n",
            "Epoch 2762/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 1.3466 - val_accuracy: 0.8523\n",
            "Epoch 2763/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.3484 - val_accuracy: 0.8524\n",
            "Epoch 2764/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3529 - val_accuracy: 0.8505\n",
            "Epoch 2765/3000\n",
            "188/188 [==============================] - 0s 1ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 0s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 2ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "188/188 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3371 - val_accuracy: 0.8521\n",
            "Epoch 2766/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3345 - val_accuracy: 0.8501\n",
            "Epoch 2767/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3340 - val_accuracy: 0.8527\n",
            "Epoch 2768/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.3211 - val_accuracy: 0.8531\n",
            "Epoch 2769/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.3318 - val_accuracy: 0.8492\n",
            "Epoch 2770/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3447 - val_accuracy: 0.8516\n",
            "Epoch 2771/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.3515 - val_accuracy: 0.8519\n",
            "Epoch 2772/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 1.3616 - val_accuracy: 0.8519\n",
            "Epoch 2773/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3570 - val_accuracy: 0.8514\n",
            "Epoch 2774/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3729 - val_accuracy: 0.8505\n",
            "Epoch 2775/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3511 - val_accuracy: 0.8516\n",
            "Epoch 2776/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3547 - val_accuracy: 0.8512\n",
            "Epoch 2777/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3510 - val_accuracy: 0.8503\n",
            "Epoch 2778/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.3652 - val_accuracy: 0.8500\n",
            "Epoch 2779/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3573 - val_accuracy: 0.8530\n",
            "Epoch 2780/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3643 - val_accuracy: 0.8508\n",
            "Epoch 2781/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3633 - val_accuracy: 0.8495\n",
            "Epoch 2782/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3686 - val_accuracy: 0.8502\n",
            "Epoch 2783/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 1.3659 - val_accuracy: 0.8484\n",
            "Epoch 2784/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.3741 - val_accuracy: 0.8506\n",
            "Epoch 2785/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3796 - val_accuracy: 0.8493\n",
            "Epoch 2786/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3624 - val_accuracy: 0.8510\n",
            "Epoch 2787/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3563 - val_accuracy: 0.8516\n",
            "Epoch 2788/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3609 - val_accuracy: 0.8493\n",
            "Epoch 2789/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.3650 - val_accuracy: 0.8500\n",
            "Epoch 2790/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3715 - val_accuracy: 0.8507\n",
            "Epoch 2791/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3735 - val_accuracy: 0.8516\n",
            "Epoch 2792/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3694 - val_accuracy: 0.8499\n",
            "Epoch 2793/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3662 - val_accuracy: 0.8502\n",
            "Epoch 2794/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.3696 - val_accuracy: 0.8512\n",
            "Epoch 2795/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.3741 - val_accuracy: 0.8508\n",
            "Epoch 2796/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3837 - val_accuracy: 0.8501\n",
            "Epoch 2797/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3724 - val_accuracy: 0.8501\n",
            "Epoch 2798/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 1.3676 - val_accuracy: 0.8495\n",
            "Epoch 2799/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3660 - val_accuracy: 0.8487\n",
            "Epoch 2800/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3803 - val_accuracy: 0.8508\n",
            "Epoch 2801/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3774 - val_accuracy: 0.8504\n",
            "Epoch 2802/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 1.3687 - val_accuracy: 0.8495\n",
            "Epoch 2803/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3703 - val_accuracy: 0.8508\n",
            "Epoch 2804/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3854 - val_accuracy: 0.8470\n",
            "Epoch 2805/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 1.3986 - val_accuracy: 0.8509\n",
            "Epoch 2806/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3994 - val_accuracy: 0.8517\n",
            "Epoch 2807/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3788 - val_accuracy: 0.8494\n",
            "Epoch 2808/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3734 - val_accuracy: 0.8499\n",
            "Epoch 2809/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3682 - val_accuracy: 0.8509\n",
            "Epoch 2810/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3603 - val_accuracy: 0.8526\n",
            "Epoch 2811/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3656 - val_accuracy: 0.8522\n",
            "Epoch 2812/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3532 - val_accuracy: 0.8504\n",
            "Epoch 2813/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.3498 - val_accuracy: 0.8510\n",
            "Epoch 2814/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3451 - val_accuracy: 0.8523\n",
            "Epoch 2815/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3543 - val_accuracy: 0.8540\n",
            "Epoch 2816/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 1.3488 - val_accuracy: 0.8517\n",
            "Epoch 2817/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.3384 - val_accuracy: 0.8511\n",
            "Epoch 2818/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 1.3547 - val_accuracy: 0.8515\n",
            "Epoch 2819/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 1.3786 - val_accuracy: 0.8510\n",
            "Epoch 2820/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3723 - val_accuracy: 0.8505\n",
            "Epoch 2821/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3730 - val_accuracy: 0.8492\n",
            "Epoch 2822/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3560 - val_accuracy: 0.8493\n",
            "Epoch 2823/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3325 - val_accuracy: 0.8505\n",
            "Epoch 2824/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3487 - val_accuracy: 0.8507\n",
            "Epoch 2825/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3461 - val_accuracy: 0.8480\n",
            "Epoch 2826/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3422 - val_accuracy: 0.8516\n",
            "Epoch 2827/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.3383 - val_accuracy: 0.8513\n",
            "Epoch 2828/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3450 - val_accuracy: 0.8494\n",
            "Epoch 2829/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.3600 - val_accuracy: 0.8475\n",
            "Epoch 2830/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.3564 - val_accuracy: 0.8535\n",
            "Epoch 2831/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.3610 - val_accuracy: 0.8503\n",
            "Epoch 2832/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3420 - val_accuracy: 0.8517\n",
            "Epoch 2833/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.3588 - val_accuracy: 0.8531\n",
            "Epoch 2834/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.3333 - val_accuracy: 0.8494\n",
            "Epoch 2835/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3464 - val_accuracy: 0.8499\n",
            "Epoch 2836/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.3390 - val_accuracy: 0.8508\n",
            "Epoch 2837/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 1.3511 - val_accuracy: 0.8486\n",
            "Epoch 2838/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.3478 - val_accuracy: 0.8522\n",
            "Epoch 2839/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.3455 - val_accuracy: 0.8512\n",
            "Epoch 2840/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 1.3503 - val_accuracy: 0.8518\n",
            "Epoch 2841/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3305 - val_accuracy: 0.8528\n",
            "Epoch 2842/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 1.3584 - val_accuracy: 0.8515\n",
            "Epoch 2843/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3621 - val_accuracy: 0.8502\n",
            "Epoch 2844/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3607 - val_accuracy: 0.8512\n",
            "Epoch 2845/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3584 - val_accuracy: 0.8509\n",
            "Epoch 2846/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3581 - val_accuracy: 0.8475\n",
            "Epoch 2847/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3847 - val_accuracy: 0.8487\n",
            "Epoch 2848/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3616 - val_accuracy: 0.8494\n",
            "Epoch 2849/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.3832 - val_accuracy: 0.8503\n",
            "Epoch 2850/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.3799 - val_accuracy: 0.8505\n",
            "Epoch 2851/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.3825 - val_accuracy: 0.8491\n",
            "Epoch 2852/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3796 - val_accuracy: 0.8500\n",
            "Epoch 2853/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3772 - val_accuracy: 0.8495\n",
            "Epoch 2854/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3819 - val_accuracy: 0.8509\n",
            "Epoch 2855/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.3746 - val_accuracy: 0.8495\n",
            "Epoch 2856/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.3592 - val_accuracy: 0.8511\n",
            "Epoch 2857/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3632 - val_accuracy: 0.8486\n",
            "Epoch 2858/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.3584 - val_accuracy: 0.8493\n",
            "Epoch 2859/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.3586 - val_accuracy: 0.8495\n",
            "Epoch 2860/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3561 - val_accuracy: 0.8481\n",
            "Epoch 2861/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.3643 - val_accuracy: 0.8500\n",
            "Epoch 2862/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3501 - val_accuracy: 0.8498\n",
            "Epoch 2863/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3609 - val_accuracy: 0.8476\n",
            "Epoch 2864/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 1.3587 - val_accuracy: 0.8484\n",
            "Epoch 2865/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.3584 - val_accuracy: 0.8500\n",
            "Epoch 2866/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 1.3591 - val_accuracy: 0.8497\n",
            "Epoch 2867/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 1.3527 - val_accuracy: 0.8506\n",
            "Epoch 2868/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3716 - val_accuracy: 0.8505\n",
            "Epoch 2869/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3756 - val_accuracy: 0.8494\n",
            "Epoch 2870/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3605 - val_accuracy: 0.8503\n",
            "Epoch 2871/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.3505 - val_accuracy: 0.8502\n",
            "Epoch 2872/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3640 - val_accuracy: 0.8506\n",
            "Epoch 2873/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.3564 - val_accuracy: 0.8485\n",
            "Epoch 2874/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.3625 - val_accuracy: 0.8493\n",
            "Epoch 2875/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.3529 - val_accuracy: 0.8486\n",
            "Epoch 2876/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3552 - val_accuracy: 0.8494\n",
            "Epoch 2877/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.3637 - val_accuracy: 0.8502\n",
            "Epoch 2878/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.3596 - val_accuracy: 0.8493\n",
            "Epoch 2879/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.3513 - val_accuracy: 0.8467\n",
            "Epoch 2880/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.3558 - val_accuracy: 0.8486\n",
            "Epoch 2881/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3591 - val_accuracy: 0.8505\n",
            "Epoch 2882/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3501 - val_accuracy: 0.8513\n",
            "Epoch 2883/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3504 - val_accuracy: 0.8528\n",
            "Epoch 2884/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.3532 - val_accuracy: 0.8517\n",
            "Epoch 2885/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3446 - val_accuracy: 0.8506\n",
            "Epoch 2886/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3566 - val_accuracy: 0.8490\n",
            "Epoch 2887/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3660 - val_accuracy: 0.8476\n",
            "Epoch 2888/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3780 - val_accuracy: 0.8492\n",
            "Epoch 2889/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.3849 - val_accuracy: 0.8494\n",
            "Epoch 2890/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 1.3581 - val_accuracy: 0.8503\n",
            "Epoch 2891/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 1.3721 - val_accuracy: 0.8499\n",
            "Epoch 2892/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3607 - val_accuracy: 0.8505\n",
            "Epoch 2893/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.3652 - val_accuracy: 0.8504\n",
            "Epoch 2894/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3507 - val_accuracy: 0.8512\n",
            "Epoch 2895/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3595 - val_accuracy: 0.8530\n",
            "Epoch 2896/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3649 - val_accuracy: 0.8514\n",
            "Epoch 2897/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.3720 - val_accuracy: 0.8531\n",
            "Epoch 2898/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.3716 - val_accuracy: 0.8487\n",
            "Epoch 2899/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.3805 - val_accuracy: 0.8499\n",
            "Epoch 2900/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 1.3721 - val_accuracy: 0.8480\n",
            "Epoch 2901/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.3702 - val_accuracy: 0.8509\n",
            "Epoch 2902/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 1.3784 - val_accuracy: 0.8494\n",
            "Epoch 2903/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.3557 - val_accuracy: 0.8503\n",
            "Epoch 2904/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.3476 - val_accuracy: 0.8510\n",
            "Epoch 2905/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3492 - val_accuracy: 0.8483\n",
            "Epoch 2906/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.3443 - val_accuracy: 0.8506\n",
            "Epoch 2907/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.3561 - val_accuracy: 0.8484\n",
            "Epoch 2908/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3527 - val_accuracy: 0.8503\n",
            "Epoch 2909/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 1.3510 - val_accuracy: 0.8529\n",
            "Epoch 2910/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 1.3484 - val_accuracy: 0.8527\n",
            "Epoch 2911/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.3536 - val_accuracy: 0.8522\n",
            "Epoch 2912/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 1.3363 - val_accuracy: 0.8524\n",
            "Epoch 2913/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.3301 - val_accuracy: 0.8538\n",
            "Epoch 2914/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.3447 - val_accuracy: 0.8523\n",
            "Epoch 2915/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.3728 - val_accuracy: 0.8524\n",
            "Epoch 2916/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.3934 - val_accuracy: 0.8509\n",
            "Epoch 2917/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3815 - val_accuracy: 0.8488\n",
            "Epoch 2918/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 1.3796 - val_accuracy: 0.8496\n",
            "Epoch 2919/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3833 - val_accuracy: 0.8490\n",
            "Epoch 2920/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.3849 - val_accuracy: 0.8505\n",
            "Epoch 2921/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.3754 - val_accuracy: 0.8501\n",
            "Epoch 2922/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.3940 - val_accuracy: 0.8478\n",
            "Epoch 2923/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3821 - val_accuracy: 0.8496\n",
            "Epoch 2924/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.3693 - val_accuracy: 0.8525\n",
            "Epoch 2925/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.3747 - val_accuracy: 0.8506\n",
            "Epoch 2926/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3720 - val_accuracy: 0.8503\n",
            "Epoch 2927/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 1.3660 - val_accuracy: 0.8494\n",
            "Epoch 2928/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3593 - val_accuracy: 0.8500\n",
            "Epoch 2929/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 1.3754 - val_accuracy: 0.8500\n",
            "Epoch 2930/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3701 - val_accuracy: 0.8526\n",
            "Epoch 2931/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.3519 - val_accuracy: 0.8513\n",
            "Epoch 2932/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.3666 - val_accuracy: 0.8516\n",
            "Epoch 2933/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3525 - val_accuracy: 0.8520\n",
            "Epoch 2934/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 1.3849 - val_accuracy: 0.8507\n",
            "Epoch 2935/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.3862 - val_accuracy: 0.8486\n",
            "Epoch 2936/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 1.3737 - val_accuracy: 0.8503\n",
            "Epoch 2937/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.3688 - val_accuracy: 0.8520\n",
            "Epoch 2938/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.3673 - val_accuracy: 0.8491\n",
            "Epoch 2939/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.3701 - val_accuracy: 0.8518\n",
            "Epoch 2940/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.3768 - val_accuracy: 0.8515\n",
            "Epoch 2941/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 1.3746 - val_accuracy: 0.8518\n",
            "Epoch 2942/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 1.3752 - val_accuracy: 0.8485\n",
            "Epoch 2943/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.3746 - val_accuracy: 0.8507\n",
            "Epoch 2944/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.3693 - val_accuracy: 0.8473\n",
            "Epoch 2945/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3708 - val_accuracy: 0.8507\n",
            "Epoch 2946/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 1.3402 - val_accuracy: 0.8498\n",
            "Epoch 2947/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3628 - val_accuracy: 0.8486\n",
            "Epoch 2948/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.3545 - val_accuracy: 0.8495\n",
            "Epoch 2949/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 1.3477 - val_accuracy: 0.8509\n",
            "Epoch 2950/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3371 - val_accuracy: 0.8494\n",
            "Epoch 2951/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3572 - val_accuracy: 0.8512\n",
            "Epoch 2952/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.3518 - val_accuracy: 0.8508\n",
            "Epoch 2953/3000\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.3469 - val_accuracy: 0.8484\n",
            "Epoch 2954/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.3410 - val_accuracy: 0.8523\n",
            "Epoch 2955/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3411 - val_accuracy: 0.8512\n",
            "Epoch 2956/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.3524 - val_accuracy: 0.8536\n",
            "Epoch 2957/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 1.3323 - val_accuracy: 0.8510\n",
            "Epoch 2958/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.3421 - val_accuracy: 0.8529\n",
            "Epoch 2959/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.3683 - val_accuracy: 0.8519\n",
            "Epoch 2960/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.3653 - val_accuracy: 0.8522\n",
            "Epoch 2961/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.3687 - val_accuracy: 0.8512\n",
            "Epoch 2962/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3590 - val_accuracy: 0.8496\n",
            "Epoch 2963/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.3575 - val_accuracy: 0.8498\n",
            "Epoch 2964/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.3621 - val_accuracy: 0.8515\n",
            "Epoch 2965/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 1.3741 - val_accuracy: 0.8513\n",
            "Epoch 2966/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.3705 - val_accuracy: 0.8529\n",
            "Epoch 2967/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.3561 - val_accuracy: 0.8532\n",
            "Epoch 2968/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.3546 - val_accuracy: 0.8516\n",
            "Epoch 2969/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3500 - val_accuracy: 0.8510\n",
            "Epoch 2970/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.3323 - val_accuracy: 0.8521\n",
            "Epoch 2971/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.3288 - val_accuracy: 0.8531\n",
            "Epoch 2972/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.3579 - val_accuracy: 0.8523\n",
            "Epoch 2973/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.3557 - val_accuracy: 0.8511\n",
            "Epoch 2974/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.3818 - val_accuracy: 0.8506\n",
            "Epoch 2975/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3795 - val_accuracy: 0.8489\n",
            "Epoch 2976/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.3747 - val_accuracy: 0.8511\n",
            "Epoch 2977/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3738 - val_accuracy: 0.8503\n",
            "Epoch 2978/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.3864 - val_accuracy: 0.8486\n",
            "Epoch 2979/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.3790 - val_accuracy: 0.8507\n",
            "Epoch 2980/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.3640 - val_accuracy: 0.8501\n",
            "Epoch 2981/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3601 - val_accuracy: 0.8499\n",
            "Epoch 2982/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 1.3619 - val_accuracy: 0.8504\n",
            "Epoch 2983/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.3704 - val_accuracy: 0.8502\n",
            "Epoch 2984/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.3679 - val_accuracy: 0.8501\n",
            "Epoch 2985/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.3580 - val_accuracy: 0.8507\n",
            "Epoch 2986/3000\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.3629 - val_accuracy: 0.8492\n",
            "Epoch 2987/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.3456 - val_accuracy: 0.8505\n",
            "Epoch 2988/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.3580 - val_accuracy: 0.8485\n",
            "Epoch 2989/3000\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3370 - val_accuracy: 0.8524\n",
            "Epoch 2990/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.3503 - val_accuracy: 0.8514\n",
            "Epoch 2991/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.3372 - val_accuracy: 0.8528\n",
            "Epoch 2992/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.3514 - val_accuracy: 0.8508\n",
            "Epoch 2993/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.3393 - val_accuracy: 0.8517\n",
            "Epoch 2994/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3453 - val_accuracy: 0.8489\n",
            "Epoch 2995/3000\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.3350 - val_accuracy: 0.8501\n",
            "Epoch 2996/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.3323 - val_accuracy: 0.8501\n",
            "Epoch 2997/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3436 - val_accuracy: 0.8517\n",
            "Epoch 2998/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.3638 - val_accuracy: 0.8507\n",
            "Epoch 2999/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.3719 - val_accuracy: 0.8508\n",
            "Epoch 3000/3000\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.3770 - val_accuracy: 0.8486\n",
            "===============Save loss and acc===============\n",
            "===============get spin===============\n",
            "===============get calc===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [00:05<00:02,  1.21it/s]/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "<ipython-input-4-78447503d08e>:233: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  q2 = ab/(np.sqrt(aa)*np.sqrt(bb))\n",
            " 80%|████████  | 8/10 [00:06<00:01,  1.20it/s]<ipython-input-4-78447503d08e>:199: RuntimeWarning: overflow encountered in square\n",
            "  x = np.sum(dot_product ** 2)\n",
            "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 16.54it/s]\n"
          ]
        }
      ],
      "source": [
        "print('='*15+'build model2'+'='*15)\n",
        "if CFG.ini_type == 'A':\n",
        "  print('initialize type A')\n",
        "  set_seed(CFG.seed2)\n",
        "  w_intializer2 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "elif CFG.ini_type == 'B':\n",
        "  print('initialize type B')\n",
        "  #w_intializer2 = tf.keras.initializers.RandomNormal(mean=0, stddev=1)\n",
        "  set_seed(CFG.seed4)\n",
        "\n",
        "\n",
        "model2 = create_model(params=model_params, w_initializer=w_intializer1, Mask_list=mask_list ,Const_list=const_list)\n",
        "print(model2.layers[3].get_weights()[0])\n",
        "print('='*15+'Train model2'+'='*15)\n",
        "history2 = model2.fit(X_train, y_train,\n",
        "                batch_size=model_params[\"batch_size\"],\n",
        "                epochs=model_params[\"epochs\"],\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[LogEpochIntermediateCallcack(layer_name_list=CFG.layer_name_list,model_num='002')]\n",
        "                )\n",
        "\n",
        "print('='*15+'Save loss and acc'+'='*15)\n",
        "with open(f'./Output/Loss/M{CFG.M}/perform002_ini{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','wb') as handle:\n",
        "        pickle.dump(history2.history, handle)\n",
        "\n",
        "print('='*15+'get spin'+'='*15)\n",
        "with open(f'./Output/Spin/M{CFG.M}/model001_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_A=pickle.loads(f.read())\n",
        "\n",
        "with open(f'./Output/Spin/M{CFG.M}/model002_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_B=pickle.loads(f.read())\n",
        "\n",
        "\n",
        "print('='*15+'get calc'+'='*15)\n",
        "qab, qaa, q2 = get_q2(spin_A,spin_B)\n",
        "sim_q = get_sim_q(spin_A, spin_B)\n",
        "layer_q = get_layer_overlap(qab,qaa,q2,sim_q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClE9vkvvXpWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2AkBEzQ_BfK7",
        "outputId": "85ca68b1-c256-4afb-8dc9-8df41f97e84e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b1c3b83d720>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "for i, l in enumerate(CFG.layer_name_list[:-1]):\n",
        "    ax.plot(q2['time'][5:],q2[l][5:],label=f'layer{i+1}')\n",
        "ax.set_xlabel('Epoch',fontsize=16)\n",
        "ax.set_ylabel('sim_q', fontsize=16)\n",
        "#ax.set_xscale('log')\n",
        "ax.set_title(f'Train Data (M:{CFG.M} L:{CFG.L})',fontsize=16)\n",
        "#ax.set_ylim(0,1)\n",
        "ax.grid(axis='y')\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaZMtXE_FiB6"
      },
      "outputs": [],
      "source": [
        "with open(f'./Output/Spin/M{CFG.M}/model001_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_A=pickle.loads(f.read())\n",
        "\n",
        "with open(f'./Output/Spin/M{CFG.M}/model002_stopW_type{CFG.ini_type}_L{CFG.L}_C{CFG.C}_{CFG.train}.txt','rb') as f:\n",
        "    spin_B=pickle.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spin_B['time']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Egop3AMXzTC",
        "outputId": "157a6f94-b264-4fe8-9081-bd99d9f1f416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 22,\n",
              " 24,\n",
              " 26,\n",
              " 28,\n",
              " 30,\n",
              " 33,\n",
              " 36,\n",
              " 39,\n",
              " 42,\n",
              " 46,\n",
              " 50,\n",
              " 55,\n",
              " 60,\n",
              " 66,\n",
              " 72,\n",
              " 79,\n",
              " 86,\n",
              " 94,\n",
              " 103,\n",
              " 113,\n",
              " 124,\n",
              " 136,\n",
              " 149,\n",
              " 163,\n",
              " 179,\n",
              " 196,\n",
              " 215,\n",
              " 236,\n",
              " 259,\n",
              " 284,\n",
              " 312,\n",
              " 343,\n",
              " 377,\n",
              " 414,\n",
              " 455,\n",
              " 500,\n",
              " 550,\n",
              " 605,\n",
              " 665,\n",
              " 731,\n",
              " 804,\n",
              " 884,\n",
              " 972]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bGYC3mGIX9Il"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMWWl2YoD/ciiCCjQjtGr5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}